<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/02/universe/typescript/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/02/universe/typescript/" class="post-title-link" itemprop="url">TypeScript</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-02 00:00:00" itemprop="dateCreated datePublished" datetime="2020-03-02T00:00:00+08:00">2020-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-15 12:02:38" itemprop="dateModified" datetime="2020-04-15T12:02:38+08:00">2020-04-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="TypeScript"><a href="#TypeScript" class="headerlink" title="TypeScript"></a>TypeScript</h1><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>typescript是编译型,编译成javascript(解释型).</p>
<ul>
<li>安装<ul>
<li><code>npm install -g typescript</code></li>
</ul>
</li>
<li>编译<ul>
<li><code>tsc hello.ts</code></li>
</ul>
</li>
<li>编写react时以.tsx为后缀</li>
</ul>
<h2 id="强类型"><a href="#强类型" class="headerlink" title="强类型"></a>强类型</h2><h3 id="指定类型"><a href="#指定类型" class="headerlink" title="指定类型"></a>指定类型</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> str:<span class="built_in">string</span> = <span class="string">"1"</span>;</span><br><span class="line"><span class="keyword">var</span> num:<span class="built_in">number</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">var</span> bool:<span class="built_in">boolean</span> = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">var</span> un:<span class="literal">undefined</span> = <span class="literal">undefined</span>;</span><br><span class="line"><span class="keyword">var</span> nil:<span class="literal">null</span> = <span class="literal">null</span>;</span><br><span class="line"><span class="keyword">var</span> a:<span class="built_in">any</span>;</span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line">a = <span class="string">"1"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> func1 = <span class="function"><span class="keyword">function</span>(<span class="params"></span>):<span class="title">void</span></span>&#123;</span><br><span class="line">     </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> func2 = <span class="function"><span class="keyword">function</span>(<span class="params"></span>):<span class="title">number</span></span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>没有赋值,表示是any值,以后不管怎么赋值都是any值的类型</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a2;</span><br><span class="line">a2 = <span class="number">1</span>;</span><br><span class="line">a2 = <span class="string">"1"</span>;</span><br></pre></td></tr></table></figure>

<p>联合类型,方法只能调用类型公共的方法</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> strnum:<span class="built_in">string</span>|<span class="built_in">number</span> = <span class="string">"1"</span>;</span><br><span class="line"><span class="comment">// strnum.length() 就不行</span></span><br><span class="line">strnum.toString()</span><br></pre></td></tr></table></figure>

<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>类似java的接口,’子类必须实现接口’</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Inf&#123;</span><br><span class="line">    name:<span class="built_in">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> obj:Inf;</span><br><span class="line">obj = &#123;name:<span class="string">"ring"</span>&#125;  <span class="comment">// 没有赋值会报错</span></span><br></pre></td></tr></table></figure>

<p>可选属性</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Inf&#123;</span><br><span class="line">    name:<span class="built_in">string</span>,</span><br><span class="line">    age?:<span class="built_in">number</span>  <span class="comment">// 可选类型</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> obj:Inf;</span><br><span class="line">obj = &#123;name:<span class="string">"ring"</span>&#125;</span><br></pre></td></tr></table></figure>

<p>不确定数量属性</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Inf&#123;</span><br><span class="line">    name:<span class="built_in">string</span>,</span><br><span class="line">    age?:<span class="built_in">number</span>, <span class="comment">// 可选类型</span></span><br><span class="line">    [propName:<span class="built_in">string</span>]:<span class="built_in">any</span>  <span class="comment">// 不确定数量的propName(strng类型),他的值是any</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> obj:Inf;</span><br><span class="line">obj = &#123;name:<span class="string">"ring"</span>, age:<span class="number">10</span>, sex:man&#125;</span><br></pre></td></tr></table></figure>

<p>只读属性</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Inf&#123;</span><br><span class="line">    name:<span class="built_in">string</span>,</span><br><span class="line">    readonly age:<span class="built_in">number</span>  <span class="comment">// 只读属性</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> obj:Inf;</span><br><span class="line">obj = &#123;name:<span class="string">"ring"</span>, age:<span class="number">10</span>, sex:man&#125;</span><br></pre></td></tr></table></figure>

<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>类型方括号</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> arr:<span class="built_in">number</span>[] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">var</span> arr2:<span class="built_in">any</span>[] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<p>泛型定义法</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> arr:<span class="built_in">Array</span>&lt;<span class="built_in">number</span>&gt; = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">var</span> arr2:<span class="built_in">Array</span>&lt;<span class="built_in">any</span>&gt; = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<p>接口定义法</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> IArr&#123;</span><br><span class="line">    [index:<span class="built_in">number</span>]:<span class="built_in">number</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> arr:IArr = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 类型除了是内置的类型, 还可以是接口的类型</span></span><br><span class="line"><span class="keyword">interface</span> Istate&#123;</span><br><span class="line">    name:<span class="built_in">string</span>,</span><br><span class="line">    age:<span class="built_in">number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> IArr&#123;</span><br><span class="line">    [index:<span class="built_in">number</span>]:Istate</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> arr:IArr = [&#123;name:<span class="string">"ring"</span>, age:<span class="number">20</span>&#125;]</span><br><span class="line"><span class="keyword">var</span> arr:<span class="built_in">Array</span>&lt;IArr&gt; = [&#123;name:<span class="string">"ring"</span>, age:<span class="number">20</span>&#125;]</span><br><span class="line"><span class="keyword">var</span> arr:Istate[] = [&#123;name:<span class="string">"ring"</span>, age:<span class="number">20</span>&#125;]</span><br></pre></td></tr></table></figure>

<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>声明式函数</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 函数名 参数名:类型  :返回类型</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">name:<span class="built_in">string</span>, age:<span class="built_in">number</span></span>):<span class="title">number</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> age:<span class="built_in">number</span> = func(<span class="string">"ring"</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p>函数参数不确定</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">name:<span class="built_in">string</span>, age:<span class="built_in">number</span>, sex?:<span class="built_in">string</span></span>):<span class="title">number</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> age:<span class="built_in">number</span> = func(<span class="string">"ring"</span>, <span class="number">20</span>, <span class="string">"man"</span>)</span><br></pre></td></tr></table></figure>

<p>参数默认值</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">name:<span class="built_in">string</span>, age:<span class="built_in">number</span>, sex?:<span class="built_in">string</span>="man"</span>):<span class="title">number</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> age:<span class="built_in">number</span> = func(<span class="string">"ring"</span>, <span class="number">20</span>, <span class="string">"man"</span>)</span><br></pre></td></tr></table></figure>

<p>表达式类型函数</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> func = <span class="function"><span class="keyword">function</span>(<span class="params">name:<span class="built_in">string</span>, age:<span class="built_in">number</span></span>):<span class="title">number</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> age:<span class="built_in">number</span> = func(<span class="string">"ring"</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p>表达式类型函数变量的约束规范</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 变量  约束  类型</span></span><br><span class="line"><span class="keyword">var</span> func:<span class="function">(<span class="params">name:<span class="built_in">string</span>, age:<span class="built_in">number</span></span>)=&gt;</span><span class="built_in">number</span> = <span class="function"><span class="keyword">function</span>(<span class="params">name:<span class="built_in">string</span>, age:<span class="built_in">number</span></span>):<span class="title">number</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> age:<span class="built_in">number</span> = func(<span class="string">"ring"</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者使用接口</span></span><br><span class="line"><span class="keyword">interface</span> Istate&#123;</span><br><span class="line">    (name:<span class="built_in">string</span>, age:<span class="built_in">number</span>):<span class="built_in">number</span>  <span class="comment">// (参数):返回类型</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> func:Istate = <span class="function"><span class="keyword">function</span>(<span class="params">name:<span class="built_in">string</span>, age:<span class="built_in">number</span></span>):<span class="title">number</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> age:<span class="built_in">number</span> = func(<span class="string">"ring"</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<p>采用重载的方式支持联合类型的函数关系</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">value:<span class="built_in">string</span></span>):<span class="title">string</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">value:<span class="built_in">number</span></span>):<span class="title">number</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">value:<span class="built_in">string</span>|<span class="built_in">number</span></span>)</span>&#123;  <span class="comment">// 这是上面的实现</span></span><br><span class="line">    <span class="keyword">return</span> value</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> a:<span class="built_in">number</span> = func(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">let</span> b:<span class="built_in">string</span> = func(<span class="string">"1"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="类型断言"><a href="#类型断言" class="headerlink" title="类型断言"></a>类型断言</h3><p>在联合类型的情况下, 调用的函数要是共有的函数, 不然会报错, 所以需要进行断言</p>
<p>&lt;类型&gt;值 或 值as类型</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">name:<span class="built_in">string</span>|<span class="built_in">number</span></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (&lt;<span class="built_in">string</span>&gt;name).length()</span><br><span class="line">    <span class="comment">// 或者return (name as string).length()</span></span><br><span class="line">    <span class="comment">// 只能转换成联合类型中存在的类型</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// !! jsx/tsx中必须采用后一种 !!</span></span><br></pre></td></tr></table></figure>

<h3 id="类型别名"><a href="#类型别名" class="headerlink" title="类型别名"></a>类型别名</h3><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> strtype = <span class="built_in">string</span>|<span class="built_in">number</span>;</span><br><span class="line"><span class="keyword">var</span> str:strtype = <span class="string">"10"</span></span><br><span class="line">str = <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>对于接口</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> muchType1&#123;</span><br><span class="line">    name:<span class="built_in">string</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">interface</span> muchType2&#123;</span><br><span class="line">    age:<span class="built_in">number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> muchType = muchType1|muchType2</span><br><span class="line"><span class="keyword">var</span> obj1:muchType = &#123;name:<span class="string">"ring"</span>&#125;</span><br><span class="line"><span class="keyword">var</span> obj2:muchType = &#123;age:<span class="number">1</span>&#125;</span><br><span class="line"><span class="keyword">var</span> obj3:muchType = &#123;name:<span class="string">"ring"</span>, age:<span class="number">1</span>&#125;  <span class="comment">// 一种或多种或全部</span></span><br></pre></td></tr></table></figure>

<p>限制字符串的选择</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> sex = <span class="string">"man"</span>|<span class="string">"woman"</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>(<span class="params">s:sex</span>):<span class="title">string</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line">&#125;</span><br><span class="line">func(<span class="string">"man"</span>)</span><br><span class="line"><span class="comment">// func("an") 就不行</span></span><br></pre></td></tr></table></figure>

<h3 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h3><p>使用枚举可以定义一些有名字的数字常量</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Days&#123;</span><br><span class="line">    Sun,  <span class="comment">// 默认第一个取值为0</span></span><br><span class="line">    Mon,  <span class="comment">// 后面的一次累加</span></span><br><span class="line">    Tue,</span><br><span class="line">    Wed,</span><br><span class="line">    Thu,</span><br><span class="line">    Fri,</span><br><span class="line">    Sat,</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">console</span>.log(Days.Sun)</span><br></pre></td></tr></table></figure>

<p>typescript枚举出来会自动赋值外, 同时会对枚举值到枚举名的反向映射, 就是变成了双向映射</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ts编译成js后的结果</span></span><br><span class="line"><span class="comment">// 即Days[0] = "Sun"</span></span><br><span class="line"><span class="keyword">var</span> Days;</span><br><span class="line">(<span class="function"><span class="keyword">function</span> (<span class="params">Days</span>) </span>&#123;</span><br><span class="line">    Days[Days[<span class="string">"Sun"</span>] = <span class="number">0</span>] = <span class="string">"Sun"</span>;</span><br><span class="line">    Days[Days[<span class="string">"Mon"</span>] = <span class="number">1</span>] = <span class="string">"Mon"</span>;</span><br><span class="line">    Days[Days[<span class="string">"Tue"</span>] = <span class="number">2</span>] = <span class="string">"Tue"</span>;</span><br><span class="line">    Days[Days[<span class="string">"Wed"</span>] = <span class="number">3</span>] = <span class="string">"Wed"</span>;</span><br><span class="line">    Days[Days[<span class="string">"Thu"</span>] = <span class="number">4</span>] = <span class="string">"Thu"</span>;</span><br><span class="line">    Days[Days[<span class="string">"Fri"</span>] = <span class="number">5</span>] = <span class="string">"Fri"</span>;</span><br><span class="line">    Days[Days[<span class="string">"Sat"</span>] = <span class="number">6</span>] = <span class="string">"Sat"</span>;</span><br><span class="line">&#125;)(Days || (Days = &#123;&#125;));</span><br><span class="line"><span class="built_in">console</span>.log(Days.Sun);</span><br></pre></td></tr></table></figure>

<h3 id="类的修饰符"><a href="#类的修饰符" class="headerlink" title="类的修饰符"></a>类的修饰符</h3><p>public private protected</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Person&#123;</span><br><span class="line">    name = <span class="string">"ring"</span>,</span><br><span class="line">    <span class="keyword">private</span> age = <span class="number">20</span>,</span><br><span class="line">    <span class="keyword">protected</span> say()&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">"halo"</span>)</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 没有修饰的话, 类中的属性后方法默认是public</span></span><br><span class="line"><span class="comment">// private 属性只能在类中被访问</span></span><br><span class="line"><span class="comment">// protected 只能在类及其子类中访问</span></span><br></pre></td></tr></table></figure>

<p>类的继承</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Child <span class="keyword">extends</span> Person&#123;</span><br><span class="line">    callParent()&#123;</span><br><span class="line">        <span class="keyword">super</span>.say()  <span class="comment">// super能拿到父类的对象, 所以能访问父类公开的属性和方法</span></span><br><span class="line">        <span class="comment">// 类中也能访问父类protected的方法, 类外就不行</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>静态方法, 可以通过类名调用</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Child <span class="keyword">extends</span> Person&#123;</span><br><span class="line">    callParent()&#123;</span><br><span class="line">        <span class="keyword">super</span>.say()  </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">static</span> test()&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">"halo"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(Child.test())  <span class="comment">// 但在静态方法中不可以使用this</span></span><br></pre></td></tr></table></figure>

<h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><p>泛型是指在定义函数, 接口或类的时候, 不预先指定具体类型, 而在使用的时候再指定类型的一种特性.<br>也可以帮助我们限定约束规范</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 用T来统一类型, T可以是任何名字</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">func</span>&lt;<span class="title">T</span>&gt;(<span class="params">len:<span class="built_in">number</span>, value:&lt;T&gt;</span>):<span class="title">Array</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">let</span> arr = []</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>;i&lt;len;<span class="number">1</span>++)&#123;</span><br><span class="line">        arr[i] = value</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> arr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> strArry: <span class="built_in">string</span>[] = func&lt;<span class="built_in">string</span>&gt;(<span class="number">3</span>, <span class="string">'1'</span>)  <span class="comment">// 制定类型为string</span></span><br><span class="line"><span class="keyword">var</span> numArry: <span class="built_in">number</span>[] = func(<span class="number">3</span>, <span class="number">1</span>)  <span class="comment">// 右边也可以不指定类型, 因为左边要求就收的是number, 所以它会反推</span></span><br></pre></td></tr></table></figure>

<p>接口采用泛型</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Istate&#123;</span><br><span class="line">    &lt;T&gt;(name:<span class="built_in">string</span>, value:T):<span class="built_in">Array</span>&lt;T&gt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> func:Istate;</span><br><span class="line"><span class="comment">// 接口约束函数返回值</span></span><br><span class="line">func = <span class="function"><span class="keyword">function</span>&lt;<span class="title">T</span>&gt;(<span class="params">name:<span class="built_in">string</span>, value:T</span>):<span class="title">Array</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> []</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用时指定类型</span></span><br><span class="line"><span class="keyword">var</span> strArry:<span class="built_in">string</span> [] = func(<span class="string">"ring"</span>, <span class="string">"2020"</span>)  <span class="comment">// 2020就指定了类型是string</span></span><br><span class="line"><span class="keyword">var</span> numArry:<span class="built_in">number</span> [] = func(<span class="string">"ring"</span>, <span class="number">2020</span>)  <span class="comment">// 同理</span></span><br></pre></td></tr></table></figure>










      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/28/universe/python_tips/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/28/universe/python_tips/" class="post-title-link" itemprop="url">Python Tips</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-28 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-28T00:00:00+08:00">2020-02-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-15 12:01:46" itemprop="dateModified" datetime="2020-04-15T12:01:46+08:00">2020-04-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="装饰器-Decorator"><a href="#装饰器-Decorator" class="headerlink" title="装饰器(Decorator)"></a>装饰器(Decorator)</h3><p>有时候我们需要进行一下重复的过程, 比如计算函数用时. 如果我们直接吧逻辑写在函数内部, 逻辑混乱且可读性不高.<br>这时我们就可以使用装饰器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a_new_decorator</span><span class="params">(a_func)</span>:</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapTheFunction</span><span class="params">(*args)</span>:</span>  <span class="comment"># 包装的函数有很多参数时用*args代替</span></span><br><span class="line">        <span class="comment"># commands</span></span><br><span class="line">        result = a_func()  <span class="comment"># result接收了包装函数返回的结果</span></span><br><span class="line">        <span class="comment"># commands</span></span><br><span class="line">        <span class="comment"># return or not</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> wrapTheFunction</span><br></pre></td></tr></table></figure>

<h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Decorator</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(*args)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/26/universe/how_to_makefile/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/26/universe/how_to_makefile/" class="post-title-link" itemprop="url">How to makefile</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-26 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-26T00:00:00+08:00">2020-02-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-15 12:00:25" itemprop="dateModified" datetime="2020-04-15T12:00:25+08:00">2020-04-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="How-to-makefile"><a href="#How-to-makefile" class="headerlink" title="How to makefile"></a>How to makefile</h1><h2 id="Compile-process"><a href="#Compile-process" class="headerlink" title="Compile process"></a>Compile process</h2><p>How dose a project turn into an excutable file? There are four step:</p>
<ul>
<li>Preprocessing<ul>
<li>Unfold all include libs, macro, head. And produce <code>.i</code> file.</li>
<li>(gcc/g++ commands)<code>-E</code></li>
</ul>
</li>
<li>Compilation<ul>
<li>The <code>.i</code> file produce an <code>.s</code> file(assembly code).</li>
<li><code>-S</code></li>
</ul>
</li>
<li>Assemble<ul>
<li>The <code>.s</code> file produce an <code>.o</code> file(object file).It is a binary file.</li>
<li><code>-c</code></li>
</ul>
</li>
<li>Linking<ul>
<li>Linking the <code>.o</code> file produce an excutable file.</li>
</ul>
</li>
</ul>
<p>Whole example</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gcc -E halo.c -o halo.i  </span><br><span class="line">gcc -S halo.i -o halo.s  </span><br><span class="line">gcc -c halo.s -o halo.o  </span><br><span class="line">gcc -o halo.o -o halo</span><br></pre></td></tr></table></figure>

<h2 id="Why-makefile"><a href="#Why-makefile" class="headerlink" title="Why makefile"></a>Why makefile</h2><p>As we see, compile a file include so much process.Though <code>gcc halo.c -o halo</code> can do the same thing as above, you need to make sure all the <code>.c</code> file are in the directory.<br>And what if a thousand file to compile?</p>
<h2 id="Lets-start"><a href="#Lets-start" class="headerlink" title="Lets start"></a>Lets start</h2><h3 id="Format"><a href="#Format" class="headerlink" title="Format"></a>Format</h3><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">target: dependencies</span></span><br><span class="line">    command</span><br><span class="line"></span><br><span class="line">^ before command IS A TAB, and make sure a new line at the end</span><br></pre></td></tr></table></figure>
<p>We should write “from rear to front”. Which means write final target command first and then write dependencies commandS</p>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make target...</span><br></pre></td></tr></table></figure>

<p>If didn’t specify target, run the first target as default. That is why should we wirte main object at first.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/26/universe/vim_in_action/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/26/universe/vim_in_action/" class="post-title-link" itemprop="url">vim实用技巧</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-26 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-26T00:00:00+08:00">2020-02-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-24 20:34:52" itemprop="dateModified" datetime="2020-05-24T20:34:52+08:00">2020-05-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Vim实用技巧"><a href="#Vim实用技巧" class="headerlink" title="Vim实用技巧"></a>Vim实用技巧</h1><h2 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h2><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>o</td>
<td>切换高亮中光标所在的端点</td>
</tr>
<tr>
<td>.</td>
<td>重复执行上一步操作</td>
</tr>
<tr>
<td>%</td>
<td>它代表当前文件中的所有行</td>
</tr>
<tr>
<td>%</td>
<td>可以在一组开, 闭括号间跳转</td>
</tr>
<tr>
<td>m{mark}</td>
<td>当前位置标记为{mark}以便以后跳转</td>
</tr>
<tr>
<td>`{mark}</td>
<td>跳到{mark}标记处</td>
</tr>
<tr>
<td>qa</td>
<td>录制宏到寄存器a</td>
</tr>
<tr>
<td>qA</td>
<td>往寄存器a中追加操作</td>
</tr>
</tbody></table>
<h2 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h2><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>*</td>
<td>向下查找光标停靠的词语</td>
</tr>
<tr>
<td>#</td>
<td>向上查找</td>
</tr>
<tr>
<td>;</td>
<td>重复上一次查找</td>
</tr>
<tr>
<td>,</td>
<td>反转方向重复上一次查找</td>
</tr>
<tr>
<td>\ze和\ze</td>
<td>匹配界定符, 匹配边界</td>
</tr>
</tbody></table>
<h3 id="按正则表达式查找"><a href="#按正则表达式查找" class="headerlink" title="按正则表达式查找"></a>按正则表达式查找</h3><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>\v</td>
<td>使用正则的特殊符号规则</td>
</tr>
<tr>
<td>\V</td>
<td>原意查找, 即.啊什么的不用反斜转意</td>
</tr>
<tr>
<td>\w</td>
<td>用来匹配单词类字符, 包括字母,数字及符号</td>
</tr>
<tr>
<td>\W</td>
<td>匹配单词类以外的所有字符</td>
</tr>
<tr>
<td>\{num}</td>
<td>引用被没对()捕获的子匹配 \0会引用整个匹配</td>
</tr>
<tr>
<td>&lt;和&gt;</td>
<td>\v模式中&lt;和&gt;用来匹配边界</td>
</tr>
</tbody></table>
<h2 id="操作符-动作-操作"><a href="#操作符-动作-操作" class="headerlink" title="操作符 + 动作 = 操作"></a>操作符 + 动作 = 操作</h2><h3 id="操作符"><a href="#操作符" class="headerlink" title="操作符"></a>操作符</h3><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>c</td>
<td>修改</td>
</tr>
<tr>
<td>d</td>
<td>删除</td>
</tr>
<tr>
<td>y</td>
<td>复制到寄存器</td>
</tr>
<tr>
<td>g~</td>
<td>反转大小写</td>
</tr>
<tr>
<td>gu</td>
<td>反转为小写</td>
</tr>
<tr>
<td>gU</td>
<td>反转为大写</td>
</tr>
<tr>
<td>&gt;</td>
<td>增加缩进</td>
</tr>
<tr>
<td>&lt;</td>
<td>减小缩进</td>
</tr>
<tr>
<td>=</td>
<td>自动缩进</td>
</tr>
<tr>
<td>!</td>
<td>使用外部程序</td>
</tr>
</tbody></table>
<h3 id="动作"><a href="#动作" class="headerlink" title="动作"></a>动作</h3><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>w</td>
<td>向后一个单词</td>
</tr>
<tr>
<td>W</td>
<td>当前字串</td>
</tr>
<tr>
<td>aw</td>
<td>a word, 光标停靠的整个单词及一个空格</td>
</tr>
<tr>
<td>ab</td>
<td>一对圆括号</td>
</tr>
<tr>
<td>aB</td>
<td>一对花括号</td>
</tr>
<tr>
<td>t</td>
<td>to 到</td>
</tr>
<tr>
<td>i”</td>
<td>inside 在””中</td>
</tr>
<tr>
<td>it</td>
<td>inside tag <h1></h1></td>
</tr>
<tr>
<td>p</td>
<td>段落</td>
</tr>
<tr>
<td>s</td>
<td>句子</td>
</tr>
<tr>
<td>@a</td>
<td>宏a</td>
</tr>
</tbody></table>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>caw</td>
<td>修改当期单词</td>
</tr>
<tr>
<td>dta</td>
<td>删除当前位置到字母啊</td>
</tr>
<tr>
<td>以此类推</td>
<td></td>
</tr>
</tbody></table>
<h2 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h2><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>“{register}</td>
<td>制定寄存器{register}</td>
</tr>
<tr>
<td>“”</td>
<td>无名寄存器, 没指定寄存器情况下缺省使用</td>
</tr>
<tr>
<td>“0</td>
<td>复制专用寄存器</td>
</tr>
<tr>
<td>“_</td>
<td>黑洞寄存器, 有去无回</td>
</tr>
<tr>
<td>“+</td>
<td>X11剪贴板</td>
</tr>
<tr>
<td>&lt;C-r&gt;{register}</td>
<td>在在插入模式下插入寄存器内容</td>
</tr>
<tr>
<td>:reg a</td>
<td>查看寄存器a</td>
</tr>
<tr>
<td>等等</td>
<td></td>
</tr>
</tbody></table>
<h2 id="Shell命令"><a href="#Shell命令" class="headerlink" title="Shell命令"></a>Shell命令</h2><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>%</td>
<td>命令行中的%会展开成当前文件的完整路径</td>
</tr>
<tr>
<td>:shell</td>
<td>启动一个shell(输入exit返回vim)</td>
</tr>
<tr>
<td>:!{cmd}</td>
<td>在shell中执行{cmd}</td>
</tr>
<tr>
<td>:read !{cmd}</td>
<td>把{cmd}的标准输出插入到光标下方</td>
</tr>
<tr>
<td>:[range]write !{cmd}</td>
<td>以[range]作为{cmd}的标准输入</td>
</tr>
</tbody></table>
<h2 id="分屏操作"><a href="#分屏操作" class="headerlink" title="分屏操作"></a>分屏操作</h2><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>&lt;C-w&gt;=</td>
<td>使得所有窗口等宽, 登高</td>
</tr>
<tr>
<td>&lt;C-w&gt;_</td>
<td>最大化活动窗口的高度</td>
</tr>
<tr>
<td>&lt;C-w&gt;|</td>
<td>最大化活动窗口的宽度</td>
</tr>
<tr>
<td>&lt;C-w&gt;方向</td>
<td>移动光标所在的窗口</td>
</tr>
</tbody></table>
<h2 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h2><table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>虚拟行, 位于第一行上方</td>
</tr>
<tr>
<td>1</td>
<td>文件第一行</td>
</tr>
<tr>
<td>$</td>
<td>最后一行</td>
</tr>
<tr>
<td>.</td>
<td>光标所在行</td>
</tr>
<tr>
<td>‘m</td>
<td>包含位置标记m的行</td>
</tr>
<tr>
<td>‘&lt;</td>
<td>高亮选取的起始行</td>
</tr>
<tr>
<td>‘&gt;</td>
<td>高亮选取的结束行</td>
</tr>
<tr>
<td>%</td>
<td>整个文件</td>
</tr>
</tbody></table>
<h2 id="宏"><a href="#宏" class="headerlink" title="宏"></a>宏</h2><p>录制宏其实是把操作过程放入了一个寄存器中，如<code>qq</code>就是用寄存器q来录制宏。用<code>:reg q</code>可以查看内容。</p>
<ul>
<li><code>qq</code>：用寄存器q录制宏</li>
<li><code>qQ</code>:往寄存器q中追加操作</li>
<li><code>:put q</code>：把寄存器q的内容粘贴到文档，以便修改</li>
<li><code>:d q</code>：复制回寄存器</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/25/universe/GDB_Usage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/universe/GDB_Usage/" class="post-title-link" itemprop="url">GDB usage</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-25 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-25T00:00:00+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-16 22:18:21" itemprop="dateModified" datetime="2020-05-16T22:18:21+08:00">2020-05-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Basic-Usage"><a href="#Basic-Usage" class="headerlink" title="Basic Usage"></a>Basic Usage</h1><ul>
<li>Make sure compile file with <code>-g</code> option, which mean turn on debugging with gdb<ul>
<li>like this: <code>gcc -g main.cpp -o main</code></li>
</ul>
</li>
</ul>
<h2 id="Debugging-with-GDB"><a href="#Debugging-with-GDB" class="headerlink" title="Debugging with GDB"></a>Debugging with GDB</h2><ul>
<li>open file<ul>
<li>here are two way</li>
<li><code>gdb filename</code><ul>
<li><code>gdb path/to/main</code></li>
</ul>
</li>
<li><code>gdb</code> -&gt; <code>file path/to/main</code></li>
</ul>
</li>
<li>show list<ul>
<li>use <code>l</code> command to show source code with line number</li>
</ul>
</li>
<li>add breakpoint<ul>
<li>use <code>b linenum</code> to add breakpoint, such as <code>b 1</code> add breakpoint at line 1</li>
<li>or use <code>b functionname</code> to add breakpoint, such as <code>b main</code> add breakpoint at main function</li>
</ul>
</li>
<li>show breakpoint information<ul>
<li><code>i b</code> i for information, b for breakpoint</li>
</ul>
</li>
<li>delete breakpoint<ul>
<li><code>d pointid</code> pointid from <code>i b</code></li>
<li><code>i b</code> information will be like a order list. If delete a pointid in the previous, the next point will just add in the end of the idlist.</li>
</ul>
</li>
<li>run debug<ul>
<li><code>r</code></li>
<li>use <code>p variable</code> will show the variable information</li>
</ul>
</li>
<li>gdb controler<ul>
<li><code>n</code> for next line, one step debugging</li>
<li><code>s</code> for step into(one step)</li>
<li><code>set args [parameter]</code> for command line args</li>
</ul>
</li>
<li>finish function and continue<ul>
<li><code>finish</code> for finish function</li>
<li><code>c</code> for continue until program exit or breakpoint</li>
</ul>
</li>
<li>quit gdb<ul>
<li><code>q</code></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/25/universe/linux%E5%93%B2%E5%AD%A6%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/universe/linux%E5%93%B2%E5%AD%A6%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">Linux哲学记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-25 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-25T00:00:00+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-15 12:01:02" itemprop="dateModified" datetime="2020-04-15T12:01:02+08:00">2020-04-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="开发效率问题"><a href="#开发效率问题" class="headerlink" title="开发效率问题"></a>开发效率问题</h4><p><strong>闭源</strong> </p>
<p>在一个项目开发中<br>假设一个人开发效率是100%, 因为他能全身心投入项目中. 两个人每个人的开发效率是80%, 其中20%是因为另一个人损耗的沟通成本, 那么两个人的效率就像一个人的160%.<br>但是如果人数增加, 每个人的沟通成本也会增加, 最后发现效率降低. 所以一个多人开发的大型项目理论上是不可能成功的.</p>
<p>那么框架, 框架的扩展性就显得尤其重要.</p>
<p><strong>开源</strong></p>
<p>一个开源项目往往有成百上千的人参与, 那根据上面的理论, 一个开源项目就不会成功.<br>但是当人数多到一定程度的时候, 一个潜在的错误一旦出现就会立刻得到解决, 反而大大提高了效率.<br>但是当人数多到一定程度的时候, 已经不在上面理论的范畴之内了, 就像物理世界的<strong>宏观和微观问题</strong>.<br>在多人开发的开源项目中的理论就遵循<em>linus</em> 提出的<strong>linus理论</strong>. 开源项目的成功就足以证明其正确性.</p>
<h4 id="开源程序的责任"><a href="#开源程序的责任" class="headerlink" title="开源程序的责任"></a>开源程序的责任</h4><p>一个开源程序往往有一个开源协议, 这些协议往往把责任只想广大社区的开发者, 也就是我们自己.<br>所以我们获取的开源软件我们自己, 我们广大开发者就要对其负责.</p>
<p>举个例子:比如你找学霸抄作业, 但是抄来的答案全是错是, 你该怪学霸吗?<br>于是你在抄之前, 问了一下别人是不是也抄了学霸的作业, 别人告诉你说没问题, 或者你检查了一遍发现没问题. 那社区就保证了它的安全性.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/23/universe/linux_tips/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/23/universe/linux_tips/" class="post-title-link" itemprop="url">linux command line</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-23 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-23T00:00:00+08:00">2020-02-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-20 17:24:53" itemprop="dateModified" datetime="2020-05-20T17:24:53+08:00">2020-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Command-line"><a href="#Command-line" class="headerlink" title="Command line"></a>Command line</h1><h2 id="shebang"><a href="#shebang" class="headerlink" title="shebang"></a>shebang</h2><p>a shebang is the interpreter of this script. like this</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br></pre></td></tr></table></figure>

<h2 id="Redirection"><a href="#Redirection" class="headerlink" title="Redirection"></a>Redirection</h2><table>
<thead>
<tr>
<th>command</th>
<th>function</th>
</tr>
</thead>
<tbody><tr>
<td>a &gt; b</td>
<td>a’s std output override into b</td>
</tr>
<tr>
<td>a &gt;&gt; b</td>
<td>a’s std output appand into b</td>
</tr>
<tr>
<td>a &lt; b</td>
<td>b as a’s input</td>
</tr>
<tr>
<td>a &lt;&lt; b</td>
<td>here document</td>
</tr>
<tr>
<td>a &lt;&lt;&lt; b</td>
<td>here</td>
</tr>
</tbody></table>
<h3 id="Here-document"><a href="#Here-document" class="headerlink" title="Here document"></a>Here document</h3><p>A block as input</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> &lt;&lt; token</span><br><span class="line">    text</span><br><span class="line">token</span><br><span class="line"></span><br><span class="line">example:</span><br><span class="line"><span class="built_in">echo</span> &lt;&lt; __EOF__</span><br><span class="line">halo</span><br><span class="line">__EOF__</span><br><span class="line"></span><br><span class="line">$ halo</span><br></pre></td></tr></table></figure>

<h3 id="Here"><a href="#Here" class="headerlink" title="Here"></a>Here</h3><p>a bit like <em>here document</em>, a line as input.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">read</span> ans1 ans2 ans3 &lt;&lt;&lt; <span class="string">"a1 a2 a3"</span></span><br><span class="line"></span><br><span class="line">a1 a2 a3 as input to <span class="built_in">read</span> process</span><br></pre></td></tr></table></figure>

<h2 id="Useful-commands"><a href="#Useful-commands" class="headerlink" title="Useful commands"></a>Useful commands</h2><h3 id="Grep"><a href="#Grep" class="headerlink" title="Grep"></a>Grep</h3><p><code>grep [option] file1 file2...</code></p>
<p>The most commonly used<br>| options  | description                    |<br>|———-|——————————–|<br>| -i       | –ignore-case                  |<br>| -v       | –revert-mathch                |<br>| -c       | –count                        |<br>| -l       | –file-with-match              |<br>| -L       | –file-without-math            |<br>| -n       | –line-number                  |<br>| -h       | no filename in multi file mode |<br>| -a/-text | do not ignore binary data      |<br>| -e       | –regexp                       |<br>| -f       | specify regexp file            |</p>
<h3 id="Sed"><a href="#Sed" class="headerlink" title="Sed"></a>Sed</h3><p>sed can deal with text file with script-command or script-file.</p>
<p><code>sed [options][target-file]</code></p>
<table>
<thead>
<tr>
<th>options</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>-e</td>
<td></td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<p>script action</p>
<table>
<thead>
<tr>
<th>action</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>a\</td>
<td>add a new line or lines next to current line</td>
</tr>
<tr>
<td>c\</td>
<td>replace current line with some text</td>
</tr>
<tr>
<td>d</td>
<td>delete line</td>
</tr>
<tr>
<td>i\</td>
<td>insert text befor curent line</td>
</tr>
<tr>
<td>h</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>H</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>g</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>G</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>I</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>p</td>
<td>print line</td>
</tr>
<tr>
<td>n</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>q</td>
<td>quit sed</td>
</tr>
<tr>
<td>r</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>!</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>s</td>
<td>replace string with other string</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<p>replace identifier</p>
<table>
<thead>
<tr>
<th>options</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>g</td>
<td>global replace in this line</td>
</tr>
<tr>
<td>p</td>
<td>print line</td>
</tr>
<tr>
<td>w</td>
<td>write line into file</td>
</tr>
<tr>
<td>x</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>y</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<h3 id="Cut"><a href="#Cut" class="headerlink" title="Cut"></a>Cut</h3><table>
<thead>
<tr>
<th>options</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<h2 id="Regular-Expressions"><a href="#Regular-Expressions" class="headerlink" title="Regular Expressions"></a>Regular Expressions</h2><h3 id="Literals"><a href="#Literals" class="headerlink" title="Literals"></a>Literals</h3><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>.</td>
<td>match any char</td>
</tr>
<tr>
<td>char</td>
<td>literaly a char</td>
</tr>
</tbody></table>
<h3 id="Metacharacters"><a href="#Metacharacters" class="headerlink" title="Metacharacters"></a>Metacharacters</h3><h4 id="Anchors"><a href="#Anchors" class="headerlink" title="Anchors"></a>Anchors</h4><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>^</td>
<td>found at the begin of line</td>
</tr>
<tr>
<td>$</td>
<td>found at the end of line</td>
</tr>
</tbody></table>
<h4 id="Quantifiers"><a href="#Quantifiers" class="headerlink" title="Quantifiers"></a>Quantifiers</h4><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>?</td>
<td>match <strong>an element</strong> zero or one time</td>
</tr>
<tr>
<td>*</td>
<td>match <strong>an element</strong> zero or more times</td>
</tr>
<tr>
<td>+</td>
<td>match <strong>an element</strong> one or more times</td>
</tr>
<tr>
<td>{}</td>
<td>match <strong>an element</strong> a specific number of times</td>
</tr>
<tr>
<td>{n,}</td>
<td>match <strong>an element</strong> if it occurs n or more times</td>
</tr>
<tr>
<td>{,n}</td>
<td>match <strong>an element</strong> if it occurs no more than n times</td>
</tr>
</tbody></table>
<p>A quantifiers is after <strong>an element</strong>, such as <code>.*</code> means match any char with any lengh equivalent any string.</p>
<p>An element can like this <code>[A_Z]</code>and this<code>[:digit:]</code>. We can see the pattern before a quantifiers as a whole.</p>
<h4 id="Bracket-Expressions-and-Character-Classes"><a href="#Bracket-Expressions-and-Character-Classes" class="headerlink" title="Bracket Expressions and Character Classes"></a>Bracket Expressions and Character Classes</h4><ul>
<li><p>Bracket Expressions</p>
<ul>
<li>specify a set of characters to be match<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep -h <span class="string">'[bg]zip'</span> test.txt</span><br><span class="line">bzip2</span><br><span class="line">bzip123</span><br><span class="line">gzip</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Negation</p>
<ul>
<li>If the first char in a bracket expression is a caret(^), the <strong>remaining char</strong> are taken to be a set of chars that must not be present at the given char position.<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep -h <span class="string">'[^bg]zip'</span> test.txt</span><br><span class="line">bunzip</span><br><span class="line">gunzip</span><br><span class="line">funzip</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Character Classes</p>
<ul>
<li>A set of characters range<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ grep -h <span class="string">'[^ABCDEF]'</span> test.txt</span><br><span class="line">or you can</span><br><span class="line">$ grep -h <span class="string">'[^A-F]'</span> test.txt</span><br><span class="line"></span><br><span class="line">Here are more expressions</span><br><span class="line">$ grep -h <span class="string">'[A-Fa-z0-9]'</span> test.txt</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>POSIX Character Class</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>char</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>[:alnum:]</td>
<td>alphanumeric characters.equivalent to[A-Za-z0-9]</td>
</tr>
<tr>
<td>[:word:]</td>
<td>same as alnum, with the addition of the underscore char(_)</td>
</tr>
<tr>
<td>[:alpha:]</td>
<td>[A-Za-z]</td>
</tr>
<tr>
<td>[:blank:]</td>
<td>space and tab char</td>
</tr>
<tr>
<td>[:digit:]</td>
<td>number 0 through 9</td>
</tr>
<tr>
<td>[:lower:]</td>
<td>the lowercase letters</td>
</tr>
<tr>
<td>[:upper:]</td>
<td>the uppercase letters</td>
</tr>
<tr>
<td>[:space:]</td>
<td>[\t\r\n\v\f]</td>
</tr>
<tr>
<td>[:xdigit:]</td>
<td>chars used to express hexadecimal numbers.[0-9a-fA-F]</td>
</tr>
</tbody></table>
<h2 id="Flow-control"><a href="#Flow-control" class="headerlink" title="Flow control"></a>Flow control</h2><h3 id="if-statements"><a href="#if-statements" class="headerlink" title="if statements"></a>if statements</h3><h4 id="File-Expressions"><a href="#File-Expressions" class="headerlink" title="File Expressions"></a>File Expressions</h4><table>
<thead>
<tr>
<th>command</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>f1 -ef f2</td>
<td>f1 and f2 have the same indoe number</td>
</tr>
<tr>
<td>f1 -nt f2</td>
<td>f1 newer than f2</td>
</tr>
<tr>
<td>f1 -ot f2</td>
<td>f1 older than f2</td>
</tr>
<tr>
<td>-d f1</td>
<td>f1 exists an is a directory</td>
</tr>
<tr>
<td>-e f1</td>
<td>f1 exists</td>
</tr>
<tr>
<td>-f f1</td>
<td>f1 is a regular file</td>
</tr>
</tbody></table>
<h4 id="String-Expressions"><a href="#String-Expressions" class="headerlink" title="String Expressions"></a>String Expressions</h4><table>
<thead>
<tr>
<th>command</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>string</td>
<td>string is not null</td>
</tr>
<tr>
<td>-n string</td>
<td>the lenth of string is greater than zero</td>
</tr>
<tr>
<td>-z string</td>
<td>the lenth of string is zero</td>
</tr>
<tr>
<td>s1 = s2 or s1 == s2</td>
<td>equal</td>
</tr>
<tr>
<td>s1 !=s2</td>
<td>not equal</td>
</tr>
<tr>
<td>s1 &gt; s2</td>
<td>s1 sorts after s2</td>
</tr>
<tr>
<td>s1 &lt; s2</td>
<td>s1 sortf before s2</td>
</tr>
</tbody></table>
<h4 id="Integer-Expressions"><a href="#Integer-Expressions" class="headerlink" title="Integer Expressions"></a>Integer Expressions</h4><table>
<thead>
<tr>
<th>command</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>int1 -eq int2</td>
<td>equal</td>
</tr>
<tr>
<td>int1 -ne int2</td>
<td>not equal</td>
</tr>
<tr>
<td>-le</td>
<td>less or equal</td>
</tr>
<tr>
<td>-lt</td>
<td>less than</td>
</tr>
<tr>
<td>-ge</td>
<td>greater or equal</td>
</tr>
<tr>
<td>-gt</td>
<td>greater</td>
</tr>
</tbody></table>
<h4 id="A-More-Modern-Version-of-test"><a href="#A-More-Modern-Version-of-test" class="headerlink" title="A More Modern Version of test"></a>A More Modern Version of test</h4><ul>
<li><strong>Designed of string</strong><ul>
<li><code>[[ command ]]</code></li>
</ul>
</li>
</ul>
<p>and here is a new feature:<br><code>string1 =~ regex</code>. This return true if string1 matched by the extended regular expression</p>
<ul>
<li><strong>Designed of Integer</strong><ul>
<li>`(( command ))</li>
<li>integer only</li>
</ul>
</li>
</ul>
<h3 id="case"><a href="#case" class="headerlink" title="case"></a>case</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> word <span class="keyword">in</span></span><br><span class="line">    [pattern [| pattern]...) commands ;;]...</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$num</span> <span class="keyword">in</span></span><br><span class="line">    0) <span class="built_in">echo</span> <span class="string">"zero"</span></span><br><span class="line">        ;;  <span class="comment"># ;; break and out of case</span></span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<h4 id="pattern"><a href="#pattern" class="headerlink" title="pattern"></a>pattern</h4><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>a)</td>
<td>matches if word equals a</td>
</tr>
<tr>
<td>[[:alpha:]]</td>
<td>matches if word is a single alphabetic</td>
</tr>
<tr>
<td>???)</td>
<td>matches if word is exactly three characters long</td>
</tr>
<tr>
<td>*.txt</td>
<td>matches if word ends with .txt</td>
</tr>
<tr>
<td>*)</td>
<td>matches any value.</td>
</tr>
</tbody></table>
<h3 id="for-while-until"><a href="#for-while-until" class="headerlink" title="for/while/until"></a>for/while/until</h3><ul>
<li>for <ul>
<li><code>for variable in words; do commands done</code></li>
<li><code>for (( expression1; expression2; expression3 )); do commands done</code></li>
</ul>
</li>
<li>while <ul>
<li><code>while commands; do commands; done</code></li>
<li>while commands is true continue</li>
</ul>
</li>
<li>until <ul>
<li><code>until commands; do commands; done</code></li>
<li>while commands is false continue</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/10/Major/compuer_organization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/12/10/Major/compuer_organization/" class="post-title-link" itemprop="url">Computer Organization</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-12-10 00:00:00" itemprop="dateCreated datePublished" datetime="2019-12-10T00:00:00+08:00">2019-12-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-02 18:32:09" itemprop="dateModified" datetime="2020-05-02T18:32:09+08:00">2020-05-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h2><h3 id="2-2-浮点数的表示"><a href="#2-2-浮点数的表示" class="headerlink" title="2.2 浮点数的表示"></a>2.2 浮点数的表示</h3><ul>
<li>单精度IEEE754格式<ul>
<li>真值变二进制数</li>
<li>二进制数移位变成$(-1)^S \times{2^e} \times {1.M}$<ul>
<li>$E = e + 01111111$ 加上偏移量127得到E</li>
</ul>
</li>
<li>根据公式得到S,E,M后按照格式保存</li>
</ul>
</li>
</ul>
<h3 id="Representation-of-data"><a href="#Representation-of-data" class="headerlink" title="Representation of data"></a>Representation of data</h3><h4 id="Overflow-of-Complement"><a href="#Overflow-of-Complement" class="headerlink" title="Overflow of Complement"></a>Overflow of Complement</h4><p>If a complement calculations run out of scope, it overflow. So we need to be careful.</p>
<h2 id="Part-3"><a href="#Part-3" class="headerlink" title="Part.3"></a>Part.3</h2><h3 id="Cpu-Subsystem"><a href="#Cpu-Subsystem" class="headerlink" title="Cpu Subsystem"></a>Cpu Subsystem</h3><p>Major component</p>
<ul>
<li>Temporal parts</li>
<li>Control unit<ul>
<li>logic controler</li>
<li>program controler</li>
</ul>
</li>
<li>Cache, to balance cpu(hight speed) and register(low speed)</li>
<li>Register(heap)<ul>
<li>general register</li>
<li>temporary register</li>
<li>IR(instruction register)</li>
<li>PC(process counter)</li>
<li>PSW(program status register)</li>
<li>MAR(address register)</li>
<li>MBR(binary register)</li>
<li>SP(stack pointer)</li>
</ul>
</li>
<li>Arithmetic unit</li>
</ul>
<p>Control mode</p>
<ul>
<li>Synchronous</li>
<li>Asynchronous</li>
</ul>
<p>Instruction type</p>
<ul>
<li>CISC(Complex Instruction Set Computing)</li>
<li>RISC(Reduced Instruction Set Computing)</li>
<li>CISC-&gt;RISC</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/26/Major/arithmetic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/11/26/Major/arithmetic/" class="post-title-link" itemprop="url">算法学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-11-26 00:00:00" itemprop="dateCreated datePublished" datetime="2019-11-26T00:00:00+08:00">2019-11-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-02 18:32:18" itemprop="dateModified" datetime="2020-05-02T18:32:18+08:00">2020-05-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><ul>
<li>比较大小,如果符合条件(升序)就交换两个元素的位置  <ul>
<li>每次执行N-1次</li>
<li>严格大/小,保证了原序(稳定性)</li>
<li>没次能保证最大/最小的元素会在最后</li>
</ul>
</li>
<li>如果全程无交换,则说明有序了,跳出即可</li>
<li>$T=O(x),x\in(N,N^2)$</li>
</ul>
<h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><ul>
<li>每次抽取一个元素,然后从序列末尾开始进行比较</li>
<li>若符合条件,往后移位,直到不符合条件跳出</li>
<li>然后插入元素</li>
</ul>
<h4 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h4><p>对插入排序的改进,每次消除多个逆序对以达到加速的效果  </p>
<ul>
<li>按照一定增量序列,每次进行D排序 $D_N &gt; D_{N-1}…&gt;D_1$ ,这样一来一趟就有可能消除多个逆序对<ul>
<li>按照$D_N &gt; D_{N-1}…&gt;D_1$进行排序,后一次会保持前一次的顺序,故可用</li>
<li>但最终都要进行1排序</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(D=N/<span class="number">2</span>;D&gt;<span class="number">0</span>;D/=<span class="number">2</span>)&#123;  <span class="comment">// 希尔增量序列。Hibbard增量序列:Dk=2^k-1...等等</span></span><br><span class="line">    <span class="keyword">for</span>(p=D;p&lt;N;p++)&#123;  <span class="comment">// 插入排序</span></span><br><span class="line">        Tmp = A[p];</span><br><span class="line">        <span class="keyword">for</span>(i=p;i&gt;=D&amp;&amp;A[i-D]&gt;Tmp;i-=D)&#123;</span><br><span class="line">            A[i] = A[i-D];</span><br><span class="line">        &#125;</span><br><span class="line">        A[i] = Tmp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><h4 id="小-大顶堆"><a href="#小-大顶堆" class="headerlink" title="小/大顶堆"></a>小/大顶堆</h4><p>子节点比父节点小/大的二叉树  </p>
<p><strong>构建方法</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 法一：上浮下沉法(小顶堆为例)</span></span><br><span class="line"><span class="comment">// 从第一个非叶子节点开始，以它为子树，先自下而上把小的节点上浮，到达子树根节点后自上而下把大的节点下沉</span></span><br><span class="line"><span class="comment">// 知道根节点结束</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createHeap</span><span class="params">(<span class="keyword">int</span> *heap,<span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=len/<span class="number">2</span><span class="number">-1</span>;j&gt;=<span class="number">0</span>;j--)&#123;</span><br><span class="line">        <span class="keyword">int</span> t = j;</span><br><span class="line">        <span class="keyword">while</span>((t+<span class="number">1</span>)*<span class="number">2</span>&lt;=len)&#123;</span><br><span class="line">            <span class="keyword">int</span> <span class="built_in">min</span> = (t+<span class="number">1</span>)*<span class="number">2</span><span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">min</span>+<span class="number">1</span>&lt;len)&#123;</span><br><span class="line">                <span class="keyword">if</span>(heap[<span class="built_in">min</span>+<span class="number">1</span>]&lt;heap[<span class="built_in">min</span>])&#123;</span><br><span class="line">                    <span class="built_in">min</span>++; </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(heap[<span class="built_in">min</span>]&lt;heap[t])&#123;</span><br><span class="line">                swop(<span class="built_in">min</span>,t,heap);</span><br><span class="line">                t = <span class="built_in">min</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 法二：插入法</span></span><br><span class="line"><span class="comment">// 从根节点出发，若父节点比插入元素大，则调整位置，如此循环，保证父节点小于子节点</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createHeap</span><span class="params">(<span class="keyword">int</span> *heap,<span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">    heap[<span class="number">0</span>] = <span class="number">-1000</span>;</span><br><span class="line">    <span class="keyword">int</span> temp;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=len;i++)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;temp);</span><br><span class="line">        <span class="keyword">int</span> j;</span><br><span class="line">        <span class="keyword">for</span>(j=i;heap[j/<span class="number">2</span>]&gt;temp;j/=<span class="number">2</span>)&#123;</span><br><span class="line">            heap[j] = heap[j/<span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        heap[j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="利用小-大顶堆排序"><a href="#利用小-大顶堆排序" class="headerlink" title="利用小/大顶堆排序"></a>利用小/大顶堆排序</h4><ul>
<li>根据小/大顶堆的性质，可以确定顶部一定是最大或最小的元素</li>
<li>交换根节点和最后一个节点，那么最后一个节点一定是最大/最小</li>
<li>把最后的节点排除，剩下节点构成的子树再调整成小/大顶堆，重复以上步骤</li>
</ul>
<h3 id="快速排序算法"><a href="#快速排序算法" class="headerlink" title="快速排序算法"></a>快速排序算法</h3><p>通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列    </p>
<ul>
<li>先从数列中取出一个数作为主元<ul>
<li>主元选不好会影响速度</li>
<li>法1.选头,中,尾三个数的中位数做主元</li>
</ul>
</li>
<li>分区过程，交替移动，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边</li>
<li>再对左右区间重复第二步，直到各区间只有一个数</li>
</ul>
<h3 id="擂台法"><a href="#擂台法" class="headerlink" title="擂台法"></a>擂台法</h3><ul>
<li>适用于找最值</li>
</ul>
<h3 id="归并法"><a href="#归并法" class="headerlink" title="归并法"></a>归并法</h3><ul>
<li>把两个有序的序列合并</li>
<li>法1.递归的进行下去(有点类似快速排序)</li>
<li>法2.每个元素看成一段序列,合并合并…</li>
<li>$T=N\log{N}$</li>
<li>缺点:需要开额外一份空间</li>
</ul>
<h2 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h2><h3 id="AOV-activity-on-vertex"><a href="#AOV-activity-on-vertex" class="headerlink" title="AOV(activity on vertex)"></a>AOV(activity on vertex)</h3><p>节点代表事件<br>若v到w连通,则v一定在w的前面  </p>
<ul>
<li>有向图</li>
<li>有优先级限制<br>按照此法输出就是拓扑排序  </li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Queuezero Q;   <span class="comment">// 储存入度为零的,即前头没有限制了的</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;|V|;i++)&#123;    <span class="comment">// 记录最先的入度为0的节点</span></span><br><span class="line">    <span class="keyword">if</span>(indegree[V]==<span class="number">0</span>)&#123;</span><br><span class="line">        Enqueue(V,Q);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span>(!isEmpty(Q))&#123;</span><br><span class="line">    V = Dequeue(Q);  <span class="comment">//cnt++,记录或者输出什么的(拓扑排序)</span></span><br><span class="line">    <span class="keyword">for</span>(V的每个邻接点W)&#123;</span><br><span class="line">        indegree(W)--;</span><br><span class="line">        <span class="keyword">if</span>(degree(w)==<span class="number">0</span>)&#123;</span><br><span class="line">            Enqueue(W,Q);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(cnt!=|V|)</span><br><span class="line">    图有回路,无法拓扑排序</span><br></pre></td></tr></table></figure>

<h3 id="AOE-activity-on-edge"><a href="#AOE-activity-on-edge" class="headerlink" title="AOE(activity on edge)"></a>AOE(activity on edge)</h3><p>例:关键路径问题  </p>
<h3 id="表排序"><a href="#表排序" class="headerlink" title="表排序"></a>表排序</h3><p>当移动的成本很高时(如移动一部电影)就用表来储存他的顺序</p>
<ul>
<li>table[N]指向N,故用table[N]进行访问\排序</li>
</ul>
<h3 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h3><p>基本原理:假如有10个数分别是0<del>9让你排序,那建立10个桶ar[10],根据情况0</del>9放到对应的桶了,最后顺序输出桶就是有序的了</p>
<h4 id="LSD-Least-Significant-Digit-次位优先"><a href="#LSD-Least-Significant-Digit-次位优先" class="headerlink" title="LSD(Least Significant Digit)次位优先"></a>LSD(Least Significant Digit)次位优先</h4><p>排10个在0~999的整数难道要建1000个桶吗？</p>
<ul>
<li>根据低位到高位建通(实际情况肯更抽象)<ul>
<li>这里是从个位到百位,没位置建10桶</li>
<li>个位桶建装好后再遍历桶,装十位的桶,以此类推</li>
<li>因为是遍历有序桶来填入新桶的,所以最后的桶只需按顺序输出就是有序了</li>
</ul>
</li>
</ul>
<hr>
<h1 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h1><h3 id="散列-hash-查找"><a href="#散列-hash-查找" class="headerlink" title="散列(hash)查找"></a>散列(hash)查找</h3><p>把关键词看成变量,通过哈希函数运算赋予地址</p>
<h4 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h4><p>关键词是数字时的常见方法</p>
<ul>
<li>折叠法</li>
<li>平方取中法</li>
<li>数字分析法</li>
<li>除留余数法</li>
</ul>
<p>关键词是字符时的常见方法</p>
<ul>
<li>位移法(变成整数移位&lt;&lt;求余)</li>
</ul>
<p><strong>核心思想就是当一位改变时尽可能多的影响位数,避免浪费</strong></p>
<h4 id="处理冲突"><a href="#处理冲突" class="headerlink" title="处理冲突"></a>处理冲突</h4><p>产生冲突就添加偏移量到别的位置  </p>
<ul>
<li>线性探测<ul>
<li>偏移量是一增量序列: 1.2.3.4…</li>
<li>容易产生聚集</li>
</ul>
</li>
<li>平方探测<ul>
<li>偏移量是一增量序列: 1^2.2^2.3^2.4^2…</li>
<li>容易产生死循环<ul>
<li>定理:散列表长是某个4k+3的素数时,一定能探测整个表</li>
</ul>
</li>
</ul>
</li>
<li>双散列探测<ul>
<li>$d_i = i\times h_2(kay)$</li>
<li>$h_2(key)=p-(key mod p)$ 效果最好</li>
</ul>
</li>
<li>再散列<ul>
<li>装填因子太大是查找效率下降</li>
<li>那就扩大散列表,在把原来的元素搬进去</li>
</ul>
</li>
<li>分离链接法<ul>
<li>有冲突的关键字都放在(同一个关键字的)一个链表中</li>
</ul>
</li>
</ul>
<p><strong>删除时不能直接删除,会影响后续的查找。正确的删除是标记为删除,新的元素来时再替换</strong></p>
<h3 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h3><p><strong>要点：</strong> </p>
<ul>
<li>next(或者说match)函数的创建<ul>
<li>…</li>
</ul>
</li>
</ul>
<hr>
<h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><h3 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h3><ul>
<li>左边孩子比根节点小</li>
<li>右边孩子比根节点大</li>
</ul>
<p><strong>查找</strong>  </p>
<ul>
<li>左小右大，递归或循环  </li>
</ul>
<p><strong>插入</strong></p>
<ul>
<li>左小右大，递归或循环  </li>
</ul>
<p><strong>删除</strong></p>
<ul>
<li>没有孩子<ul>
<li>直接插入</li>
</ul>
</li>
<li>只有一个孩子<ul>
<li>子承父业</li>
</ul>
</li>
<li>有两个孩子<ul>
<li>找到左子树的最大或右子树的最小替换被删除节点…有效降低树的高度</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">BinTree <span class="title">Delete</span><span class="params">( BinTree BST, ElementType X )</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    Position Tmp; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span>( !BST ) </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"要删除的元素未找到"</span>); </span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>( X &lt; BST-&gt;Data ) </span><br><span class="line">            BST-&gt;Left = Delete( BST-&gt;Left, X );   <span class="comment">/* 从左子树递归删除 */</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>( X &gt; BST-&gt;Data ) </span><br><span class="line">            BST-&gt;Right = Delete( BST-&gt;Right, X ); <span class="comment">/* 从右子树递归删除 */</span></span><br><span class="line">        <span class="keyword">else</span> &#123; <span class="comment">/* BST就是要删除的结点 */</span></span><br><span class="line">            <span class="comment">/* 如果被删除结点有左右两个子结点 */</span> </span><br><span class="line">            <span class="keyword">if</span>( BST-&gt;Left &amp;&amp; BST-&gt;Right ) &#123;</span><br><span class="line">                <span class="comment">/* 从右子树中找最小的元素填充删除结点 */</span></span><br><span class="line">                Tmp = FindMin( BST-&gt;Right );</span><br><span class="line">                BST-&gt;Data = Tmp-&gt;Data;</span><br><span class="line">                <span class="comment">/* 从右子树中删除最小元素 */</span></span><br><span class="line">                BST-&gt;Right = Delete( BST-&gt;Right, BST-&gt;Data );</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123; <span class="comment">/* 被删除结点有一个或无子结点 */</span></span><br><span class="line">                Tmp = BST; </span><br><span class="line">                <span class="keyword">if</span>( !BST-&gt;Left )       <span class="comment">/* 只有右孩子或无子结点 */</span></span><br><span class="line">                    BST = BST-&gt;Right; </span><br><span class="line">                <span class="keyword">else</span>                   <span class="comment">/* 只有左孩子 */</span></span><br><span class="line">                    BST = BST-&gt;Left;</span><br><span class="line">                <span class="built_in">free</span>( Tmp );</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> BST;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h3><h3 id="哈夫曼树"><a href="#哈夫曼树" class="headerlink" title="哈夫曼树"></a>哈夫曼树</h3><hr>
<h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><h2 id="DFS深度优先搜索"><a href="#DFS深度优先搜索" class="headerlink" title="DFS深度优先搜索"></a>DFS深度优先搜索</h2><ul>
<li>从一节点出发<ul>
<li>非连通图分而治之</li>
</ul>
</li>
<li>依次从访问邻接点,直至所有邻接点都被访问<ul>
<li>例:迷宫  </li>
</ul>
</li>
</ul>
<h2 id="BFS广度优先搜索"><a href="#BFS广度优先搜索" class="headerlink" title="BFS广度优先搜索"></a>BFS广度优先搜索</h2><ul>
<li>从一节点出发</li>
<li>把他所有的邻接点入队列,并检测目标节点</li>
<li>依次把节点出队列,并递归的把他的邻接点入队列,直到访问所有点<ul>
<li>例:树的层序遍历  </li>
</ul>
</li>
</ul>
<h3 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h3><p>若存在两点在同一个连通集合中，则这两点存在回路</p>
<ul>
<li>Find() 找根节点</li>
<li>Union() 合并成集合</li>
</ul>
<h2 id="最短路问题"><a href="#最短路问题" class="headerlink" title="最短路问题"></a>最短路问题</h2><h3 id="Dijkstra算法"><a href="#Dijkstra算法" class="headerlink" title="Dijkstra算法"></a>Dijkstra算法</h3><p>解决单源路非递减顺序(没有负)最短路径问题</p>
<ul>
<li>对所有未检索的点进行标记:collected[v] = false</li>
<li>从一点出发,记录所有邻接点,若邻接点加入后路径最短,则更新<ul>
<li>类似BFS</li>
</ul>
</li>
<li>所有邻接点访问完后colleceted[v]=true,从下一个未检索的点继续循环,直到检索所有节点</li>
</ul>
<h3 id="Floyd算法"><a href="#Floyd算法" class="headerlink" title="Floyd算法"></a>Floyd算法</h3><p>解决多源路非递减顺序最短路径问题   </p>
<p>稠密图有优势  </p>
<p>$T=O(V^3)$  </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 核心</span></span><br><span class="line"><span class="comment">// 顶点i到顶点j,顶点间的最短路就在矩阵显示出来了</span></span><br><span class="line"><span class="keyword">for</span>(k = <span class="number">0</span>;k&lt;N;k++)&#123;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;N;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;N;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(D[i][k]+D[k][j]&lt;D[i][j])&#123;</span><br><span class="line">                D[i][j] = D[i][k]+D[k][j];</span><br><span class="line">                path[i][j] = k;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="Prim算法"><a href="#Prim算法" class="headerlink" title="Prim算法"></a>Prim算法</h3><p>解决稠密图的最小生成树问题  </p>
<ul>
<li>从任意点出发</li>
<li>寻找与这个整体相邻,且不构成回路的权最小点</li>
<li>加入该整体,继续搜索,直至所有点都收录(生成树必须包含所有点)</li>
</ul>
<h3 id="Kruskal算法"><a href="#Kruskal算法" class="headerlink" title="Kruskal算法"></a>Kruskal算法</h3><p>解决稀疏图的最小生成树问题  </p>
<p>$T=E\log{E}$  </p>
<ul>
<li>核心思想,每个顶点都是一棵树,把森林连成树</li>
<li>找最短且不构成回路的边,又因为每个顶点都是一棵树,每个边都把森林连成树</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">MST=&#123;&#125;;  <span class="comment">// 最小生成树</span></span><br><span class="line">E;   <span class="comment">// 边集</span></span><br><span class="line"><span class="keyword">while</span>(没够V<span class="number">-1</span>条边&amp;&amp;E没空)&#123;</span><br><span class="line">    findmin();  <span class="comment">// 找最小边  用最小堆</span></span><br><span class="line">    delet(E(v,w));  <span class="comment">// 把该边移除边集E</span></span><br><span class="line">    <span class="keyword">if</span>(E(v,w)加入MST不构成回路)   <span class="comment">// 并查集</span></span><br><span class="line">        join(E(v,w));  <span class="comment">// 加入并查集</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        单纯的删除</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(MST中边不够V<span class="number">-1</span>条)</span><br><span class="line">    生成树不存在</span><br></pre></td></tr></table></figure>


<hr>
<h1 id="效率问题"><a href="#效率问题" class="headerlink" title="效率问题"></a>效率问题</h1><h3 id="联机算法"><a href="#联机算法" class="headerlink" title="联机算法"></a>联机算法</h3><p>在任意时刻，算法对要操作的数据只读入（扫描）一次，一旦被读入并处理，它就不需要在被记忆了。而在此处理过程中算法能对它已经读入的数据立即给出相应子序列问题的正确答案。具有这种特性的算法叫做联机算法（on-line algorithm。</p>
<h3 id="分治算法"><a href="#分治算法" class="headerlink" title="分治算法"></a>分治算法</h3><p>在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。这个技巧是很多高效算法的基础，如排序算法(快速排序，归并排序)，傅立叶变换(快速傅立叶变换)……</p>
<ul>
<li>该问题的规模缩小到一定的程度就可以容易地解决</li>
<li>该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质</li>
<li>利用该问题分解出的子问题的解可以合并为该问题的解</li>
<li>该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题</li>
</ul>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/19/universe/tensorflow_learning/Tensorflow_learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/19/universe/tensorflow_learning/Tensorflow_learning/" class="post-title-link" itemprop="url">Tensorflow</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-19 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-19T00:00:00+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-22 11:57:21" itemprop="dateModified" datetime="2020-04-22T11:57:21+08:00">2020-04-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><h3 id="图片读取展示"><a href="#图片读取展示" class="headerlink" title="图片读取展示"></a>图片读取展示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2  <span class="comment"># 引入OpenCV</span></span><br><span class="line">img = cv2.imread(<span class="string">'path'</span>,<span class="number">1</span>)  <span class="comment"># 读取图片，0是灰图，1是彩图</span></span><br><span class="line">cv2.imshow(<span class="string">'image'</span>,img)  <span class="comment"># 'image'打开的窗体的标题，img展示的内容</span></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)  <span class="comment"># 暂停</span></span><br></pre></td></tr></table></figure>
<p>cv.imread 过程：1文件读取 2封装格式解析 3数据解码 4数据加载  </p>
<h3 id="读写操作"><a href="#读写操作" class="headerlink" title="读写操作"></a>读写操作</h3><h4 id="图片读写"><a href="#图片读写" class="headerlink" title="图片读写"></a>图片读写</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(<span class="string">'path'</span>,<span class="number">1</span>)  <span class="comment"># 读取图片，0是灰图，1是彩图</span></span><br><span class="line">cv2.imwrite(<span class="string">"path"</span>,img)  <span class="comment"># 1,图片名 2.图片数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同质量的图片写入</span></span><br><span class="line"><span class="comment"># jpg,有损压缩</span></span><br><span class="line"><span class="comment"># 压缩比参数范围为0~100，越低压缩比越高</span></span><br><span class="line">cv2.imwrite(<span class="string">"path.jpg"</span>,img,[cv2.IMWRITE_JPEG_QUALITY,<span class="number">0</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># png是无损压缩，有透明度属性</span></span><br><span class="line"><span class="comment"># 压缩比参数0~9,越低压缩比越低</span></span><br><span class="line">cv2.imwrite(<span class="string">"path.png"</span>,img,[cv2.IMWRITE_PNG_QUALITY,<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<h4 id="操作像素"><a href="#操作像素" class="headerlink" title="操作像素"></a>操作像素</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(<span class="string">"img.jpg"</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># OpenCv读取图片是bgr(rgb倒过来)，左上角开始的坐标轴</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取像素点</span></span><br><span class="line">(b,g,r) = img[x,y]</span><br><span class="line">print(b,g,r)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入像素</span></span><br><span class="line">img[x,y] = (b,g,r)</span><br></pre></td></tr></table></figure>





<hr>
<h1 id="OpenCv"><a href="#OpenCv" class="headerlink" title="OpenCv"></a>OpenCv</h1><h3 id="OpenCv模块结构"><a href="#OpenCv模块结构" class="headerlink" title="OpenCv模块结构"></a>OpenCv模块结构</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">to be continued</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Tensotflow"><a href="#Tensotflow" class="headerlink" title="Tensotflow"></a>Tensotflow</h1><h4 id="基本操作-1"><a href="#基本操作-1" class="headerlink" title="基本操作"></a>基本操作</h4><h5 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 定义常量</span></span><br><span class="line">data1 = tf.constant(<span class="number">2.5</span>)  <span class="comment"># 指定数据类型可以加参数(2,dtype=tf.int32)</span></span><br><span class="line"><span class="comment"># 定义变量</span></span><br><span class="line">data2 = tf.Variable(b,name=<span class="string">"name"</span>)</span><br><span class="line"><span class="comment"># 打印出来的是描述信息</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有操作要session会话进行</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(data1))  <span class="comment"># 通过会话进行的就可以打印了</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有变量都要用session进行初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)  <span class="comment"># 初始化</span></span><br><span class="line"><span class="comment"># session打印多个内容</span></span><br><span class="line">sess.run([x1,x2,x3])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭session</span></span><br><span class="line"><span class="comment"># 法一</span></span><br><span class="line">sess.close()</span><br><span class="line"><span class="comment"># 法二  with</span></span><br><span class="line"><span class="keyword">with</span> sees:</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>

<h5 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow运算的每个类型都要是tensor</span></span><br><span class="line"><span class="comment"># 转换为tensor,如 a=np.arange(1)</span></span><br><span class="line">aa = tf.convert_to_tensor(a,dtye=tf.int32) <span class="comment">#dtype=数据类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor类型间转换</span></span><br><span class="line">tf.cast(aa,dtype=tf.double)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Variable</span></span><br><span class="line"><span class="comment"># Variable包装过的变量会具有一些特殊的属性,如可导</span></span><br><span class="line">b=tf.Variable(b,name=<span class="string">"name"</span>)</span><br><span class="line">b.name</span><br><span class="line">b.trainable</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor变numpy</span></span><br><span class="line"><span class="comment"># tensor一般在GPU,当有时我们要在CPU上处理默写逻辑时就要转成numpy</span></span><br><span class="line">a.numpy()  <span class="comment"># tensor:a 就变成了numpy</span></span><br></pre></td></tr></table></figure>

<h5 id="创建tensor"><a href="#创建tensor" class="headerlink" title="创建tensor"></a>创建tensor</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a.convert_to_tensor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">tf.zeros(shape)  <span class="comment"># tf.zeros_like(a) 初始化一个和a一样维度的(shape)</span></span><br><span class="line">tf,ones(shape)</span><br><span class="line">tf.fill(shape,elem)</span><br><span class="line">tf.random.normal(shape,mean=<span class="number">1</span>,stddev=<span class="number">1</span>)  <span class="comment"># 用正态分布采样(normal,其他分部同理)初始化一个,其中mean,stddev正太分部的参数,其他分部同理</span></span><br><span class="line">tf.random.truncated_normal(...)  <span class="comment"># 截断的正态分布</span></span><br><span class="line">tf.random.uniform(shape,minval=<span class="number">0</span>,maxval=<span class="number">1</span>)  <span class="comment"># 均匀分布采样</span></span><br><span class="line"><span class="comment"># shape表示维度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打散</span></span><br><span class="line"><span class="comment"># 就是random了,但是如果是两组有一一对应关系的东西,怎么打散才不会破坏那个一一对应关系?</span></span><br><span class="line">idx = tf.range(<span class="number">10</span>)  <span class="comment"># 假设有10组数据</span></span><br><span class="line">idx = rf.random.shuffle(idx)  <span class="comment"># (就好比生成了10组随机的通道(每个通道代表一种一一对应关系)通道两边绑定了,所以对应关系不变)</span></span><br></pre></td></tr></table></figure>

<h5 id="索引与切片"><a href="#索引与切片" class="headerlink" title="索引与切片"></a>索引与切片</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 索引</span></span><br><span class="line"><span class="comment"># numpy风格的索引，如：</span></span><br><span class="line">a.shape() = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">a[<span class="number">1</span>,<span class="number">2</span>].shape = [<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"><span class="comment"># 索引写在一个[]内，用逗号隔开</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切片</span></span><br><span class="line"><span class="comment"># 对于某个维度</span></span><br><span class="line">a[<span class="number">-1</span>:]  <span class="comment"># 到数第一个到最后一个,就是python的切片</span></span><br><span class="line"><span class="comment"># 对多个维度的切片</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">1</span>,:,<span class="number">1</span>:<span class="number">3</span>,:]  <span class="comment"># (取a01的全部的1到3的全部。。。很灵活)</span></span><br><span class="line"><span class="comment"># step,步长.... [::] 同理, 步长为负，实现倒叙</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 省略号:省略多个:(自动识别)</span></span><br><span class="line">a[<span class="number">1</span>,<span class="number">2</span>,...,<span class="number">0</span>,:]  <span class="comment"># 中间的没有切片操作,但是倒数第二有切片操作,用...就不用人为的把中间的:不上了</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Selective Indexing </span></span><br><span class="line"><span class="comment"># 可以乱序取样</span></span><br><span class="line"><span class="comment"># 假设a.shape = [4,32,8] ,a[4个班,35个学生,8门科目成绩]</span></span><br><span class="line">a = tf.gather(a,axis=<span class="number">0</span>,indices=[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 1.取样的样本 2.抽取的维度,上面就是从第一个维度中乱序的抽取,随机抽取一个班查看 3.抽取的顺序,抽2班1班3班0班</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还是上面的例子,如果想要取n个学生的m门成绩呢？</span></span><br><span class="line">aa = tf.gather(a,axis=<span class="number">1</span>,indices=[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">0</span>])  <span class="comment"># 取4个班2，1，3，0号学生</span></span><br><span class="line">aaa = tf.gather(aa,axis=<span class="number">2</span>,indices=[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">0</span>])  <span class="comment"># 取这4个班2，1，3，0号学生,的2，1，3，0号成绩</span></span><br><span class="line"><span class="comment"># 多个gather嵌套</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.gather_nd !!!比较难理解</span></span><br><span class="line">gather_nd(a,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])  <span class="comment"># 1班1号同学的1号成绩,标量</span></span><br><span class="line">gather_nd(a,[[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]])  <span class="comment"># 0班0号同学的8门成绩,和1班1号同学的8门成绩,组成的矩阵,shape = [2,8] 2个同学,8门成绩</span></span><br><span class="line">gather_nd(a,[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>]])  <span class="comment"># shape = [2]</span></span><br><span class="line">gather_nd(a,[[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>]]])  <span class="comment"># shape = [1,2]</span></span><br><span class="line"><span class="comment"># 体会标量放[]里和矩阵放[]里的区别,差不多就是这个意思</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.boolean_mask</span></span><br><span class="line"><span class="comment"># 通过boolean来取样 假设a.shape = [4,28,28,3]</span></span><br><span class="line">tf.boolean_mask(a,mask=[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>])  <span class="comment"># 默认从最外层(mask嘛)</span></span><br><span class="line"><span class="comment"># 结果shape = [2,28,28,3]</span></span><br><span class="line"><span class="comment"># 多维遮罩 例:a.shape = [2,3,4]</span></span><br><span class="line">tf.boolean_mask(a,mask=[[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>],[<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">True</span>]])  <span class="comment"># mask.shape=[2,3] 采样的元素取对应关系,根据mask,第0行第一个元素是True，所以要...</span></span><br><span class="line"><span class="comment"># 结果shape = [3,4]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然也可以指定,遮罩哪个维度 </span></span><br><span class="line">tf.boolean_mask(a,mask=[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>],axis = <span class="number">3</span>)  <span class="comment"># shape = [4,28,28,2]</span></span><br></pre></td></tr></table></figure>

<h5 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a.shape = [4,28,28,3]</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">784</span>,<span class="number">3</span>])  <span class="comment"># 4*28*28*3  ==  4*784*3 才能保证所有数据充分利用</span></span><br><span class="line"><span class="comment"># 如果先偷懒的话可以用-1</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">-1</span>,<span class="number">3</span>])  <span class="comment"># 一个式子只能有一个-1,-1就相当于x,保证4*28*28*3 == 4*x*3</span></span><br><span class="line"><span class="comment"># 变换前要理清楚物理含义</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵变换,改变格式</span></span><br><span class="line"><span class="comment"># a.shape = [4,3,2,1] </span></span><br><span class="line">tf.transpose(a)  <span class="comment"># 矩阵转置</span></span><br><span class="line">tf.transpose(a,perm=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>])  <span class="comment"># 原来的0维放在新的0维...原来的3维放在新的2维...</span></span><br><span class="line"><span class="comment"># 结果 shape = [4,3,1,2]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 维度的增加</span></span><br><span class="line"><span class="comment"># a.shape=[4,35,8]</span></span><br><span class="line">tf.expand_dims(a,axis=<span class="number">0</span>)  <span class="comment"># 插入的(一个)维度相当于插入后维度的第0维,a.shape=[1,4,35,8]</span></span><br><span class="line">tf.expand_dims(a,axis=<span class="number">3</span>)  <span class="comment"># 插入的维度相当于插入后维度的第3维,a.shape=[4,35,8,1]</span></span><br><span class="line"><span class="comment"># 负数同理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 维度减少</span></span><br><span class="line"><span class="comment"># 元素个数为1的维度是可以去掉的,a.shape=[1,2,1,1,3]</span></span><br><span class="line">tf.squeeze(a)  <span class="comment"># 不加axis参数就是把所有1去掉</span></span><br><span class="line">tf.squeeze(a,axis=<span class="number">2</span>)  <span class="comment"># 把第二维度去掉</span></span><br></pre></td></tr></table></figure>

<h5 id="Broadcasting"><a href="#Broadcasting" class="headerlink" title="Broadcasting"></a>Broadcasting</h5><ul>
<li>expand without copying data:扩张了一个数据,但实际上并没有复制出来多份<img src="./static/broadcasting.png" style="zoom:50%">

</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tf.broadcast_to</span><br><span class="line"><span class="comment"># ape=[3,5]</span></span><br><span class="line">aa = broadcast_to(a,[<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>])</span><br><span class="line">aa.shape = [<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如前面的 x@w+b,b是一个一维的，但却能加上去,就是broadcast的功劳</span></span><br><span class="line"><span class="comment"># 如a.shape=[4,16,16,32] b.shape=[32]</span></span><br><span class="line"><span class="comment"># 如果a+b 那么b就会相当于自动变成[4,16,16,32],以满足相应的运算(包括加减乘除</span></span><br><span class="line"><span class="comment"># 先从小维度开始匹配,自动扩张是满足运算</span></span><br><span class="line"><span class="comment"># 但却不会生成4*16*16个b</span></span><br><span class="line"><span class="comment"># 判断方法:右对其,用1把维度补相同,然后把1是维度变成和另一个匹配的</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># a.shape=[1,3,4]</span></span><br><span class="line"><span class="comment"># tf.tile(a,[2,1,3]) 第一个维度复制2ci，第二个1次，第三个4次</span></span><br><span class="line"><span class="comment"># a.shape = [2,3,12]</span></span><br></pre></td></tr></table></figure>

<h5 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># element-wise: +-*/</span></span><br><span class="line"><span class="comment"># shape一样，对应元素运算</span></span><br><span class="line"><span class="comment"># (一般的运算,非矩阵...吧)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># matrix-wise: @,matmul</span></span><br><span class="line"><span class="comment"># 如 [b,3,4]@[b,4,5]</span></span><br><span class="line"><span class="comment"># 相当于把后两个当成矩阵然后来运算[3,4]*[4,5] = [3,5]</span></span><br><span class="line"><span class="comment"># 相当于一下子b个矩阵相乘</span></span><br><span class="line"><span class="comment"># (矩阵运算...)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># dim-wise: reduce_mean/max/min/sum</span></span><br></pre></td></tr></table></figure>

<h5 id="手写数字识别-你可能用到"><a href="#手写数字识别-你可能用到" class="headerlink" title="手写数字识别,你可能用到"></a>手写数字识别,你可能用到</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">(xs, ys),_ = datasets.mnist.load_data()</span><br><span class="line">xs = tf.convert_to_tensor(xs, dtype=tf.float32) / <span class="number">255.</span>    <span class="comment"># 除以255是为了优化,这样0&lt;x&lt;1</span></span><br><span class="line">ys = ....  <span class="comment"># 变成tensor</span></span><br><span class="line"></span><br><span class="line">train_db = tf.data.Dataset.from_tenfor_slices((x,y)).batch(<span class="number">128</span>)</span><br><span class="line">train_iter = iter(train_db)</span><br><span class="line">sample = next(train_iter)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>,<span class="number">256</span>]),stddev=<span class="number">0.1</span>)  <span class="comment"># stddev=0.1是为了......</span></span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))   <span class="comment"># 变成tf.Variable才能被Gradient跟踪</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):   <span class="comment"># 对整个数据集循环,反复使用用一个数据集不断优化</span></span><br><span class="line">	<span class="keyword">for</span> step,(x, y) <span class="keyword">in</span> enumerate(train_db):  <span class="comment"># step,方便记录,查enumerate用法</span></span><br><span class="line">		x = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># 默认只会跟踪tf.Variable的类型</span></span><br><span class="line">			h1 = x@w1 + b1</span><br><span class="line">			h1 = tf.nn.relu(h1)</span><br><span class="line">			...</span><br><span class="line">			out = ...</span><br><span class="line">			</span><br><span class="line">			y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)  <span class="comment"># y:[b] =&gt; [b,10]</span></span><br><span class="line">		</span><br><span class="line">			loss = tf.square(y_onehot - out)</span><br><span class="line">			loss = tf.reduce_mean(loss)</span><br><span class="line">			</span><br><span class="line">		grads = tape.gradient(loss,[w1,b1,w2,b2,w3,b3])</span><br><span class="line">		<span class="comment"># 更新w,b</span></span><br><span class="line">		w1.assign_sub(lr*grads[<span class="number">0</span>])  <span class="comment"># 原地更新,引用不变,类型不变</span></span><br><span class="line">		...</span><br><span class="line">		...</span><br><span class="line">		<span class="keyword">if</span> step % <span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">			print(float(loss))</span><br></pre></td></tr></table></figure>

<h5 id="合并与拼接"><a href="#合并与拼接" class="headerlink" title="合并与拼接"></a>合并与拼接</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">c =tf.concat([a,b],axis=<span class="number">0</span>)   <span class="comment"># a和b第0维度合并</span></span><br><span class="line"><span class="comment"># 在原有维度上累加,不能生成新的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果要创造新的维度</span></span><br><span class="line"><span class="comment"># a.shape = [4,3,5] b.shape = [4,3,5]</span></span><br><span class="line">c = tf.stack([a,b]axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># c.shape = [4,2,3,5]  </span></span><br><span class="line"><span class="comment"># 根据表示意义理解 如[chool,class,student,scores]</span></span><br><span class="line"><span class="comment">### 以上对维度都有要求,有一定的局限性</span></span><br><span class="line"><span class="comment"># 同样用[class,student,scores] 模型举例</span></span><br><span class="line"><span class="comment"># 每个学校，班等都可能不同,stack就操作不了</span></span><br><span class="line"></span><br><span class="line">tf.unstack(a,axis=<span class="number">0</span>)   <span class="comment"># 全部拆开,返回几个tensor取决于有几个</span></span><br><span class="line">tf.unstack(a,axis=<span class="number">3</span>,num_or_size_splits=<span class="number">2</span>)   <span class="comment"># 在指定维度拆开拆开,参数是2所以拆成两个</span></span><br><span class="line">tf.unstack(a,axis=<span class="number">3</span>,num_or_size_splits=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>])   <span class="comment"># 指定拆开,拆开的低0个有2份,地2个有3份...</span></span><br></pre></td></tr></table></figure>

<h5 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h5><ul>
<li>范数<ul>
<li>二范数<br>$${||x||}_2 = [\sum_k{x^2_k}]^\frac{1}{2}$$  </li>
<li>无穷范数  </li>
<li>一范数..等等<br>$${||x||}_1 = \sum_k{|x_k|}$$  </li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###  这里讨论的都是向量的范数(非矩阵)</span></span><br><span class="line">tf.norm(a)  <span class="comment"># 二范数</span></span><br><span class="line">tf.norm(a,ord=<span class="number">1</span>,axis=<span class="number">1</span>)  <span class="comment"># 一范数,同时把某维度看做整体来做范数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># reduce_mean/min/max</span></span><br><span class="line"><span class="comment"># reduce说明,这操作会有个减维的过程:相当于每组选出了指定的数,那组的大小就成了1</span></span><br><span class="line">tf.reduce_mean(a,axis=<span class="number">1</span>)  <span class="comment"># 2.不指定维度的话会打平成以维度</span></span><br><span class="line"><span class="comment"># 指定了维度就会在指定维度取  $注意,这里讨论的都是向量,不用矩阵来理解</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 就最大最小值的位置</span></span><br><span class="line"><span class="comment"># a.shape = [4,10]</span></span><br><span class="line">tf.argmax(a)  <span class="comment"># 默认第0维比较,a有10组,所以会返回10个结果[2,3,4..]</span></span><br><span class="line">tf.argmin(a,axis=<span class="number">1</span>)  <span class="comment"># 指定维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 比较</span></span><br><span class="line">tf.equal(a,b) <span class="comment"># 返回[True,False,True,...]</span></span><br><span class="line"><span class="comment"># 准确度:把上面的返回结果dtype成0,1然后累加</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.unique</span></span><br><span class="line">tf,unique(a)</span><br><span class="line"><span class="comment"># 返回两个值,第一个是无重复值的tensor,第二个是tensor是值表示原tensor的元素在新tensor中的位置</span></span><br><span class="line"><span class="comment"># 这么一来可以用tf.gather来吧原tensor还原出来</span></span><br></pre></td></tr></table></figure>

<h5 id="张量排序"><a href="#张量排序" class="headerlink" title="张量排序"></a>张量排序</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">tf.sort(a,direction=<span class="string">'DESCENDING'</span>)  <span class="comment"># 降序,  direction='ASCENDING'就能升序</span></span><br><span class="line">tf.argsort(a,direction=<span class="string">'DESCENDING'</span>)  <span class="comment"># 降序,返回的是位置:如[最大值位置，次大..]</span></span><br><span class="line"><span class="comment"># 同理可与gather配合</span></span><br><span class="line"><span class="comment"># 高维的话就按每维排列完全排序</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但有时候我们只需要最大最小(不用完全排序,耗时)</span></span><br><span class="line">res = tf.max.top_k(a,<span class="number">2</span>)  <span class="comment"># 返回最大的两个</span></span><br><span class="line">res.indices   <span class="comment"># 返回索引值,像argsort</span></span><br><span class="line">res.values  <span class="comment"># 返回值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用</span></span><br><span class="line"><span class="comment"># 预测问题:0,1,2,3的预测分别是 prob[0.1,0.2,0.3,0.4]</span></span><br><span class="line"><span class="comment"># 真实值是2</span></span><br><span class="line"><span class="comment"># top-1 prediction(正确答案在前1个的概率):0%   (预测对的样本个数/总样本数(这了只用应该样本)) </span></span><br><span class="line"><span class="comment"># top-2 prediction(正确答案在前2个的概率):100% </span></span><br><span class="line"><span class="comment"># top-3 prediction(正确答案在前3个的概率):100% </span></span><br><span class="line"><span class="comment"># 举例</span></span><br><span class="line"><span class="comment"># prob = tf.constant([[0.1,0.2,0.7],[0.2,0.7,0.1]]) #样本1最可能是2,样本2最可能是1</span></span><br><span class="line"><span class="comment"># target = tf.constant([2,0])  # 样本1正式值应该是2，样本2真实值应该是0</span></span><br><span class="line"><span class="comment"># 所以: top-1 prediction=1/2  = 50%</span></span><br><span class="line"><span class="comment"># top-2 prediction = 2/2 = 100%</span></span><br><span class="line"><span class="comment"># top-3 prediction = 2/2 = 100%</span></span><br></pre></td></tr></table></figure>

<h5 id="填充与复制"><a href="#填充与复制" class="headerlink" title="填充与复制"></a>填充与复制</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 填充 pad</span></span><br><span class="line">tf.pad(a,[[<span class="number">2</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]])  <span class="comment"># 行上边边填充2行下边0行;列左0右1</span></span><br><span class="line"><span class="comment">#          ^行  ^列  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制 tile</span></span><br><span class="line"><span class="comment"># a.shape = [3,3]</span></span><br><span class="line">tf.tile(a,[<span class="number">1</span>,<span class="number">2</span>])  <span class="comment"># 第一维复制一次(不变),第二维复制2次 </span></span><br><span class="line"><span class="comment"># res.shape = [3,6]</span></span><br><span class="line"><span class="comment"># 会真实的复制到内存</span></span><br></pre></td></tr></table></figure>

<h5 id="张量的限幅"><a href="#张量的限幅" class="headerlink" title="张量的限幅"></a>张量的限幅</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 限制最小值</span></span><br><span class="line">tf.maximum(a,<span class="number">2</span>)  <span class="comment"># 返回a,2间的最大值,故a不会小于2,限制的最小值</span></span><br><span class="line"><span class="comment"># 限制最大值</span></span><br><span class="line">tf.minimum(a,<span class="number">8</span>)  <span class="comment"># 返回a,8间的最小值 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 限制范围</span></span><br><span class="line">tf.clip_by_value(a,<span class="number">2</span>,<span class="number">8</span>)  <span class="comment"># 2&lt;x&lt;8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># relu函数,x小于0时取0，大于0是取本身</span></span><br><span class="line"><span class="comment"># 可用maximum(a,0)实现</span></span><br><span class="line"><span class="comment"># 也可用封装好的relu函数</span></span><br><span class="line">tf.relu(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等比例放缩,希望把grad缩小方便学习,但又不希望改变gred值</span></span><br><span class="line"><span class="comment"># 可用除以模再乘以一个值来控制范围来,也可用函数</span></span><br><span class="line">tf.clipe_by_norm(a,<span class="number">15</span>)  <span class="comment"># 相当于除模后乘15,改变了a的模</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Gradient Exploding 梯度太大,一步学习跨越太大,来回震荡</span></span><br><span class="line"><span class="comment"># Gradient Vanishing 梯度太小,学习太慢，长时间没有变化</span></span><br><span class="line"><span class="comment"># tf.clipe_by_global_norm(grads,25)  # 整体缩放,避免方向改变</span></span><br><span class="line"><span class="comment"># 梯度向量表示[2,5,3],那么整体缩小就不会改变方向</span></span><br></pre></td></tr></table></figure>

<h5 id="高级操作"><a href="#高级操作" class="headerlink" title="高级操作"></a>高级操作</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 筛选 mask = [True,False,True]</span></span><br><span class="line">tf.where(mask)  <span class="comment"># 没有参数,返回tensor中值是True的值的对应坐标tensor</span></span><br><span class="line">tf.where(mask,A,B)  <span class="comment"># True时对A采样,False时对B采样</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有目的性的更新</span></span><br><span class="line">tf.scatter_nd(indices,updates,shape) </span><br><span class="line"><span class="comment"># 1.只能在全0的底板上更新,就是上面的shape</span></span><br><span class="line"><span class="comment"># 2.indices表示要更新的位置,把对应位置上updates的值更新过去</span></span><br><span class="line"><span class="comment"># 一般用作给指定位置加减(因为只能全0为底板)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 快速生成坐标轴系(GPU加速的,区别于传统for循环的)</span></span><br><span class="line">point_x,point_y = tf.meshgrid(x,y)</span><br><span class="line"><span class="comment"># 返回两个值,个存取x的所有值和y的所有值</span></span><br><span class="line"><span class="comment"># 对应位置的祝贺就是(x,y) </span></span><br><span class="line"><span class="comment"># 重新组合: tf.stack([point_x,point_y],axis=2)</span></span><br></pre></td></tr></table></figure>

<h4 id="神经网络与全连接层"><a href="#神经网络与全连接层" class="headerlink" title="神经网络与全连接层"></a>神经网络与全连接层</h4><h5 id="数据集的加载-小型"><a href="#数据集的加载-小型" class="headerlink" title="数据集的加载(小型)"></a>数据集的加载(小型)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集准备</span></span><br><span class="line">(x,y),(x_test,y_test) = keras.datasets.mnist.load_data()  <span class="comment"># 获取mninst数据集,返回各有不同</span></span><br><span class="line"><span class="comment"># 返回的是numpy的格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将numpy转换成对象</span></span><br><span class="line">db = tf.data.Dataset.from_tenfor_slices(x_test,y_test)</span><br><span class="line">next(iter(db))[<span class="number">0</span>].shape  <span class="comment"># 转换成对象后就可进行的一系列操作,支持多线程等</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打散</span></span><br><span class="line">db = db.shuffle(<span class="number">10000</span>)  <span class="comment"># 打散,但x和y的对应关系不打撒(gather),参数?给大点就是了</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">db2 = db.map(func)  <span class="comment"># 对db里的每个元素进行func里的操作</span></span><br><span class="line"><span class="comment"># 如每个元素是(x,y),func函数的参数的x,y返回的是处理后的x,y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch</span></span><br><span class="line">db3 = db2.batch(<span class="number">42</span>)  <span class="comment"># 不再一次读取一组数据,一次读取指定数量的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重复迭代</span></span><br><span class="line">db4 = db3.repeat(<span class="number">2</span>)  <span class="comment"># 重复迭代2次</span></span><br><span class="line">db4 = db3.repeat()  <span class="comment"># 无限重复</span></span><br></pre></td></tr></table></figure>

<h5 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个节点跟每个节点连接——Dense</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">728</span>])  <span class="comment"># 输入</span></span><br><span class="line">net = tf.keras.layers.Dense(<span class="number">512</span>)  <span class="comment"># 创建输出512的层</span></span><br><span class="line">out = net(x)  <span class="comment"># out.shape = [4,512]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多层嵌套——Multi-Layers</span></span><br><span class="line"><span class="comment"># keras.Sequential([layer1,layer2,...])  # layer-&gt;Dense</span></span><br><span class="line">network = keras.Sequential([</span><br><span class="line">        keras.layers.Dense(<span class="number">2</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">        keras.layers.Dense(<span class="number">2</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">        keras.layers.Dense(<span class="number">2</span>)</span><br><span class="line">    ])</span><br><span class="line">network.build(input_shape=[<span class="literal">None</span>,<span class="number">3</span>])  <span class="comment"># 创建，给定输入维度3</span></span><br><span class="line">network.summary()   <span class="comment"># 打印信息</span></span><br><span class="line">network.trainable_variables   <span class="comment"># list[],可训练参数</span></span><br></pre></td></tr></table></figure>

<h5 id="输出方式"><a href="#输出方式" class="headerlink" title="输出方式"></a>输出方式</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出范围压缩</span></span><br><span class="line"><span class="comment"># sigmod函数(同理relu)</span></span><br><span class="line">y = tf.sigmod(x)   <span class="comment"># x属于R,y属于[0,1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tanh函数,压缩范围到[-1,1]</span></span><br><span class="line">tf.tanh(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出概率(所有的和为1)</span></span><br><span class="line"><span class="comment"># softmax函数</span></span><br><span class="line">tf.softmax(a)</span><br></pre></td></tr></table></figure>

<h5 id="损失函数的计算"><a href="#损失函数的计算" class="headerlink" title="损失函数的计算"></a>损失函数的计算</h5><ul>
<li>MSE<br>$$loss=\frac{1}{N}\sum(y-out)^2$$<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss1 = tf.reduce_mean(tf.square(y-out))</span><br><span class="line">loss2 = tf.reduce_mean(tf.losses.MSE(y,out))</span><br><span class="line"><span class="comment"># loss1 = loss2 等价</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="标差熵"><a href="#标差熵" class="headerlink" title="标差熵"></a>标差熵</h5><ul>
<li>熵 $Entropy = -\sum P(i)\log_2{P(i)}$<ul>
<li>不确定度 Uncertainty</li>
<li>惊奇度 measure of surprise</li>
<li>lower entropy -&gt; more info</li>
</ul>
</li>
</ul>
<h5 id="交叉熵-Cross-Entropy"><a href="#交叉熵-Cross-Entropy" class="headerlink" title="交叉熵 Cross Entropy"></a>交叉熵 Cross Entropy</h5><ul>
<li><p>描述两个集合p,q的惊奇度</p>
<ul>
<li>$H(p,q) = -\sum{p(x) \log_2{q(x)}}$</li>
<li>$H(p,g) = H(p) + D(p|q)$ <ul>
<li>$D(p|q)$ 表示p和q的离散度</li>
<li>当p=q时$D(p|q)=0$</li>
</ul>
</li>
</ul>
</li>
<li><p>for p:one_hot encoding</p>
<ul>
<li>$h(p:[0,1,0]) = -1\log_2{1}=0$</li>
<li>$H([0,1,0],[q_1,q_2,q_3]) = 0+D(p|q)=-1\log{q_1}$</li>
<li>即要使p逼近与q用交叉熵的方法的可行的  </li>
</ul>
</li>
<li><p>具体解法<br>设一组分类的one_hot encoding是$P_1[1,0,0,0,0]$;<br>一组输出为$Q_1[0.4,0.3,0.05,0.05,0.5]$;<br>则:</p>
</li>
</ul>
<p>$$\begin{aligned}<br>loss &amp;= H(p,q) \<br>&amp;= -\sum{P_1(x) \log_2{Q_1(x)}} \<br>&amp;= -\log_2{0.4}  \<br>&amp;= 0.916<br>\end{aligned}<br>$$</p>
<p>然后lr,w1,b2…,多次学习后发现loss越来越小,即q = p  </p>
<ul>
<li>在tensorflow中的使用</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.losses.categorical_crossentropy(p,q) <span class="comment"># 函数的形式</span></span><br><span class="line">tf.losses.BinaryCrossentropy()(p,q)  <span class="comment"># 类的形式</span></span><br><span class="line">tf.losses.binary_crossentropy(p,q) <span class="comment"># 函数的形式 </span></span><br><span class="line"><span class="comment"># p是真实在的one_hot encodingq是预测值</span></span><br><span class="line"><span class="comment"># 如tf.losses.categorical_crossentropy([1,0,0,0],[0.25,0.25,0.25,0.25])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 通常的用法 ###</span></span><br><span class="line">tf.losses.categorical_crossentropy(one_hot,logits,from_logits=<span class="literal">True</span>)  <span class="comment"># 这样能处理logits转换成prob时的错误</span></span><br><span class="line">tf.losses.categorical_crossentropy(one_hot,prob)  <span class="comment"># 等价但不推荐</span></span><br></pre></td></tr></table></figure>


<h3 id="梯度下降-Gradient-Descent"><a href="#梯度下降-Gradient-Descent" class="headerlink" title="梯度下降 Gradient Descent"></a>梯度下降 Gradient Descent</h3><ul>
<li>梯度:向量grad<ul>
<li>用梯度下降来逼近<br>$$ w_n = w - lr \times \frac{\partial{loss}}{\partial{w}} $$</li>
</ul>
</li>
<li>在tensorflow中的使用</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># 把计算过程包在里面</span></span><br><span class="line">    tape.watch([w,b])  <span class="comment"># 如果参数不是tf.variable类型话要用这个函数声明</span></span><br><span class="line">    loss = f(x)</span><br><span class="line">[w_grad] = tape.gradient(loss,[w])  <span class="comment"># 自动求解参数的梯度,并返回相应的列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tape.gradient调用一次后会把资源释放掉,可用参数persistent改变</span></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape(persistent=<span class="literal">True</span>) <span class="keyword">as</span> tape:  <span class="comment"># 用完后会保留资源</span></span><br><span class="line">grad1 = tape.gradient(loss,[w]) </span><br><span class="line">grad2 = tape.gradient(loss,[w])  <span class="comment"># 可调用多次</span></span><br><span class="line"><span class="comment"># 但要记得手动释放资源！！！</span></span><br></pre></td></tr></table></figure>


<h4 id="激活函数-Activation-Function"><a href="#激活函数-Activation-Function" class="headerlink" title="激活函数 Activation Function"></a>激活函数 Activation Function</h4><p>科学家在研究青蛙神经是发现，当刺激到达一定程度是青蛙才会做出相应的反应，是个离散的过程<br>因此在深度学习中就可模仿设点，设计神经网络，因此有了激活函数  </p>
<p>连续的光滑的激活函数</p>
<ul>
<li><strong>sigmoid(logistic)</strong><ul>
<li>$f(x)=\delta(x)=\frac{1}{1+e^{-x}}$</li>
<li><code>y = tf.sigmoid(a)</code></li>
<li>可以将范围压缩到[0,1]</li>
<li>但当x接近无穷时，导数几乎为零，导致梯度离散，使得长期得不到更新</li>
</ul>
</li>
<li><strong>Tanh</strong><ul>
<li>$f(x)=tanh(x)=\frac{(e^x-e^{-x})}{e^x+e^{-x}}=2sigmoid(2x)-1$</li>
<li><code>y = tf.tanh(a)</code></li>
</ul>
</li>
<li><strong>ReLU(Rectified Linear Unit)</strong><ul>
<li>$<br>f(x) = \begin{cases}<br>0, &amp; \text{if } x &lt; 0  \<br>x, &amp; \text{if } x \geq 0<br>\end{cases}<br>$</li>
<li><code>tf.nn.relu()</code></li>
<li>深度学习最常用的<ul>
<li>优势</li>
<li>求导简单</li>
<li>不会放大或缩小梯度(reLU的导数为1)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Softmax</strong><ul>
<li>$S(y_i)=\frac{e^{y_i}}{\sum_j{e^{y_i}}}$</li>
<li>常用于多分类问题，因为它把logits转换为prob</li>
<li>区别于一般的转换成prob的方法，Softmax会把大的放大，小的缩小；拉大差距(sotf version of max)</li>
<li>求导:把先把分子分母看做整体<code>f(x)和g(x)</code>然后相当于$\frac{\partial p_i}{\partial a_j}=\frac{f’(x)g(x)-f(x)g’(x)}{g(x)^2}$;注意i和j不同的情况要分开讨论<ul>
<li>结果$<br>\frac{\partial p_i}{\partial a_j} = \begin{cases}<br>p_i(1-p_1), &amp; \text{if } i=j  \</li>
<li>p_jp_i, &amp; \text{if } i\neq j<br>\end{cases}<br>$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Loss函数的梯度"><a href="#Loss函数的梯度" class="headerlink" title="Loss函数的梯度"></a>Loss函数的梯度</h4><p>经典的loss函数</p>
<ul>
<li>Mean Squared Error(MSE,均方差)<ul>
<li>$loss=\frac{1}{N}\sum(y-out)^2$</li>
<li><code>loss1 = tf.reduce_mean(tf.square(y-out))</code></li>
<li><code>loss2 = tf.reduce_mean(tf.losses.MSE(y,out))</code></li>
</ul>
</li>
<li>Cross Entropy Loss<ul>
<li>Softmax</li>
</ul>
</li>
</ul>
<h4 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h4><p>$\frac{\partial y}{\partial x} = \frac{\partial y}{\partial u}\frac{\partial u}{\partial x}$</p>
<h4 id="感知机梯度传导"><a href="#感知机梯度传导" class="headerlink" title="感知机梯度传导"></a>感知机梯度传导</h4><p>利用链式法则从输出往输入退就可以知道梯度信息，然后更新  </p>
<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ul>
<li>tensorboard<ul>
<li><code>pip install tensorboard</code></li>
<li>在代码中写入<code>summary_writer = tf.summary.create_file_writer(DIR)</code></li>
<li>拿到<code>summary_writer</code>后就可以忘里面喂数据</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1,喂数据点</span></span><br><span class="line"><span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">    tf.summary.scalar(<span class="string">'NAME1'</span>, float(LOSS), step=STEP)  <span class="comment"># (图的名字,数据,坐标(默认是x轴))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2,喂一个图片</span></span><br><span class="line"><span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">    tf.summary.image(<span class="string">'NAME1'</span>, IMG, step=STEP)  <span class="comment"># (图的名字,数据,坐标(默认是x轴))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3,给多个图片</span></span><br><span class="line"><span class="comment"># 最好的办法是认为的拼接图片,然后传一张拼接的图片(google)</span></span><br></pre></td></tr></table></figure>

<ul>
<li>visdom </li>
</ul>
<h2 id="Keras高层API"><a href="#Keras高层API" class="headerlink" title="Keras高层API"></a>Keras高层API</h2><h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><p>在计算loss,accuracy的时候经常会发现数据忽高忽低,所以可借助keras的api来优化</p>
<ul>
<li>metrics测量<ul>
<li>keras会将数据放在一个list,然后取平均值来优化?</li>
<li>如<code>loss_meter = metrics.Mean()</code>,<code>acc_meter = metrics.Accuracy()</code></li>
</ul>
</li>
<li>update_state更新数据<ul>
<li><code>loss_meter.update_state(loss)</code>,<code>acc_meter.update_state(y, pred)</code></li>
</ul>
</li>
<li>result().numpy()获取结果,转换成numpy输出<ul>
<li><code>loss_meter.result().numpy()</code>result得到tensor，再转换成numpy</li>
</ul>
</li>
<li>reset_states释放数据<ul>
<li>当要废弃旧的数据时<code>loss_meter.reset_states()</code></li>
</ul>
</li>
</ul>
<h4 id="Compile-amp-Fit"><a href="#Compile-amp-Fit" class="headerlink" title="Compile&amp;Fit"></a>Compile&amp;Fit</h4><ul>
<li>Compile,类似装载弹药,可以指定loss,优化器,评估指标</li>
<li>Fix,完成标准创立</li>
<li>Evaluate,测试</li>
<li>Predic,拿创建好的模型来预测</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 一般的流程</span></span><br><span class="line">epoch <span class="keyword">in</span> range(num):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(db):</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:   <span class="comment"># 循环网络</span></span><br><span class="line">            <span class="comment"># [b, 784] =&gt; [b, 10]</span></span><br><span class="line">            logits = model(x)</span><br><span class="line">            y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">            loss_ce = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=<span class="literal">True</span>)</span><br><span class="line">            loss_ce = tf.reduce_mean(loss_ce)</span><br><span class="line"></span><br><span class="line">        grads = tape.gradient(loss_ce, model.trainable_variables)    <span class="comment"># 更新</span></span><br><span class="line">        optimizer.apply_gradients(zip(grads, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:   </span><br><span class="line">            <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">for</span> (x_test, y_test) <span class="keyword">in</span> test_db:    <span class="comment"># 测试</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 使用Keras的api快速建立标准化的神经网络</span></span><br><span class="line"><span class="comment"># 称network或model</span></span><br><span class="line">network = Sequential([...])   <span class="comment"># 如果是别的没学到的话...</span></span><br><span class="line">network.compile(</span><br><span class="line">        optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),    <span class="comment"># 指定优化器</span></span><br><span class="line">        loss=tf.loss.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),   <span class="comment"># 指定loss函数</span></span><br><span class="line">        metrics=[<span class="string">'accuracy'</span>]     <span class="comment"># 指定测试标准</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.fit(</span><br><span class="line">        db,   <span class="comment"># 要训练的数据集</span></span><br><span class="line">        epochs=<span class="number">10</span>,    <span class="comment"># 训练的周期</span></span><br><span class="line">        validation_data=db_test,    <span class="comment"># 用于做测试的数据集,一般写作ds_val</span></span><br><span class="line">        validation_freq=<span class="number">2</span>    <span class="comment"># 测试的周期,如这里一共10个epochs,每2个epochs就进行一次测试</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.evaluate(ds_val)    <span class="comment"># 训练完后对模型的评估,传入一个数据集</span></span><br><span class="line"></span><br><span class="line">pred = network(x)</span><br><span class="line"><span class="comment"># 或 pred = network.predict(x)    预测</span></span><br></pre></td></tr></table></figure>


<h4 id="自定义网络"><a href="#自定义网络" class="headerlink" title="自定义网络"></a>自定义网络</h4><ul>
<li>keras.Sequential(layer1, layer2, …)<ul>
<li>参数要继承自<code>keras.layers.Layer()</code></li>
<li>建立好网络后variable(w和b)是没有的<ul>
<li>法1:指定输入shape<code>network.build(input_shape=(None, 28*28))</code></li>
<li>法2:自动识别<code>network(x)</code><ul>
<li>这个的原理是调用了类中的call()方法,相当于network.<strong>call</strong>(x)。同理自定义类中也可如此</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>keras.layers.Layer()<ul>
<li>任何要自定义的层要继承自它</li>
</ul>
</li>
<li>keras.Model()<ul>
<li>compile/fit/evaluate</li>
<li>Sequential也是继承自该类，所以自定义的网络应该继承这个</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span><span class="params">(layers.Layer)</span>:</span>    <span class="comment"># 自定义层继承</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inp_dim, outp_dim)</span>:</span></span><br><span class="line">        super(MyDense, self).__init__() </span><br><span class="line">        self.kernel = self.add_weight(<span class="string">'name1'</span>, [inp_dim, outp_dim])   <span class="comment"># 用母类的add_weight而不是用tf.variable</span></span><br><span class="line">        self.bias = self.add_weight(<span class="string">'name2'</span>, [outp_dim])    <span class="comment"># name是给母类管理用的</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs, training=None)</span>:</span></span><br><span class="line">        out = inputs @ self.kernel + self.bias</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比</span></span><br><span class="line">layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同理Model自定义方法也一样</span></span><br></pre></td></tr></table></figure>

<h4 id="模型的加载与保持"><a href="#模型的加载与保持" class="headerlink" title="模型的加载与保持"></a>模型的加载与保持</h4><ul>
<li>save/load weights<ul>
<li>只保存模型参数</li>
<li>缺点是没有源代码，网络不得而知</li>
</ul>
</li>
<li>save/load entire model<ul>
<li>简单粗暴的</li>
</ul>
</li>
<li>saved_model <ul>
<li>通用的保存格式</li>
</ul>
</li>
</ul>
<p><strong>save/load weights</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save</span></span><br><span class="line">model.save_weights(<span class="string">'PATH'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">model = create_model()    <span class="comment"># 需要人工创建网络</span></span><br><span class="line">model.load_weights(<span class="string">'PATH'</span>)</span><br></pre></td></tr></table></figure>

<p><strong>save/load entire model</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save</span></span><br><span class="line">model.save(<span class="string">'PATH'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">model = tf.keras.models.load_model(<span class="string">'PATH'</span>)  <span class="comment"># 不需要人工创建网络</span></span><br></pre></td></tr></table></figure>

<p><strong>saved model</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save</span></span><br><span class="line">tf.saved_model.saved(model, <span class="string">'PATH'</span>)   <span class="comment"># 标准的，可供其他模型使用的保存</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">imported = tf.saved_model.load(path)   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 还原除网络</span></span><br><span class="line">f = imported.signature[<span class="string">'serving_defaut'</span>]</span><br></pre></td></tr></table></figure>



<h3 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h3><p>现实情况是我们并不知道模型的符合什么分布  </p>
<ul>
<li>model capacity,模型的学习能力<ul>
<li>显然项越多越高</li>
</ul>
</li>
<li>underfitting<ul>
<li>模型的表达能力弱于真实数据，如用直线拟合双曲线</li>
</ul>
</li>
<li>overfitting<ul>
<li>模型的表达能力大于真实数据，把不必要的噪声也拟合进来了</li>
<li>最常见</li>
</ul>
</li>
</ul>
<h4 id="检查overfitting"><a href="#检查overfitting" class="headerlink" title="检查overfitting"></a>检查overfitting</h4><h5 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h5><p>检查欠拟合和过拟合的方法   </p>
<p>一般情况下会把数据集切分(splitting)成三份,作用分别是train set，val set，test set<br>数据集一部分用来训练，一部分用来验证accuracy这是是显然的，那为什么有第三份呢？<br>因为在真实的需求中，是不是有取巧的人会把test用的数据集也用来训练，从而过拟合来达到很高的准确度(但实际它们已经过拟合了)<br>所以第三份是用来防止这种情况发生的，不参与训练的，最终检验模型的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">network.compile(</span><br><span class="line">        optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),   </span><br><span class="line">        loss=tf.loss.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),   </span><br><span class="line">        metrics=[<span class="string">'accuracy'</span>]   </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.fit(</span><br><span class="line">        db,    <span class="comment"># training</span></span><br><span class="line">        epochs=<span class="number">10</span>,</span><br><span class="line">        validation_data=db_test,   <span class="comment"># val set</span></span><br><span class="line">        validation_freq=<span class="number">2</span>   </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.evaluate(ds_val)   <span class="comment"># test set</span></span><br></pre></td></tr></table></figure>

<h5 id="K-fold-cross-validation"><a href="#K-fold-cross-validation" class="headerlink" title="K-fold cross-validation"></a>K-fold cross-validation</h5><p>由上面知，test set是完全不能动的，所以在切分的时候train set和val set可以随机的切分，可以防止网络记忆特性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在tensorflow中可以表现为</span></span><br><span class="line">shuffle(db)  <span class="comment"># 打散</span></span><br><span class="line">splices()   <span class="comment"># 切割</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可用keras的功能</span></span><br><span class="line">network.fit(db, validation_split=<span class="number">0.1</span>)   <span class="comment"># 按照9:1随机切分</span></span><br></pre></td></tr></table></figure>

<h4 id="减轻overfitting"><a href="#减轻overfitting" class="headerlink" title="减轻overfitting"></a>减轻overfitting</h4><h5 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h5><ul>
<li>L1-regularization<ul>
<li>loss加上lambda约束的一范式</li>
<li>$j(\theta) = -\sum^m_1{y_i\log_e{\bar y_i} + (1-y_i)\log_e{(1-\bar y_i)}} + \lambda \sum_i^n{|\theta_i|}$</li>
</ul>
</li>
<li>L2-regularization<ul>
<li>loss加上lambda约束的一范式</li>
<li>$J(W;x,y)+\frac{1}{2} \times ||W||^2$</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 法一：在一层网络中添加kernel_regularizer参数</span></span><br><span class="line">keras.layers.Dense(<span class="number">16</span>,</span><br><span class="line">                    kernel_regularizer=keras.regularizers.L2(<span class="number">0.001</span>)   <span class="comment"># 0.001就是 lambda</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 法二：更加灵活的自己控制范式</span></span><br><span class="line">loss_regularization = []   </span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> network.trainable_variables:     <span class="comment"># 取范式里面的参数w1,w2...b1,b2...取法很灵活</span></span><br><span class="line">    loss_regularization.append(tf.nn.l2_loss(p))</span><br><span class="line">loss_regularization = tf.reduce_sum(tf.stack(loss_regularization))  <span class="comment"># 做一范式还是二范数...</span></span><br><span class="line"></span><br><span class="line">loss = loss + <span class="number">0.0001</span>*loss_regularization</span><br></pre></td></tr></table></figure>

<h4 id="动量与学习率"><a href="#动量与学习率" class="headerlink" title="动量与学习率"></a>动量与学习率</h4><h5 id="Momentum-动量"><a href="#Momentum-动量" class="headerlink" title="Momentum 动量"></a>Momentum 动量</h5><p>由于梯度的更新，会有大幅的反复跳跃的现象，动量就是在更新方向的基础上结合上一阶段的方向进行梯度更新，从而使得更平缓，像踩刹车一样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = SGD(learing_rate=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>)   <span class="comment"># momentum 就在超参数lambda</span></span><br><span class="line">optimizer = RMSprop(learing_rate=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">optimizer = Adam(learing_rate=<span class="number">0.02</span>,   <span class="comment"># Adam没有momentum(内置),但有beta_1,beta_2</span></span><br><span class="line">        beta_1=<span class="number">0.9</span>,</span><br><span class="line">        beta_2=<span class="number">0.999</span>)</span><br></pre></td></tr></table></figure>

<h5 id="Learning-rate-学习率"><a href="#Learning-rate-学习率" class="headerlink" title="Learning rate 学习率"></a>Learning rate 学习率</h5><p>学习率动态调整来优化网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">optimizer = SGD(learing_rate=<span class="number">0.02</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    <span class="comment"># get loss</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># change learing_rate 比较简单粗暴</span></span><br><span class="line">    optimizer.learing_rate = <span class="number">0.2</span>*(<span class="number">100</span>-epoch)/<span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># update weights</span></span><br></pre></td></tr></table></figure>

<h4 id="Early-Stopping-amp-Dropout"><a href="#Early-Stopping-amp-Dropout" class="headerlink" title="Early Stopping &amp; Dropout"></a>Early Stopping &amp; Dropout</h4><h5 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h5><p>很多情况下虽然training accuracy还在上升，但是validation accuracy以及达到最优甚至开始下降了，这是就需要以前终止</p>
<h5 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h5><p>和overfitting的情况一样，为减少噪声的干扰，可以减少节点数(?矩阵里面的?),learning less to learning better</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">                      layers.Dropout(<span class="number">0.5</span>),    <span class="comment"># 0.5 rate to dropout</span></span><br><span class="line">                      layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">                      layers.Dropout(<span class="number">0.5</span>),    <span class="comment"># 0.5 rate to dropout</span></span><br><span class="line">                      ...</span><br><span class="line">                    ])</span><br></pre></td></tr></table></figure>
<p>因为training和test的策略不同(training时为得到更好的w,b，而使用dropout的方法来减小overfitting,所以开启dropout，test是测试模型，所以不用开)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># training</span></span><br><span class="line">network(x, training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># validation || test</span></span><br><span class="line">network(x, training=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h5 id="Stochastic"><a href="#Stochastic" class="headerlink" title="Stochastic"></a>Stochastic</h5><h5 id="Deterministic"><a href="#Deterministic" class="headerlink" title="Deterministic"></a>Deterministic</h5><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>在处理图像问题时，使用全连接的方式会导致大量的资源占用.<br>于是由生物学上眼睛可视域的启发，我们采用局部连接，然后滑动直至扫描全部输入。特点在于对于相同的层如(RGB),每次扫描的观察方式(卷积核)是一样的(weight sharing)<br>所以学习的时候就大大减少了参数量  </p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>信号的叠加叫做卷积,得到的结果叫做<strong>feature map</strong>  </p>
<p>$$<br>y(t)=x(t) * h(t)=\int^\infty _ {-\infty}  x(\tau)h(t-\tau)\mathrm{d}x<br>$$</p>
<p>* 表示卷积操作,x就相当于输入,h就相当于观察方式(卷积核),t就相当偏移量，扫过整个图片t发生改变x和h卷积出信号输出y</p>
<h4 id="Padding-amp-Stride"><a href="#Padding-amp-Stride" class="headerlink" title="Padding &amp; Stride"></a>Padding &amp; Stride</h4><ul>
<li>Padding<ul>
<li>把输入层扩大(虚的)然后扫描后就能得到维度与输入相等的输出</li>
</ul>
</li>
<li>Stride<ul>
<li>把扫描的步长加大，就能减少输出的维度</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layers.Conv2D(<span class="number">4</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="string">'samd'</span>)  <span class="comment"># 卷积核个数,5*5,步长,'same'可以保证输入维度等于输出</span></span><br></pre></td></tr></table></figure>

<h4 id="Channels"><a href="#Channels" class="headerlink" title="Channels"></a>Channels</h4><ul>
<li>设输入是[1, 32, 32, 3],32*32的图片,3个通道<ul>
<li>那我们的一个卷积核可以是[3, 5, 5] 3表示输入通道的数量(RGB)</li>
<li>最后可以得到一个[b, 30, 30, 1]的输出</li>
</ul>
</li>
<li>如果使用多个核如[N, 3, 5, 5]那就能得到N个[b, 30, 30, 1]即[b, 30, 30, N]</li>
</ul>
<p>多通道输出，多通道输入</p>
<h4 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h4><p>$$<br>O _ {mn} = \sum {x _ {ij} * w _ {ij}} + b  \<br>\frac{\delta Loss}{\delta w _ {ij}}<br>$$</p>
<h3 id="Classic-Network"><a href="#Classic-Network" class="headerlink" title="Classic Network"></a>Classic Network</h3><h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><p>When the network get deeper, above 20, is get harder to training, even make trains revoke.</p>
<h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>Residual</p>
<h2 id="Sequence"><a href="#Sequence" class="headerlink" title="Sequence"></a>Sequence</h2><p>Signal with time order</p>
<ul>
<li>sequence embed<ul>
<li>turn digital signal into a sequence</li>
</ul>
</li>
</ul>
<p>Many sets can be like a sequence. mnist for example[b, 28, 28]. can expand like [b, time, 28] or [time, b, 28] and so on.</p>
<p>But a sequence better to expand like a time orde things [time, b, 28] is much better. It depend on how you expand.</p>
<p>Here are some rules:</p>
<ul>
<li>semantic similarity</li>
<li>trainable</li>
</ul>
<h3 id="Cycle-network"><a href="#Cycle-network" class="headerlink" title="Cycle network"></a>Cycle network</h3><p>Two question:</p>
<ul>
<li><p>Long sentence</p>
<ul>
<li>weight sharing</li>
<li>We can do like a conv_net</li>
</ul>
</li>
<li><p>Context information</p>
<ul>
<li>It is a pertinence bettween word and word</li>
<li>Here is the example formulation</li>
</ul>
</li>
</ul>
<p>$$\begin{aligned}<br>h_t &amp;= f_w(h_{t-1}, x_t) \<br>h_t &amp;= tanh(W_{hh}h_{t-1} + W{xh}x_t) \<br>y_t &amp;= W_{hy}h_t \<br>\end{aligned}$$</p>
<h3 id="RNNlayer"><a href="#RNNlayer" class="headerlink" title="RNNlayer"></a>RNNlayer</h3><h4 id="SimpleRNN"><a href="#SimpleRNN" class="headerlink" title="SimpleRNN"></a>SimpleRNN</h4><p>$$<br>\begin{aligned}<br>call &amp;= xw_{xh} + h_tw_{hh}, (for\ each\ item\ in\ timeline) \<br>out_1, h_1 &amp;= call(x, h_0) \<br>out_2, h_2 &amp;= call(x, h_1) \<br>out_t, h_t &amp;= call(x, h_{t-1})<br>\end{aligned}<br>$$</p>
<p>$h_t$ and $out_t$ is the same thing(id) but have difference meaning </p>
<h4 id="Optimize"><a href="#Optimize" class="headerlink" title="Optimize"></a>Optimize</h4><ul>
<li>Step 1:Gradient Exploding<ul>
<li>Gradient Clipping</li>
<li>$grad = \frac{|grad|}{grad}$ ,shrink to 1 and mult $15\times{lr}$</li>
<li><code>grads = [tf.clipe_by_norm(g, 15) for g in grads]</code></li>
</ul>
</li>
<li>Step 2:Gradient Vanishing<ul>
<li><em>LSTM</em> \ <em>GRU</em>  </li>
</ul>
</li>
</ul>
<h5 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h5><p>Compare with RNN(short term memory), which can only remenber nearly sentence.<em>LSTM</em> is long short term memory.</p>
<p>LSTM use three gates(sigmoid) to contral the signal. </p>
<ul>
<li>Forget gate<ul>
<li>$f_t = \sigma(W_f\cdot[h_{t-1}, x_t]+b_f)$</li>
<li><img src="./static/forget_gate.png" style="zoom:50%"></li>
</ul>
</li>
<li>Input gate<ul>
<li>$$<br>\begin{aligned}<br>  i_t &amp;= \sigma(W_i\cdot[h{t-1}, x_t] + b_i) \<br>  \widetilde{C_t} &amp;= tanh(W_C\cdot[h_{t-1}, x_t] + b_C)<br>\end{aligned}<br>$$</li>
<li><img src="./static/input_gate.png" style="zoom:50%"></li>
</ul>
</li>
<li>Cell state<ul>
<li>$C_t = f_f * C_{t-1} + i_t * \widetilde{C_t}$</li>
<li><img src="./static/cell_state.png" style="zoom:50%"></li>
</ul>
</li>
<li>Output gate<ul>
<li>$$<br>  \begin{aligned}<br>  O_t &amp;= \sigma(W_o[h_{t-1}, x_t] + b_o) \<br>  h_t &amp;= O_t * tanh(C_t)<br>  \end{aligned}$$</li>
<li><img src="./static/output_gate.png" style="zoom:50%">

</li>
</ul>
</li>
</ul>
<h5 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h5><h2 id="Auto-Encoder"><a href="#Auto-Encoder" class="headerlink" title="Auto-Encoder"></a>Auto-Encoder</h2><p>Why we need:</p>
<ul>
<li>Dimension reduction</li>
<li>Visualization</li>
<li>Take advantages of <em>unsupervised</em> date<ul>
<li>Unsupervise</li>
<li><em>Reconstruct</em> itself</li>
</ul>
</li>
</ul>
<h3 id="Denoising-AutoEncoder"><a href="#Denoising-AutoEncoder" class="headerlink" title="Denoising AutoEncoder"></a>Denoising AutoEncoder</h3><p>Add some noise and can still reconstruct well. Means model can dig out information from a mass data.</p>
<h3 id="Dropout-AutoEncoder"><a href="#Dropout-AutoEncoder" class="headerlink" title="Dropout AutoEncoder"></a>Dropout AutoEncoder</h3><p>Use dropout to autoencoder. It the hard dropouted network can than the disdropout network do better.</p>
<h3 id="Adversarial-AutoEncoder"><a href="#Adversarial-AutoEncoder" class="headerlink" title="Adversarial AutoEncoder"></a>Adversarial AutoEncoder</h3><h3 id="Variational-AutoEncoder"><a href="#Variational-AutoEncoder" class="headerlink" title="Variational AutoEncoder"></a>Variational AutoEncoder</h3><h1 id="Gen"><a href="#Gen" class="headerlink" title="Gen"></a>Gen</h1><ul>
<li>Painter or Generator</li>
<li>Critic or Discriminator</li>
</ul>
<p>$$<br>\begin{aligned}<br>min_G\ max_D\ L(D,G) &amp;= E_{x<del>p_r(x)}[\log{D(x)}] + E_{z</del>p_r(z)}[\log{1-D(G(z))}] \<br>&amp;= E_{x<del>p_r(x)}[\log{D(x)}] + E_{x</del>p_r(x)}[\log{1-D(x)}] \<br>\end{aligned}<br>$$</p>
<p>Both of they want to maximum and than get a nash equilibrium</p>
<h3 id="Nash-Equilibrium"><a href="#Nash-Equilibrium" class="headerlink" title="Nash Equilibrium"></a>Nash Equilibrium</h3><ul>
<li>Q1.Where will D converge, given fixed G</li>
<li>Q2.Where will G converge, after optimal D</li>
</ul>
<h3 id="tensorflow运行机制"><a href="#tensorflow运行机制" class="headerlink" title="tensorflow运行机制"></a>tensorflow运行机制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本质 tf = tensor + 计算图</span></span><br><span class="line"><span class="comment"># tensor 数据</span></span><br><span class="line"><span class="comment"># op 操作</span></span><br><span class="line"><span class="comment"># graphs 数据操作</span></span><br><span class="line"><span class="comment"># session 会话核心</span></span><br></pre></td></tr></table></figure>

<h3 id="四则运算"><a href="#四则运算" class="headerlink" title="四则运算"></a>四则运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果是变量的话要先init</span></span><br><span class="line">tf.add(data1+data2)</span><br><span class="line">tf.multiply(data1,data2)</span><br><span class="line">tf.subtract(data1,data2)</span><br><span class="line">tf.divide(data1,data2)</span><br><span class="line"></span><br><span class="line">dataCopy = tf.assign(x1,x2)  <span class="comment"># 把x2的值赋给x1</span></span><br><span class="line">dataCopy.eval()  <span class="comment"># 相当于sess.run(dataCopy)</span></span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line">tf.get_default_session().run(dataCopy)</span><br></pre></td></tr></table></figure>

<h3 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 数据装载</span><br><span class="line">x1 &#x3D; tf.placeholder(tf.float32)</span><br><span class="line">x2 &#x3D; tf.placeholder(tf.float32)</span><br><span class="line">dataAdd &#x3D; tf.add(x1,x2)</span><br><span class="line">sess.run(dataAdd,feed_dict&#x3D;&#123;x1:2,x2:4&#125;)</span><br><span class="line"># 1.tensor张量dataAdd  2.追加的数据 语法同上</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 矩阵~&#x3D;数组 矩阵整体[] 每列都要[]包起来 每[]就是一行</span><br><span class="line">x1 &#x3D; tf.constant([2,2])</span><br><span class="line">x2 &#x3D; tf.constant([[2],</span><br><span class="line">				  [2]])</span><br><span class="line">x1.shape  #维度</span><br><span class="line">sess.run(x1)   # 打印整体</span><br><span class="line">sess.run(x1.[0])   # 打印第0行</span><br><span class="line">sess.run(x1.[:,0])   # 打印第0列</span><br><span class="line"></span><br><span class="line"># 运算</span><br><span class="line">tf.matmul(x1,x2)  # 矩阵乘法</span><br><span class="line">tf.multiply()  # 普通乘法 对应元素相乘</span><br><span class="line">tf.add()   # ..</span><br><span class="line"></span><br><span class="line"># 特殊矩阵的初始化</span><br><span class="line">tf.zeros([2,3])  # 两行三列空间矩阵</span><br><span class="line">tf.onex([2,3])   # 全一矩阵</span><br><span class="line">tf.fill([2,3],15)  # 填充矩阵,全为15的2*3矩阵</span><br><span class="line"></span><br><span class="line">tf.zeros_like(x1)  # 矩阵维度同x1的全零矩阵</span><br><span class="line">x3 &#x3D; tf.linspace(0.0,2.0,11)  # 生成一个矩阵，元素从0到2均匀分成11分</span><br><span class="line">x4 &#x3D; tf.random_uniform([2,3],-1,2)  # 生成2*3的一个矩阵，元素是-1到2的随机数</span><br></pre></td></tr></table></figure>

<h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>loss function:<br>$$loss = \sum_i(w\times x_i+b-y_i)^2 \tag{1}$$<br>loss 累加会很大，所以一般会除以元素个数n,结果还是一样的</p>
<p>$$w^<code>= w - lr \times \frac{\partial{loss}}{\partial{w}} \tag{2}$$
$$b^</code> = b - lr \times \frac{\partial{loss}}{\partial{b}}$$<br>这样就会得到新的w b,再返回第(1)步，如此循环就能得到最回事的w b</p>
<p>对loss的求导其实有规律可循:<br>$$\frac{\partial{loss}}{\partial{w}} = \frac{2}{n}\sum(wx + b - y)x$$<br>$$\frac{\partial{loss}}{\partial{b}} = \frac{2}{n}\sum(wx + b - y)$$</p>
<h3 id="Discrete-Prediction"><a href="#Discrete-Prediction" class="headerlink" title="Discrete Prediction"></a>Discrete Prediction</h3><p>离散值预测  </p>
<p>Classification (分类)为例<br>显然的离散的问题，那我们要怎么解决离散的问题呢？<br>激活函数 activation<br>常见的有ReLU和sigmoid<br>目的是为了把线性的值离散化，然后才能套用上面的公式  </p>
<p>但是就算用一个函数把线性模型离散化了，但还是太简单<br>所以引入隐藏层概念<br>input -&gt; h1 -&gt; h2 -&gt; out<br>经过多层隐藏层问题就更加离散了<br>$$h1 = relu(x@w_1 + b_1)$$<br>$$h2 = relu(h1@w_2 + b_2)$$<br>$$out = relu(h2@w_3 + b_3)$$<br>@表示矩阵乘法, 每道工序都有自己的参数   </p>
<p>那参数w和b怎么确定呢？<br>若我们想要识别0~9,那我们是不是应该希望最后输出是有10类(一个[1,10]的矩阵,每个元素可以代表一个数字)<br>那么根据矩阵运算的规则(nm*mt = nt),所以我们只要控制每层运算符合矩阵乘法规则且最后输出是我们想要的规模就好<br>最后再用out来计算loss(这里是欧氏距离(n维空间两点的距离)的loss)<br>然后就可以反复更新w` b`了</p>
<hr>
<h1 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h1><p>tensorflow的弟弟版,因为他不能GPU计算</p>
<h3 id="基本操作-2"><a href="#基本操作-2" class="headerlink" title="基本操作"></a>基本操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.array([第一行],[第二行]...)</span><br><span class="line">x1.shape   <span class="comment"># 打印规模</span></span><br><span class="line">np.zeros([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">np.ones([<span class="number">2</span>,<span class="number">3</span>])   <span class="comment"># 零矩阵和单位矩阵的初始化（2行3列）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 改查</span></span><br><span class="line">x1[<span class="number">1</span>,<span class="number">2</span>]=<span class="number">5</span>  <span class="comment"># 第二行第一列改成5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基本运算</span></span><br><span class="line">x1*x2   <span class="comment"># 加减乘除都是对应元素加减乘除</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵运算</span></span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><p><code>import matplotlib as plt</code></p>
<h3 id="基本操作-3"><a href="#基本操作-3" class="headerlink" title="基本操作"></a>基本操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line">y = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 折线图</span></span><br><span class="line">plt.plot(x,y,<span class="string">"r"</span>)  <span class="comment"># 1.x轴 2.y轴 3.颜色</span></span><br><span class="line">plt.plot(x,y,<span class="string">"g"</span>,lw=<span class="number">10</span>)  <span class="comment"># 1.x轴 2.y轴 3.颜色 4.折线的宽度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 柱状图</span></span><br><span class="line">plt.bar(x,y,<span class="number">0.9</span>,alpha=<span class="number">1</span>,color=<span class="string">'b'</span>)  <span class="comment"># 3.柱状图的宽 4.alpha通道,即透明度</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>













<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">36</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
