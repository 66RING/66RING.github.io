<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/25/universe/GDB_Usage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/universe/GDB_Usage/" class="post-title-link" itemprop="url">GDB usage</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-25 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-25T00:00:00+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-17 14:23:22" itemprop="dateModified" datetime="2020-06-17T14:23:22+08:00">2020-06-17</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Basic-Usage"><a href="#Basic-Usage" class="headerlink" title="Basic Usage"></a>Basic Usage</h1><ul>
<li>Make sure compile file with <code>-g</code> option, which mean turn on debugging with gdb<ul>
<li>like this: <code>gcc -g main.cpp -o main</code></li>
</ul>
</li>
</ul>
<h2 id="Debugging-with-GDB"><a href="#Debugging-with-GDB" class="headerlink" title="Debugging with GDB"></a>Debugging with GDB</h2><ul>
<li>open file<ul>
<li>here are two way</li>
<li><code>gdb filename</code><ul>
<li><code>gdb path/to/main</code></li>
</ul>
</li>
<li><code>gdb</code> -&gt; <code>file path/to/main</code></li>
</ul>
</li>
<li>show list<ul>
<li>use <code>l</code> command to show source code with line number</li>
</ul>
</li>
<li>add breakpoint<ul>
<li>use <code>b linenum</code> to add breakpoint, such as <code>b 1</code> add breakpoint at line 1</li>
<li>or use <code>b functionname</code> to add breakpoint, such as <code>b main</code> add breakpoint at main function</li>
</ul>
</li>
<li>show breakpoint information<ul>
<li><code>i b</code> i for information, b for breakpoint</li>
</ul>
</li>
<li>delete breakpoint<ul>
<li><code>d pointid</code> pointid from <code>i b</code></li>
<li><code>i b</code> information will be like a order list. If delete a pointid in the previous, the next point will just add in the end of the idlist.</li>
</ul>
</li>
<li>run debug<ul>
<li><code>r</code></li>
<li>use <code>p variable</code> will show the variable information</li>
</ul>
</li>
<li>gdb controler<ul>
<li><code>n</code> for next line, one step debugging</li>
<li><code>s</code> for step into(one step)</li>
<li><code>set args [parameter]</code> for command line args</li>
</ul>
</li>
<li>finish function and continue<ul>
<li><code>finish</code> for finish function</li>
<li><code>c</code> for continue until program exit or breakpoint</li>
</ul>
</li>
<li>quit gdb<ul>
<li><code>q</code></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/25/universe/linux%E5%93%B2%E5%AD%A6%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/25/universe/linux%E5%93%B2%E5%AD%A6%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">Linux哲学记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-25 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-25T00:00:00+08:00">2020-02-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-15 21:34:14" itemprop="dateModified" datetime="2020-06-15T21:34:14+08:00">2020-06-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="开发效率问题"><a href="#开发效率问题" class="headerlink" title="开发效率问题"></a>开发效率问题</h4><p><strong>闭源</strong> </p>
<p>在一个项目开发中<br>假设一个人开发效率是100%, 因为他能全身心投入项目中. 两个人每个人的开发效率是80%, 其中20%是因为另一个人损耗的沟通成本, 那么两个人的效率就像一个人的160%.<br>但是如果人数增加, 每个人的沟通成本也会增加, 最后发现效率降低. 所以一个多人开发的大型项目理论上是不可能成功的.</p>
<p>那么框架, 框架的扩展性就显得尤其重要.</p>
<p><strong>开源</strong></p>
<p>一个开源项目往往有成百上千的人参与, 那根据上面的理论, 一个开源项目就不会成功.<br>但是当人数多到一定程度的时候, 一个潜在的错误一旦出现就会立刻得到解决, 反而大大提高了效率.<br>但是当人数多到一定程度的时候, 已经不在上面理论的范畴之内了, 就像物理世界的<strong>宏观和微观问题</strong>.<br>在多人开发的开源项目中的理论就遵循<em>linus</em> 提出的<strong>linus理论</strong>. 开源项目的成功就足以证明其正确性.</p>
<h4 id="开源程序的责任"><a href="#开源程序的责任" class="headerlink" title="开源程序的责任"></a>开源程序的责任</h4><p>一个开源程序往往有一个开源协议, 这些协议往往把责任只想广大社区的开发者, 也就是我们自己.<br>所以我们获取的开源软件我们自己, 我们广大开发者就要对其负责.</p>
<p>举个例子:比如你找学霸抄作业, 但是抄来的答案全是错是, 你该怪学霸吗?<br>于是你在抄之前, 问了一下别人是不是也抄了学霸的作业, 别人告诉你说没问题, 或者你检查了一遍发现没问题. 那社区就保证了它的安全性.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/23/universe/linux_tips/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/23/universe/linux_tips/" class="post-title-link" itemprop="url">linux command line</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-23 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-23T00:00:00+08:00">2020-02-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-15 21:34:14" itemprop="dateModified" datetime="2020-06-15T21:34:14+08:00">2020-06-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Command-line"><a href="#Command-line" class="headerlink" title="Command line"></a>Command line</h1><h2 id="Some-Ussful-tips"><a href="#Some-Ussful-tips" class="headerlink" title="Some Ussful tips"></a>Some Ussful tips</h2><ul>
<li><code>#</code> can delete a sub-string <strong>from the very beginning</strong> , like <code>var=apple; echo ${var#app}</code>, which will print <code>le</code>. <ul>
<li><code>#</code>, delete a few things as posible</li>
<li><code>##</code>, (greedy)delete a more things as posible</li>
<li><code>%</code>, use like <code>#</code>, but it delete from the end<ul>
<li><code>echo ${var%el}</code>, print app</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="shebang"><a href="#shebang" class="headerlink" title="shebang"></a>shebang</h2><p>a shebang is the interpreter of this script. like this</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br></pre></td></tr></table></figure>

<h2 id="Redirection"><a href="#Redirection" class="headerlink" title="Redirection"></a>Redirection</h2><table>
<thead>
<tr>
<th>command</th>
<th>function</th>
</tr>
</thead>
<tbody><tr>
<td>a &gt; b</td>
<td>a’s std output override into b</td>
</tr>
<tr>
<td>a &gt;&gt; b</td>
<td>a’s std output appand into b</td>
</tr>
<tr>
<td>a &lt; b</td>
<td>b as a’s input</td>
</tr>
<tr>
<td>a &lt;&lt; b</td>
<td>here document</td>
</tr>
<tr>
<td>a &lt;&lt;&lt; b</td>
<td>here</td>
</tr>
</tbody></table>
<h3 id="Here-document"><a href="#Here-document" class="headerlink" title="Here document"></a>Here document</h3><p>A block as input</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> &lt;&lt; token</span><br><span class="line">    text</span><br><span class="line">token</span><br><span class="line"></span><br><span class="line">example:</span><br><span class="line"><span class="built_in">echo</span> &lt;&lt; __EOF__</span><br><span class="line">halo</span><br><span class="line">__EOF__</span><br><span class="line"></span><br><span class="line">$ halo</span><br></pre></td></tr></table></figure>

<h3 id="Here"><a href="#Here" class="headerlink" title="Here"></a>Here</h3><p>a bit like <em>here document</em>, a line as input.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">read</span> ans1 ans2 ans3 &lt;&lt;&lt; <span class="string">"a1 a2 a3"</span></span><br><span class="line"></span><br><span class="line">a1 a2 a3 as input to <span class="built_in">read</span> process</span><br></pre></td></tr></table></figure>

<h2 id="Useful-commands"><a href="#Useful-commands" class="headerlink" title="Useful commands"></a>Useful commands</h2><h3 id="Grep"><a href="#Grep" class="headerlink" title="Grep"></a>Grep</h3><p><code>grep [option] file1 file2...</code></p>
<p>The most commonly used<br>| options  | description                    |<br>|———-|——————————–|<br>| -i       | –ignore-case                  |<br>| -v       | –revert-mathch                |<br>| -c       | –count                        |<br>| -l       | –file-with-match              |<br>| -L       | –file-without-math            |<br>| -n       | –line-number                  |<br>| -h       | no filename in multi file mode |<br>| -a/-text | do not ignore binary data      |<br>| -e       | –regexp                       |<br>| -f       | specify regexp file            |</p>
<h3 id="Sed"><a href="#Sed" class="headerlink" title="Sed"></a>Sed</h3><p>sed can deal with text file with script-command or script-file.</p>
<p><code>sed [options][target-file]</code></p>
<table>
<thead>
<tr>
<th>options</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>-e</td>
<td></td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<p>script action</p>
<table>
<thead>
<tr>
<th>action</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>a\</td>
<td>add a new line or lines next to current line</td>
</tr>
<tr>
<td>c\</td>
<td>replace current line with some text</td>
</tr>
<tr>
<td>d</td>
<td>delete line</td>
</tr>
<tr>
<td>i\</td>
<td>insert text befor curent line</td>
</tr>
<tr>
<td>h</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>H</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>g</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>G</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>I</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>p</td>
<td>print line</td>
</tr>
<tr>
<td>n</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>q</td>
<td>quit sed</td>
</tr>
<tr>
<td>r</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>!</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>s</td>
<td>replace string with other string</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<p>replace identifier</p>
<table>
<thead>
<tr>
<th>options</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>g</td>
<td>global replace in this line</td>
</tr>
<tr>
<td>p</td>
<td>print line</td>
</tr>
<tr>
<td>w</td>
<td>write line into file</td>
</tr>
<tr>
<td>x</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>y</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<h3 id="Cut"><a href="#Cut" class="headerlink" title="Cut"></a>Cut</h3><table>
<thead>
<tr>
<th>options</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
<tr>
<td>&lt;++&gt;</td>
<td>&lt;++&gt;</td>
</tr>
</tbody></table>
<h2 id="Regular-Expressions"><a href="#Regular-Expressions" class="headerlink" title="Regular Expressions"></a>Regular Expressions</h2><h3 id="Literals"><a href="#Literals" class="headerlink" title="Literals"></a>Literals</h3><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>.</td>
<td>match any char</td>
</tr>
<tr>
<td>char</td>
<td>literaly a char</td>
</tr>
</tbody></table>
<h3 id="Metacharacters"><a href="#Metacharacters" class="headerlink" title="Metacharacters"></a>Metacharacters</h3><h4 id="Anchors"><a href="#Anchors" class="headerlink" title="Anchors"></a>Anchors</h4><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>^</td>
<td>found at the begin of line</td>
</tr>
<tr>
<td>$</td>
<td>found at the end of line</td>
</tr>
</tbody></table>
<h4 id="Quantifiers"><a href="#Quantifiers" class="headerlink" title="Quantifiers"></a>Quantifiers</h4><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>?</td>
<td>match <strong>an element</strong> zero or one time</td>
</tr>
<tr>
<td>*</td>
<td>match <strong>an element</strong> zero or more times</td>
</tr>
<tr>
<td>+</td>
<td>match <strong>an element</strong> one or more times</td>
</tr>
<tr>
<td>{}</td>
<td>match <strong>an element</strong> a specific number of times</td>
</tr>
<tr>
<td>{n,}</td>
<td>match <strong>an element</strong> if it occurs n or more times</td>
</tr>
<tr>
<td>{,n}</td>
<td>match <strong>an element</strong> if it occurs no more than n times</td>
</tr>
</tbody></table>
<p>A quantifiers is after <strong>an element</strong>, such as <code>.*</code> means match any char with any lengh equivalent any string.</p>
<p>An element can like this <code>[A_Z]</code>and this<code>[:digit:]</code>. We can see the pattern before a quantifiers as a whole.</p>
<h4 id="Bracket-Expressions-and-Character-Classes"><a href="#Bracket-Expressions-and-Character-Classes" class="headerlink" title="Bracket Expressions and Character Classes"></a>Bracket Expressions and Character Classes</h4><ul>
<li><p>Bracket Expressions</p>
<ul>
<li>specify a set of characters to be match<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep -h <span class="string">'[bg]zip'</span> test.txt</span><br><span class="line">bzip2</span><br><span class="line">bzip123</span><br><span class="line">gzip</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Negation</p>
<ul>
<li>If the first char in a bracket expression is a caret(^), the <strong>remaining char</strong> are taken to be a set of chars that must not be present at the given char position.<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep -h <span class="string">'[^bg]zip'</span> test.txt</span><br><span class="line">bunzip</span><br><span class="line">gunzip</span><br><span class="line">funzip</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Character Classes</p>
<ul>
<li>A set of characters range<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ grep -h <span class="string">'[^ABCDEF]'</span> test.txt</span><br><span class="line">or you can</span><br><span class="line">$ grep -h <span class="string">'[^A-F]'</span> test.txt</span><br><span class="line"></span><br><span class="line">Here are more expressions</span><br><span class="line">$ grep -h <span class="string">'[A-Fa-z0-9]'</span> test.txt</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>POSIX Character Class</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>char</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>[:alnum:]</td>
<td>alphanumeric characters.equivalent to[A-Za-z0-9]</td>
</tr>
<tr>
<td>[:word:]</td>
<td>same as alnum, with the addition of the underscore char(_)</td>
</tr>
<tr>
<td>[:alpha:]</td>
<td>[A-Za-z]</td>
</tr>
<tr>
<td>[:blank:]</td>
<td>space and tab char</td>
</tr>
<tr>
<td>[:digit:]</td>
<td>number 0 through 9</td>
</tr>
<tr>
<td>[:lower:]</td>
<td>the lowercase letters</td>
</tr>
<tr>
<td>[:upper:]</td>
<td>the uppercase letters</td>
</tr>
<tr>
<td>[:space:]</td>
<td>[\t\r\n\v\f]</td>
</tr>
<tr>
<td>[:xdigit:]</td>
<td>chars used to express hexadecimal numbers.[0-9a-fA-F]</td>
</tr>
</tbody></table>
<h2 id="Flow-control"><a href="#Flow-control" class="headerlink" title="Flow control"></a>Flow control</h2><h3 id="if-statements"><a href="#if-statements" class="headerlink" title="if statements"></a>if statements</h3><h4 id="File-Expressions"><a href="#File-Expressions" class="headerlink" title="File Expressions"></a>File Expressions</h4><table>
<thead>
<tr>
<th>command</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>f1 -ef f2</td>
<td>f1 and f2 have the same indoe number</td>
</tr>
<tr>
<td>f1 -nt f2</td>
<td>f1 newer than f2</td>
</tr>
<tr>
<td>f1 -ot f2</td>
<td>f1 older than f2</td>
</tr>
<tr>
<td>-d f1</td>
<td>f1 exists an is a directory</td>
</tr>
<tr>
<td>-e f1</td>
<td>f1 exists</td>
</tr>
<tr>
<td>-f f1</td>
<td>f1 is a regular file</td>
</tr>
</tbody></table>
<h4 id="String-Expressions"><a href="#String-Expressions" class="headerlink" title="String Expressions"></a>String Expressions</h4><table>
<thead>
<tr>
<th>command</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>string</td>
<td>string is not null</td>
</tr>
<tr>
<td>-n string</td>
<td>the lenth of string is greater than zero</td>
</tr>
<tr>
<td>-z string</td>
<td>the lenth of string is zero</td>
</tr>
<tr>
<td>s1 = s2 or s1 == s2</td>
<td>equal</td>
</tr>
<tr>
<td>s1 !=s2</td>
<td>not equal</td>
</tr>
<tr>
<td>s1 &gt; s2</td>
<td>s1 sorts after s2</td>
</tr>
<tr>
<td>s1 &lt; s2</td>
<td>s1 sortf before s2</td>
</tr>
</tbody></table>
<h4 id="Integer-Expressions"><a href="#Integer-Expressions" class="headerlink" title="Integer Expressions"></a>Integer Expressions</h4><table>
<thead>
<tr>
<th>command</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>int1 -eq int2</td>
<td>equal</td>
</tr>
<tr>
<td>int1 -ne int2</td>
<td>not equal</td>
</tr>
<tr>
<td>-le</td>
<td>less or equal</td>
</tr>
<tr>
<td>-lt</td>
<td>less than</td>
</tr>
<tr>
<td>-ge</td>
<td>greater or equal</td>
</tr>
<tr>
<td>-gt</td>
<td>greater</td>
</tr>
</tbody></table>
<h4 id="A-More-Modern-Version-of-test"><a href="#A-More-Modern-Version-of-test" class="headerlink" title="A More Modern Version of test"></a>A More Modern Version of test</h4><ul>
<li><strong>Designed of string</strong><ul>
<li><code>[[ command ]]</code></li>
</ul>
</li>
</ul>
<p>and here is a new feature:<br><code>string1 =~ regex</code>. This return true if string1 matched by the extended regular expression</p>
<ul>
<li><strong>Designed of Integer</strong><ul>
<li>`(( command ))</li>
<li>integer only</li>
</ul>
</li>
</ul>
<h3 id="case"><a href="#case" class="headerlink" title="case"></a>case</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> word <span class="keyword">in</span></span><br><span class="line">    [pattern [| pattern]...) commands ;;]...</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$num</span> <span class="keyword">in</span></span><br><span class="line">    0) <span class="built_in">echo</span> <span class="string">"zero"</span></span><br><span class="line">        ;;  <span class="comment"># ;; break and out of case</span></span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<h4 id="pattern"><a href="#pattern" class="headerlink" title="pattern"></a>pattern</h4><table>
<thead>
<tr>
<th>pattern</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>a)</td>
<td>matches if word equals a</td>
</tr>
<tr>
<td>[[:alpha:]]</td>
<td>matches if word is a single alphabetic</td>
</tr>
<tr>
<td>???)</td>
<td>matches if word is exactly three characters long</td>
</tr>
<tr>
<td>*.txt</td>
<td>matches if word ends with .txt</td>
</tr>
<tr>
<td>*)</td>
<td>matches any value.</td>
</tr>
</tbody></table>
<h3 id="for-while-until"><a href="#for-while-until" class="headerlink" title="for/while/until"></a>for/while/until</h3><ul>
<li>for <ul>
<li><code>for variable in words; do commands done</code></li>
<li><code>for (( expression1; expression2; expression3 )); do commands done</code></li>
</ul>
</li>
<li>while <ul>
<li><code>while commands; do commands; done</code></li>
<li>while commands is true continue</li>
</ul>
</li>
<li>until <ul>
<li><code>until commands; do commands; done</code></li>
<li>while commands is false continue</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/23/universe/regular_expression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/23/universe/regular_expression/" class="post-title-link" itemprop="url">正则表达式基础语法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-23 00:00:00" itemprop="dateCreated datePublished" datetime="2020-01-23T00:00:00+08:00">2020-01-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-15 21:34:14" itemprop="dateModified" datetime="2020-06-15T21:34:14+08:00">2020-06-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><code>.</code><ul>
<li>匹配任何一个字符</li>
</ul>
</li>
<li><code>*</code><ul>
<li>匹配任何数量(包括0)的前面的内容，贪婪匹配</li>
</ul>
</li>
<li><code>+</code><ul>
<li>匹配任何数量(不包括0)的前面的内容，非贪婪匹配</li>
</ul>
</li>
<li><code>$</code><ul>
<li>以前面的内容结束</li>
</ul>
</li>
<li><code>^</code><ul>
<li>以前面的内容开头</li>
</ul>
</li>
<li><code>\S</code><ul>
<li>任何非空白字符</li>
</ul>
</li>
<li><code>\s</code><ul>
<li>任何空白字符</li>
</ul>
</li>
<li><code>?</code><ul>
<li>前面内容是可选的</li>
</ul>
</li>
<li><code>\</code><ul>
<li>有时可以起到转意的作用，<code>\S</code>等就是例外</li>
</ul>
</li>
<li><code>[0-9]</code><ul>
<li>任何0到9的数字，范围可变但要按顺序</li>
</ul>
</li>
<li><code>[a-z]</code><ul>
<li>任何a到z的小写字符，范围可变但要按顺序</li>
</ul>
</li>
<li><code>[A-Z]</code><ul>
<li>任何A到Z的大写字符，范围可变但要按顺序</li>
</ul>
</li>
<li><code>[A-Za-z]</code><ul>
<li>任何A到Z的字符，范围可变但要按顺序</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/10/Major/compuer_organization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/12/10/Major/compuer_organization/" class="post-title-link" itemprop="url">Computer Organization</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-12-10 00:00:00" itemprop="dateCreated datePublished" datetime="2019-12-10T00:00:00+08:00">2019-12-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-28 17:13:04" itemprop="dateModified" datetime="2020-06-28T17:13:04+08:00">2020-06-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>从纯文本的程序到可执行的编码，以<code>hello.c</code>为例<ul>
<li>预处理：把头文件的内容直接插入程序文本。结果得到另一个c程序，通常以.i结尾</li>
<li>编译：编译器将本文文件hello.i翻译成文本文件hello.s，它包含一个汇编语言程序</li>
<li>汇编：汇编器将hello.s翻译成机器指令(编码)，把这些指令打包成一种叫做可重定位目标程序的格式，并将结果保存在目标文件hello.o中(一个二进制文件)。</li>
<li>链接：hello程序可能会用到许多函数，如printf。printf函数存在与一个名为printf.o的单独编译的与编译好了的目标文件中，这个文件需要以某种形式合并到我们的hello.o程序中。链接器就负责处理这种合并</li>
</ul>
</li>
</ul>
<ul>
<li>虚拟内存：虚拟内存是一个抽象概念，它为每个进程提供一个假象，即每个进程都在单独的使用主存。每个进程看到的内存都是一致的，称为虚拟地址空间</li>
<li>虚拟地址空间的结构：<ul>
<li>程序代码和数据</li>
<li>堆：代码和数据区在进程一开始运行时就被指定了大小，与此不同，当调用像malloc和free这样的函数时，堆可以在运行时动态伸缩</li>
<li>共享库：大约在地址空间的中间部分是一块用来存放像C标准这样的共享库的代码和数据的区域</li>
<li>栈</li>
<li>内核虚拟内存：地址空间的顶部区域是为内核保留的。不允许任何程序的读写</li>
</ul>
</li>
</ul>
<h2 id="程序结构和执行"><a href="#程序结构和执行" class="headerlink" title="程序结构和执行"></a>程序结构和执行</h2><h3 id="整数运算"><a href="#整数运算" class="headerlink" title="整数运算"></a>整数运算</h3><h4 id="无符号加法"><a href="#无符号加法" class="headerlink" title="无符号加法"></a>无符号加法</h4><p>考虑两个非负整数x和y，满足$0 \leq x, y&lt;2^w$。每个数都能表示为w为无符号数字。如果计算他们的和，我们就有一个可能的范围$0 \leq x+y \leq 2^{w+1} - 2$，表示这个和可能需要w+1位。对于固定精度的编程语言会发生溢出。</p>
<p>我们为x和y定义运算$+^u_w, 其中0 \leq x, y &lt; 2^w$，该操作是把整数和x+y截断为w位得到的结果。这也可以被视为一种形式的模运算，对于x+y的位级表示，简单的丢弃任何权重大于$2^{w-1}$的位就可以计算出和模$2^w$。如考虑一个4位数字表示$x=12, y=9,x+y=21([10101])$如果丢掉最高位，我们的到[0101]，也就是十进制的5。也就和值21 mod 16 = 6一致。</p>
<blockquote>
<p>定义$+^u_w$:</p>
<p>对于满足$0 \leq x, y &lt; 2^w$的x和y有</p>
<p>$$<br>x+^u_w y =<br>\begin{cases}<br>x+y&amp; ,{x+y&lt;2^w}&amp; 正常\<br>x+y-2^w&amp; ,{2^w \leq x+y &lt; 2^{w+1}}&amp; 溢出<br>\end{cases}<br>$$</p>
</blockquote>
<p>如何判断是否发生了溢出：</p>
<ul>
<li>原理：对在范围$0 \leq x, y \leq UMax_w$中的x和y，令$s = x +^u_w y$。则对计算是，当且仅当s&lt;x(或等价地s&lt;y)时发生溢出</li>
<li>推导：显然$x+y \geq x$，因此如果s没有溢出$s \geq x$。如果s发生溢出，有$s = x+y-2^w$，假设$y &lt; 2^w$，有$y-2^w &lt; 0$，因此$s = x+(y-2^w) &lt; x$</li>
</ul>
<h4 id="乘以常数"><a href="#乘以常数" class="headerlink" title="乘以常数"></a>乘以常数</h4><p>整数乘法指令相当慢，需要多个时钟周期，然而其他的整数运算(如加法、减法、位移)之需要1个时钟周期。因此编译器使用了一项重要的优化：试着用移位和加法运算的组合来代替乘以常数因子的乘法。</p>
<p>如$x \times 14$，$14=2^3+2^2+2^1$，编译器将乘法重写为(x&lt;&lt;3)+(x&lt;&lt;2)+(x&lt;&lt;1)，将一个乘法代替为3个移位和2个加法。甚至还可以$14=2^4-2^1$。</p>
<p>到这里，无符号数和补码的结果还是相同的</p>
<h4 id="除以2的幂"><a href="#除以2的幂" class="headerlink" title="除以2的幂"></a>除以2的幂</h4><p>在大多数机器上，整数除法要比整数乘法更慢：需要30个或者更多的时钟周期。除以2的幂也可以通过用移位(左移)运算来实现。</p>
<p>无符号和补码数分别使用逻辑移位和算数移位来达到目的：</p>
<ul>
<li>逻辑移位<ul>
<li>移出的空位用0补上</li>
</ul>
</li>
<li>算术移位<ul>
<li>对于无符号型，算术移位等同于逻辑移位</li>
<li>对于有符号型，算数左移等同于逻辑左移，算数右移补的是符号位</li>
</ul>
</li>
</ul>
<blockquote>
<p>定义$\lfloor a \rfloor$为向下舍入，$\lceil a \rceil$为向上舍入。</p>
</blockquote>
<p>对于$x \geq 0$和$y&gt;0$，结果会是$\lfloor x/y \rfloor$，对于$x&lt;0$和$y&gt;0$，结果会是$\lceil x/y \rceil$。也就是说要向下舍入一个正值，而向上舍入一个负值。</p>
<ul>
<li>除以2的幂的无符号数除法<ul>
<li>很简单，就直接右移，产生$\lfloor x/2^k \rfloor$</li>
</ul>
</li>
<li>除以2的幂的补码，正值情况，向下舍入<ul>
<li>也是直接右移，直接右移的结果是向下舍入的</li>
</ul>
</li>
<li>除以2的幂的补码，负值情况，向上舍入<ul>
<li>不能直接右移，因为直接右移导致结果向下舍入，而我们需要向上舍入</li>
<li>执行算数右移前要加上一个适当的偏执量才能使得结果正确舍入</li>
<li>表达式：(x+(1&lt;&lt;k)-1)&gt;&gt;k产生数值$\lceil x/2^k \rceil$</li>
<li>偏置技术利用如下属性：对于整数x和y(y&gt;0)，$\lceil x/y \rceil=\lfloor (x+y-1)/y \rfloor$。这样就可以通过逻辑移位来的到向上取整的结果了</li>
<li><strong>推导:</strong> $\lceil x/y \rceil=\lfloor (x+y-1)/y \rfloor$，设$x = qy+r$，其中$0 \leq r &lt; y$，得到(x+y-1)/y=q+(r+y-1)，因此$\lfloor (x+y-1)/y \rfloor = q + \lfloor (r+y-1)/y \rfloor$。当r=0时，后面一项等于0，当r&gt;0时，等于1。级通过给x增加一个偏移量y-1,然后再将除法向下舍入，当y整除x时，我们得到q，否则，得到q+1。</li>
</ul>
</li>
</ul>
<h3 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h3><h4 id="IEEE浮点数表示"><a href="#IEEE浮点数表示" class="headerlink" title="IEEE浮点数表示"></a>IEEE浮点数表示</h4><p>定点表示法不能很有效地表示非常大的数字。我们希望通过给定x和y的值，来表示形如$x \times 2^y$的数。</p>
<blockquote>
<p>IEEE浮点数标准用$V = (-1)^s \times M \times 2^E$的形式来表示一个数：</p>
<ul>
<li>符号(sign)<ul>
<li>s决定是负数(s=1)还是正数</li>
</ul>
</li>
<li>尾数(significand) M<ul>
<li>M是一个二进制小数，它的取值范围是[1, 2)或[0, 1)</li>
<li>有n位小数字段$frac=f_{n-1}…f_0$编码尾数M，但编码出来的值也依赖于阶码字段是否等于0(规格化的和非规格化的)</li>
</ul>
</li>
<li>阶码(exponent) E<ul>
<li>E的作用是对浮点数加权，这个权重是2的E次幂</li>
<li>由k位的阶码字段组成$exp=e_{k-1}…f_0$来编码阶码E</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>以下是两种常见的格式：单精度和双精度<ul>
<li>单精度:s、exp、frac字段分别为1位、k=8位和n=23位，得到一个32位的表示</li>
<li>双精度:s、exp、frac字段分别为1位、k=11位和n=52位，得到一个64位的表示</li>
</ul>
</li>
<li>给定位的表示，根据exp的值，被编码的值可以分成三种不同的情况(最后一种情况有两种变种)<ul>
<li>规格化的<ul>
<li>exp字段既不全为0也不全为1</li>
<li>阶码的值E=e-Bias，e是无符号数，而$Bias=2^{k-1}-1$的偏置值</li>
<li>尾数M=1+f，f是frac字段描述的小数值$0 \leq f &lt; 1$</li>
</ul>
</li>
<li>非规格化的值<ul>
<li>exp字段全为0时</li>
<li>阶码E=1-Bias</li>
<li>尾数M=f</li>
<li>注意和规格化的区别</li>
</ul>
</li>
<li>特殊值<ul>
<li>当exp全为1，frac字段全为0时，得到的值表示无穷</li>
<li>当exp全为1，frac字段不全为0时，得到的值表示NaN(Not a Number)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>示例：假定用6位格式表示，k=3的阶码位和n=2的尾数位，如下</p>
<table>
<thead>
<tr>
<th>描述</th>
<th>位表示</th>
<th>e</th>
<th>E</th>
<th>$2^E$</th>
<th>f</th>
<th>M</th>
<th>$2^E \times M$</th>
<th>V</th>
<th>十进制</th>
<th>公式</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0 0000 000</td>
<td>0</td>
<td>-6</td>
<td>$\frac1{64}$</td>
<td>$\frac08$</td>
<td>$\frac08$</td>
<td>$\frac0{512}$</td>
<td>0</td>
<td>0.0</td>
<td>E=1-Bias</td>
</tr>
<tr>
<td>最小非规格化数</td>
<td>0 0000 001</td>
<td>0</td>
<td>-6</td>
<td>$\frac1{64}$</td>
<td>$\frac18$</td>
<td>$\frac18$</td>
<td>$\frac1{512}$</td>
<td>$\frac1{512}$</td>
<td>0.001953</td>
<td>M=f</td>
</tr>
<tr>
<td></td>
<td>0 0000 010</td>
<td>0</td>
<td>-6</td>
<td>$\frac1{64}$</td>
<td>$\frac28$</td>
<td>$\frac38$</td>
<td>$\frac2{512}$</td>
<td>$\frac1{256}$</td>
<td>0.003906</td>
<td></td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>..</td>
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>最大非规格化数</td>
<td>0 0000 111</td>
<td>0</td>
<td>-6</td>
<td>$\frac1{64}$</td>
<td>$\frac78$</td>
<td>$\frac78$</td>
<td>$\frac7{512}$</td>
<td>$\frac7{512}$</td>
<td>0.013672</td>
<td></td>
</tr>
<tr>
<td>——–</td>
<td>——</td>
<td>–</td>
<td>–</td>
<td>—</td>
<td>—-</td>
<td>—-</td>
<td>——</td>
<td>—–</td>
<td>—–</td>
<td></td>
</tr>
<tr>
<td>最小规格化数</td>
<td>0 0001 000</td>
<td>1</td>
<td>-6</td>
<td>$\frac1{64}$</td>
<td>$\frac08$</td>
<td>$\frac88$</td>
<td>$\frac8{512}$</td>
<td>$\frac1{64}$</td>
<td>0.015625</td>
<td>E=e-Bias</td>
</tr>
<tr>
<td></td>
<td>0 0001 001</td>
<td>1</td>
<td>-6</td>
<td>$\frac1{64}$</td>
<td>$\frac18$</td>
<td>$\frac98$</td>
<td>$\frac9{512}$</td>
<td>$\frac9{256}$</td>
<td>0.017578</td>
<td>M=1+f</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>..</td>
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>0 1110 110</td>
<td>14</td>
<td>7</td>
<td>128</td>
<td>$\frac68$</td>
<td>$\frac{14}8$</td>
<td>$\frac{1792}8$</td>
<td>224</td>
<td>224</td>
<td></td>
</tr>
<tr>
<td>最大规格化数</td>
<td>0 1110 111</td>
<td>14</td>
<td>7</td>
<td>128</td>
<td>$\frac78$</td>
<td>$\frac{15}8$</td>
<td>$\frac{1920}8$</td>
<td>240</td>
<td>240</td>
<td></td>
</tr>
<tr>
<td>——–</td>
<td>——</td>
<td>–</td>
<td>–</td>
<td>—</td>
<td>—-</td>
<td>—-</td>
<td>——</td>
<td>—–</td>
<td>—–</td>
<td></td>
</tr>
<tr>
<td>无穷大</td>
<td>0 1111 000</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>无穷</td>
<td>-</td>
<td></td>
</tr>
</tbody></table>
<h2 id="程序的机器级表示"><a href="#程序的机器级表示" class="headerlink" title="程序的机器级表示"></a>程序的机器级表示</h2><h3 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h3><table>
<thead>
<tr>
<th>C声明</th>
<th>Intel数据类型</th>
<th>汇编代码后缀</th>
<th>大小(字节)</th>
</tr>
</thead>
<tbody><tr>
<td>char</td>
<td>字节</td>
<td>b</td>
<td>1</td>
</tr>
<tr>
<td>short</td>
<td>字</td>
<td>w</td>
<td>2</td>
</tr>
<tr>
<td>int</td>
<td>双字</td>
<td>l</td>
<td>4</td>
</tr>
<tr>
<td>long</td>
<td>四字</td>
<td>q</td>
<td>8</td>
</tr>
<tr>
<td>char*</td>
<td>四字</td>
<td>q</td>
<td>8</td>
</tr>
<tr>
<td>float</td>
<td>单精度</td>
<td>s</td>
<td>4</td>
</tr>
<tr>
<td>double</td>
<td>双精度</td>
<td>l</td>
<td>8</td>
</tr>
</tbody></table>
<h3 id="访问信息"><a href="#访问信息" class="headerlink" title="访问信息"></a>访问信息</h3><p>一个x86-64的CPU包含一组16个储存64位值的通用目的寄存器。每个寄存器都有特殊的用途，它们的名字就反映了这些用途。</p>
<table>
<thead>
<tr>
<th>64寄存器</th>
<th>32位寄存器</th>
<th>16位寄存器</th>
<th>8位寄存器</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td>%rax</td>
<td>%eax</td>
<td>%ax</td>
<td>%ax</td>
<td>返回值</td>
</tr>
<tr>
<td>%rbx</td>
<td>%ebx</td>
<td>%bx</td>
<td>%bl</td>
<td>被调用者保存</td>
</tr>
<tr>
<td>%rcx</td>
<td>%ecx</td>
<td>%cx</td>
<td>%cl</td>
<td>第4个参数</td>
</tr>
<tr>
<td>%rdx</td>
<td>%edx</td>
<td>%dx</td>
<td>%dl</td>
<td>第3个参数</td>
</tr>
<tr>
<td>%rsi</td>
<td>%esi</td>
<td>%si</td>
<td>%sil</td>
<td>第2个参数</td>
</tr>
<tr>
<td>%rdi</td>
<td>%edi</td>
<td>%di</td>
<td>%dil</td>
<td>第1个参数</td>
</tr>
<tr>
<td>%rbp</td>
<td>%ebp</td>
<td>%bp</td>
<td>%bpl</td>
<td>被调用者保存</td>
</tr>
<tr>
<td>%rsp</td>
<td>%esp</td>
<td>%sp</td>
<td>%spl</td>
<td>栈指针</td>
</tr>
<tr>
<td>%r8</td>
<td>%r8d</td>
<td>%r8w</td>
<td>%r8b</td>
<td>第5个参数</td>
</tr>
<tr>
<td>%r9</td>
<td>%r9d</td>
<td>%r9w</td>
<td>%r9b</td>
<td>第6个参数</td>
</tr>
<tr>
<td>%r10</td>
<td>%r10d</td>
<td>%r10w</td>
<td>%r10b</td>
<td>调用者保存</td>
</tr>
<tr>
<td>%r11</td>
<td>%r11d</td>
<td>%r11w</td>
<td>%r11b</td>
<td>调用者保存</td>
</tr>
<tr>
<td>%r12</td>
<td>%r12d</td>
<td>%r12w</td>
<td>%r12b</td>
<td>被调用者保存</td>
</tr>
<tr>
<td>%r13</td>
<td>%r13d</td>
<td>%r13w</td>
<td>%r13b</td>
<td>被调用者保存</td>
</tr>
<tr>
<td>%r14</td>
<td>%r14d</td>
<td>%r14w</td>
<td>%r14b</td>
<td>被调用者保存</td>
</tr>
<tr>
<td>%r15</td>
<td>%r15d</td>
<td>%r15w</td>
<td>%r15b</td>
<td>被调用者保存</td>
</tr>
</tbody></table>
<p>指令可以对这16个寄存器的低位字节中存放的不同大小的数据进行操作。</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>*AX</td>
<td>累加器Accumulator</td>
</tr>
<tr>
<td>*BX</td>
<td>基地址寄存器Base Register</td>
</tr>
<tr>
<td>*CX</td>
<td>计数寄存器Count Register</td>
</tr>
<tr>
<td>*DX</td>
<td>数据寄存器Data Register</td>
</tr>
<tr>
<td>*BP</td>
<td>堆栈基指针Base Pointer</td>
</tr>
<tr>
<td>*SI/*DI</td>
<td>变址寄存器Index Register</td>
</tr>
<tr>
<td>*SP</td>
<td>堆栈顶指针Stack Pointer</td>
</tr>
<tr>
<td>*S</td>
<td>段寄存器Segement Register</td>
</tr>
</tbody></table>
<h2 id="MIPS体系结构"><a href="#MIPS体系结构" class="headerlink" title="MIPS体系结构"></a>MIPS体系结构</h2><p>Microprocessor without Interlocked Piped Stage，流水线不会互锁的处理器。避免不同指令间的相互影响。如x86指令的标志寄存器，前一条指令作出的改动会对后面的产生影响，这MIPS所要避免的。</p>
<ul>
<li>它的主要关注点<ul>
<li>减少指令类型</li>
<li>降低指令复杂度</li>
</ul>
</li>
<li>基本原则是用非常简单的CPU解决非常复杂的系统<ul>
<li>越简单的CPU越快</li>
</ul>
</li>
<li>MIPS特点<ul>
<li>固定指令长度(32bit)<ul>
<li>简化了从存储器取指令</li>
</ul>
</li>
<li>简单的寻址模式<ul>
<li>简化了从存储器取操作数</li>
</ul>
</li>
<li>指令数量少，功能简单<ul>
<li>一条指令之完成一个操作</li>
<li>简化指令的执行过程</li>
</ul>
</li>
<li>只允许Load和Store指令访问存储器</li>
<li>MIPS这些特点让使用MIPS进行编程变得困难</li>
</ul>
</li>
</ul>
<h3 id="基本指令"><a href="#基本指令" class="headerlink" title="基本指令"></a>基本指令</h3><ul>
<li>格式：<code>OPT a, b, c</code><ul>
<li>如<code>add a, b, c</code>将b和c求和，结果存如a中</li>
<li>如此还有<ul>
<li><code>sub a, b, c</code></li>
<li><code>mul a, b, c</code></li>
<li><code>div a, b, c</code></li>
<li><code>and a, b, c</code></li>
<li><code>or a, b, c</code></li>
<li><code>sll a, b, c</code>，左移</li>
<li><code>srl a, b, c</code>，右移</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>指令高度统一，而且操作数都不可是存储器操作数，要使用存储器就必须使用专门的访存指令。</p>
<ul>
<li><code>lw $a, $b</code>, load word，读取寄存器b的字(32bit)，放入a中<ul>
<li>MIPS的寄存器编号用<code>$</code>符进行标记</li>
</ul>
</li>
<li><code>sw $a, $b</code>, store word，将寄存器a的字(32bit)，存到b中</li>
</ul>
<p>MIPS有32个通用寄存器，编号从0到31，可以实用<code>$</code>加编号进行指示，也可使用他们的名称(每个寄存器都另有一个名称，并约定了特定的用途)</p>
<h3 id="指令的基本格式"><a href="#指令的基本格式" class="headerlink" title="指令的基本格式"></a>指令的基本格式</h3><p>MIPS的指令非常的精简</p>
<ul>
<li>按照功能划分<ul>
<li>运算指令</li>
<li>访存指令</li>
<li>分支指令</li>
</ul>
</li>
<li>从指令的格式划分<ul>
<li>R：Register，寄存器</li>
<li>I：Immediate，立即数</li>
<li>J：Jump，转移</li>
</ul>
</li>
</ul>
<h4 id="R型"><a href="#R型" class="headerlink" title="R型"></a>R型</h4><table>
<thead>
<tr>
<th>R</th>
<th>opcode</th>
<th>rs</th>
<th>rt</th>
<th>rd</th>
<th>shamt</th>
<th>funct</th>
</tr>
</thead>
<tbody><tr>
<td>大小(bit)</td>
<td>6</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>位置</td>
<td>31~26</td>
<td>25~21</td>
<td>20~16</td>
<td>15~11</td>
<td>10~6</td>
<td>5~0</td>
</tr>
</tbody></table>
<ul>
<li><p>R型指令的格式</p>
<ul>
<li>opcode域指定指令的类型，对于R型指令均为0</li>
<li>funct来精确指定指令的类型</li>
<li>rs：Source Register，通常指定第一个源操作数所在寄存器编号</li>
<li>rt：Target Register，通常指定第二个源操作数所在寄存器编号</li>
<li>rd：Destination Register，通常指定目的操作数所在寄存器编号</li>
<li>shamt用于指定移位指令进行操作数的位数，对于非移位指令为0</li>
</ul>
</li>
<li><p>通过指令得到编码，如<code>add $8, $9, $10</code></p>
<ul>
<li>查MIPS的指令编码表：对于add，opcode=0, funct=32, shamt=0</li>
<li>分析指令操作数：rd=8, rs=9, rt=10</li>
<li>把对应的值转化为二进制数即可得到编码</li>
</ul>
</li>
</ul>
<h4 id="I型"><a href="#I型" class="headerlink" title="I型"></a>I型</h4><p>如果只用5bit来表示立即数，显然不够用，所以对于I型指令需要新的格式</p>
<table>
<thead>
<tr>
<th>I</th>
<th>opcode</th>
<th>rs</th>
<th>rt</th>
<th>immediate</th>
</tr>
</thead>
<tbody><tr>
<td>大小(bit)</td>
<td>6</td>
<td>5</td>
<td>5</td>
<td>16</td>
</tr>
<tr>
<td>位置</td>
<td>31~26</td>
<td>25~21</td>
<td>20~16</td>
<td>15~0</td>
</tr>
</tbody></table>
<ul>
<li><p>I型指令的格式</p>
<ul>
<li>opcode域指定指令的类型，没有funct</li>
<li>funct来精确指定指令的类型</li>
<li>rs：Source Register，通常指定第一个源操作数所在寄存器编号</li>
<li>rt：Target Register，通常指定第二个源操作数所在寄存器编号</li>
<li>immediate可以存放16位的立即数</li>
</ul>
</li>
<li><p>通过指令得到编码，如<code>add $21, $22, -50</code></p>
<ul>
<li>opcode=8</li>
<li>rs=22, rt=21, immedaite=-50</li>
</ul>
</li>
</ul>
<h4 id="分支指令-条件指令"><a href="#分支指令-条件指令" class="headerlink" title="分支指令(条件指令)"></a>分支指令(条件指令)</h4><ul>
<li>条件分支<ul>
<li>根据比较结果改变控制流</li>
<li><code>beq</code>(branch if equal)<ul>
<li>opcode=4</li>
</ul>
</li>
<li><code>bne</code>(branch if not equal)<ul>
<li>opcode=5</li>
</ul>
</li>
</ul>
</li>
<li>非条件分支<ul>
<li>无条件地改变控制流</li>
<li><code>j</code>(jump)</li>
</ul>
</li>
</ul>
<p>格式：<code>bep reg1, reg2, L1</code><br>    - 前两个是寄存器操作数，第三个是存储器地址(一个立即数，偏移量)<br>    - 不同于x86指令，没有标志寄存器，在一条语句中完成了比较和转移</p>
<table>
<thead>
<tr>
<th>I</th>
<th>opcode</th>
<th>rs</th>
<th>rt</th>
<th>immediate</th>
</tr>
</thead>
<tbody><tr>
<td>大小(bit)</td>
<td>6</td>
<td>5</td>
<td>5</td>
<td>16</td>
</tr>
<tr>
<td>位置</td>
<td>31~26</td>
<td>25~21</td>
<td>20~16</td>
<td>15~0</td>
</tr>
</tbody></table>
<ul>
<li>如何发挥16bit的作用？<ul>
<li>以当前的PC为基准，16bit偏移量可以表示$\pm 2^{15}$bytes</li>
<li>由于MIPS指令长度固定为32bit，因此我们可以用16bit的立即数来表示每4个字节为一个单位的地址，这样目标地址范围可以扩大4倍。</li>
<li>16bit偏移量可以表示$\pm 2^{17}$bytes</li>
</ul>
</li>
<li>目标地址计算方法<ul>
<li>分支条件不成立时，PC = PC + 4 = 下一条语句</li>
<li>分支条件成立时，PC = PC + 4  + immediate*4</li>
</ul>
</li>
</ul>
<p>对于非条件分支指令</p>
<table>
<thead>
<tr>
<th>J</th>
<th>opcode</th>
<th>immediate</th>
</tr>
</thead>
<tbody><tr>
<td>大小(bit)</td>
<td>6</td>
<td>26</td>
</tr>
<tr>
<td>位置</td>
<td>31~26</td>
<td>25~0</td>
</tr>
</tbody></table>
<ul>
<li>不同于条件分支，需要两个寄存器比较，所以可以表示更大的范围</li>
<li>目标地址计算方法：New PC = {(PC+4)后取最高4位, address, 00}</li>
<li>J型指令的目标地址范围：<code>\pm 2^{28}</code>bytes<ul>
<li>如何到达更远的目标地址？<ul>
<li>两次调用j指令</li>
<li>使用jr指令：<code>jr rs</code>，可把要转移的目标地址放在寄存器中，这样就可以使用32位的目标地址</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="算数逻辑单元"><a href="#算数逻辑单元" class="headerlink" title="算数逻辑单元"></a>算数逻辑单元</h2><p>通过MIPS指令来做示例</p>
<h3 id="算数运算和逻辑运算"><a href="#算数运算和逻辑运算" class="headerlink" title="算数运算和逻辑运算"></a>算数运算和逻辑运算</h3><p>把编码好的指令，如<code>add r1, r2, r3</code>放入IR寄存器中，根据各个域的数值控制电路向ALU发出信号：输入、输出、运算方法等。</p>
<p>在如对于立即数加法：<code>addi</code>，ALU接受到信号，通过opcode知道要进行立即数加法，把把源寄存器作为输入，把输出放入目标寄存器。</p>
<ul>
<li>立即数是16bit的，但寄存器是32bit的，要能成功相加，需要扩展16bit<ul>
<li>MIPS使用补码，所以这个立即数采用符号扩展，不会改变补码的值</li>
</ul>
</li>
</ul>
<p>对于逻辑运算，与算数运算类似，只是立即数采用0扩展。</p>
<h3 id="门电路的基本原理"><a href="#门电路的基本原理" class="headerlink" title="门电路的基本原理"></a>门电路的基本原理</h3><p>现代集成电路通常使用MOS晶体管</p>
<ul>
<li>N型MOS管<ul>
<li>Source源：电流流入</li>
<li>Drain漏：电流流出</li>
<li>Gate门：控制，高电频导通</li>
</ul>
</li>
<li>P型MOS管<ul>
<li>Source源：电流流入</li>
<li>Drain漏：电流流出</li>
<li>Gate门：控制，低电频导通</li>
</ul>
</li>
<li>用这两种晶体管就构成了互补型的MOS关：CMOS</li>
</ul>
<p>逻辑门由晶体管构成，各种逻辑门的结构这里就不说了</p>
<h3 id="寄存器的原理"><a href="#寄存器的原理" class="headerlink" title="寄存器的原理"></a>寄存器的原理</h3><p>在MIPS结构中，寄存器是由32个位组成，从电路上来说每个bit都是一样的，都是一个 <strong>D触发器</strong>。</p>
<ul>
<li>D触发器<ul>
<li>具有存储信息能力的基本单元</li>
<li>由若干逻辑门构成，有多种实现方式</li>
<li>主要有1个数据输入、1个数据输出和1个时钟输入</li>
<li>在上升沿，采样输入D的值，传送到输出Q，其余时间输出Q的值不变</li>
<li>要求采样信号前后有一段很短的稳定时间</li>
</ul>
</li>
</ul>
<p>用32个D触发器构成MIPS的寄存器，在将寄存器用逻辑门相连，就构成了CPU。</p>
<h3 id="逻辑运算的实现"><a href="#逻辑运算的实现" class="headerlink" title="逻辑运算的实现"></a>逻辑运算的实现</h3><p>ALU中包含很多中运算单元，以与元算单元为例：32位的输入需要32个与逻辑门处理，得到对应的32位输出。ALU包含多个单元，一组输入通过不同的单元，的到多组输出，这时需要一个多选器根据选择信号(opcode)对这些输出进行选择，得到一个32位的输出。</p>
<h3 id="加减法的实现"><a href="#加减法的实现" class="headerlink" title="加减法的实现"></a>加减法的实现</h3><ul>
<li><p>半加器</p>
<ul>
<li>将两个一位二进制数相加</li>
<li>不能将进位位用与加法</li>
</ul>
</li>
<li><p>全加器</p>
<ul>
<li>由两个半加器组成</li>
<li>能将进位位用与加法</li>
</ul>
</li>
<li><p>MIPS对溢出的处理方式</p>
<ul>
<li>将操作数看做有符号数<code>add</code>和<code>addi</code><ul>
<li>发生溢出时会产生异常</li>
</ul>
</li>
<li>将操作数看做无符号数<code>addu</code>和<code>addiu</code><ul>
<li>不处理溢出</li>
</ul>
</li>
</ul>
</li>
<li><p>x86对溢出的处理方式</p>
<ul>
<li>采用溢出标志OF，根据标志寄存器OF来进行相应的操作</li>
</ul>
</li>
</ul>
<p>对于减法运算，减法可以转换成加法，那么就要对一个数进行取反操作</p>
<ul>
<li>补码表示的二进制数取反<ul>
<li>规则：按位取反，末位加一</li>
<li>推导 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x :010101</span><br><span class="line">~x:101010</span><br><span class="line">----------</span><br><span class="line">-1:111111</span><br><span class="line"></span><br><span class="line">x + (~x) &#x3D; -1</span><br><span class="line"></span><br><span class="line">(~x) + 1 &#x3D; -x</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h3 id="加法器的优化"><a href="#加法器的优化" class="headerlink" title="加法器的优化"></a>加法器的优化</h3><p>前面将的加法有一个个的全加器串联而成，需要等待进位输入，延迟长。进位像波一样传递，这样的加法器也称为 <strong>行波进位加法器(RCA)</strong> 。</p>
<ul>
<li>超前进位加法器(CLA)<ul>
<li>优点： <ul>
<li>计算延迟时间固定为三级门延迟</li>
</ul>
</li>
<li>缺点：<ul>
<li>进一步扩宽加法器的位数，则电路变得非常复杂</li>
</ul>
</li>
<li>因此通常使用小规模的CLA拼接形成加法器</li>
</ul>
</li>
</ul>
<h2 id="乘法器和除法器"><a href="#乘法器和除法器" class="headerlink" title="乘法器和除法器"></a>乘法器和除法器</h2><p>整数乘法指令相当慢，需要多个时钟周期，然而其他的整数运算(如加法、减法、位移)之需要1个时钟周期。因此编译器使用了一项重要的优化：试着用移位和加法运算的组合来代替乘以常数因子的乘法。</p>
<p>如$x \times 14$，$14=2^3+2^2+2^1$，编译器将乘法重写为(x&lt;&lt;3)+(x&lt;&lt;2)+(x&lt;&lt;1)，将一个乘法代替为3个移位和2个加法。甚至还可以$14=2^4-2^1$。</p>
<h3 id="乘法器的实现"><a href="#乘法器的实现" class="headerlink" title="乘法器的实现"></a>乘法器的实现</h3><p>观察下列乘法过程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">   1000</span><br><span class="line">   1001</span><br><span class="line">   ------</span><br><span class="line">   1000</span><br><span class="line">  0000_   好似乘数左移乘</span><br><span class="line"> 0000__</span><br><span class="line">1000___</span><br></pre></td></tr></table></figure>

<p>一个N位乘法器需要3个寄存器，分别设为被乘数md，乘mr，结果res。由上列过程得到启发，过程如下：</p>
<ul>
<li><p>如果被乘数第一位不为0则乘以乘数</p>
</li>
<li><p>把结果加到res中</p>
</li>
<li><p>乘数右移，被乘数左移</p>
</li>
<li><p>如果执行了N次则乘法结束，否则回到第一步</p>
</li>
<li><p>对N位乘法器进行优化</p>
<ul>
<li><ol>
<li>加法移位并行<ul>
<li>通过控制器，控制移位，在一个时钟周期完成移位操作</li>
</ul>
</li>
</ol>
</li>
<li><ol start="2">
<li>减少不必要的硬件资源<ul>
<li>md由于左移，储存需要的位数是它原始位宽的两倍<ul>
<li>取消左移</li>
</ul>
</li>
<li>mr右移有效数字每个周期减少1位<ul>
<li>用res的低4为存放，因此可以取消mr</li>
</ul>
</li>
<li>res每个周期增加1位<ul>
<li>增加右移，来代替md的左移，乘积始终放在高4位</li>
</ul>
</li>
<li>加法器参加运输，但实际有效数字自由其位宽的一半<ul>
<li>md和res的高4位进行运算</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="除法的运算过程"><a href="#除法的运算过程" class="headerlink" title="除法的运算过程"></a>除法的运算过程</h3><p>观察除法的运算过程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">         0001        结果累加，相当于左移</span><br><span class="line">        0001</span><br><span class="line">       0000</span><br><span class="line">      0000</span><br><span class="line">     0000            0010&lt;0000所以商为0</span><br><span class="line">0010&#x2F;00000111</span><br><span class="line">     0010____        相当于右移</span><br><span class="line">      0010</span><br><span class="line">       0010</span><br><span class="line">        0010</span><br><span class="line">        ----</span><br><span class="line">         0011</span><br><span class="line">         0010</span><br><span class="line">         ----</span><br><span class="line">            1        记录余数</span><br></pre></td></tr></table></figure>

<p>过程如下</p>
<ul>
<li>余数寄存器减去除数，检测最高位判断大小</li>
<li>除数右移</li>
<li>商左移，累加</li>
</ul>
<p>除法器的优化:</p>
<ul>
<li><ol>
<li>硬件资源优化<ul>
<li>除数寄存器实际只用了一半</li>
<li>商寄存器初始的空的，从右到左逐位填满</li>
<li>余数初始是满的，有意义的位从左到右逐位减少</li>
</ul>
</li>
</ol>
</li>
<li><ol start="2">
<li>性能资源优化</li>
</ol>
</li>
</ul>
<h2 id="单周期处理器"><a href="#单周期处理器" class="headerlink" title="单周期处理器"></a>单周期处理器</h2><h3 id="处理器设计的主要步骤"><a href="#处理器设计的主要步骤" class="headerlink" title="处理器设计的主要步骤"></a>处理器设计的主要步骤</h3><ul>
<li><ol>
<li>分析指令系统，得出对数据通路的需求</li>
</ol>
</li>
<li><ol start="2">
<li>为数据通路选择合适的组件</li>
</ol>
</li>
<li><ol start="3">
<li>连接组件建立数据通路</li>
</ol>
</li>
<li><ol start="4">
<li>分析每条指令的实现，以确定控制信号</li>
</ol>
</li>
<li><ol start="5">
<li>集成控制信号，形成完整的控制逻辑，控制器</li>
</ol>
</li>
</ul>
<p>下面以一个简化的MIPS指令系统作为实例，改系统的指令有：</p>
<ul>
<li>无符号加法和和减法<ul>
<li><code>addu rd, rs, rt</code></li>
<li><code>subu rd, rs, rt</code></li>
</ul>
</li>
<li>立即数的逻辑或<ul>
<li><code>ori rt, rs, imm16</code></li>
</ul>
</li>
<li>装载和储存一个字<ul>
<li><code>lw rt, imm16(rs)</code></li>
<li><code>sw rt, imm16(rs)</code></li>
</ul>
</li>
<li>条件分支<ul>
<li><code>bep rs, rt, imm16</code></li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>R</th>
<th>opcode</th>
<th>rs</th>
<th>rt</th>
<th>rd</th>
<th>shamt</th>
<th>funct</th>
</tr>
</thead>
<tbody><tr>
<td>大小(bit)</td>
<td>6</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>位置</td>
<td>31~26</td>
<td>25~21</td>
<td>20~16</td>
<td>15~11</td>
<td>10~6</td>
<td>5~0</td>
</tr>
</tbody></table>
<ul>
<li><p>指令位域分解</p>
<ul>
<li>R型指令：{op, rs, rt, rd, shamt, funct}</li>
<li>I型指令：{op, rs, rt, imm16}</li>
<li>需求：<ul>
<li>存放指令的存储器</li>
<li>PC:存放地址的32位寄存器</li>
</ul>
</li>
</ul>
</li>
<li><p>通过指令操作分析需求</p>
<ul>
<li>运算指令需求：<ul>
<li>一组存放数据的通用寄存器，这些寄存器称为寄存器堆</li>
<li>同时读取两个寄存器的内容</li>
<li>写入一个寄存器的内容，保存结果</li>
<li>将16位的立即数扩展到32位，供I型指令需要</li>
<li>提供加、减、逻辑或功能的运算器</li>
<li>运算器的操作数可以时寄存器或立即数</li>
</ul>
</li>
<li>访存指令<ul>
<li>存放数据的储存器，可读可写</li>
<li>将16位的立即数扩展到32位，供I型指令需要</li>
</ul>
</li>
<li>分支指令<ul>
<li>比较内容，判断是否相等</li>
<li>PC寄存器支持两种自增方式，加4或加一个立即数</li>
</ul>
</li>
</ul>
</li>
<li><p>整理：</p>
<ul>
<li>算数逻辑单元(ALU)<ul>
<li>支持运算类型</li>
<li>操作数</li>
</ul>
</li>
<li>立即数扩展部件<ul>
<li>支持0扩展、符号扩展</li>
</ul>
</li>
<li>程序计数器(PC)<ul>
<li>支持两种自增方式，加4或加一个立即数</li>
</ul>
</li>
<li>寄存器堆<ul>
<li>支持读操作：rs和rt</li>
<li>支持写操作：rt和rd</li>
</ul>
</li>
<li>存储器<ul>
<li>一个只读指令存储器</li>
<li>一个可读写的数据存储器</li>
</ul>
</li>
</ul>
</li>
<li><p>寄存器堆</p>
<ul>
<li>内部构成<ul>
<li>32个32位的寄存器</li>
</ul>
</li>
<li>数据接口信号<ul>
<li>busA、busB：两组32位的数据输出</li>
<li>busW：一组32位的数据输入</li>
</ul>
</li>
<li>读写控制<ul>
<li>Ra(5bit)：选中对应编号的寄存器，将其内容放到busA</li>
<li>Rb(5bit)：选中对应编号的寄存器，将其内容放到busB</li>
<li>Rw(5bit)：选中对应编号的寄存器，在时钟信号的上升沿，如果写使能信号有效，将busW的内容写入改寄存器</li>
<li>读操作不受时钟信号控制</li>
</ul>
</li>
</ul>
</li>
<li><p>存储器</p>
<ul>
<li>数据接口信号<ul>
<li>Date In：32位的数据输入信号</li>
<li>Data Out：32位的数据输出信号</li>
</ul>
</li>
<li>读写操作<ul>
<li>Address：32位的地址信号。该信号指定一个存储单元，将其内容送到数据输入信号</li>
<li>Write Enable：写使能信号，在时钟上升沿，如果写使能信号有效，将数据输入信号的内容存入地址信号指定的存储单元</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="数据通路的建立"><a href="#数据通路的建立" class="headerlink" title="数据通路的建立"></a>数据通路的建立</h3><ul>
<li>基本原则<ul>
<li>根据指令需求，连接组件，建立数据通路</li>
</ul>
</li>
<li>指令的需求<ul>
<li>所有指令的共同需求<ul>
<li>取指令，由IFU(Instruction Fetch Unit)完成<ul>
<li>程序计数器(PC)的内容是指令的地址</li>
<li>用PC的内容作为地址，访问指令存储器获得指令编码</li>
</ul>
</li>
<li>更新程序计数器PC<ul>
<li>顺序时PC+=4</li>
<li>分支时PC=目标地址</li>
</ul>
</li>
</ul>
</li>
<li>不同指令的各自需求<ul>
<li>加减法指令的需求</li>
<li>逻辑运算指令的需求</li>
<li>访存指令需求</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="运算指令的控制信号"><a href="#运算指令的控制信号" class="headerlink" title="运算指令的控制信号"></a>运算指令的控制信号</h3><p>以加法运算指令为例：</p>
<ul>
<li><ol>
<li>通过IFU取指令</li>
</ol>
</li>
<li><ol start="2">
<li>执行加法<ul>
<li>解析IFU的输出，放入寄存器堆对应的输入中</li>
<li>busB如果是立即数需要扩展<ul>
<li>扩展又有0扩展和符号扩展</li>
</ul>
</li>
<li>对ALU：给ALU信号使其执行加法计算</li>
<li>对数据存储器：如果不需要数据存储器，写使能信号关闭，防止对结果修改</li>
<li>要写入寄存器，所有要把寄存器的写使能信号设为有效</li>
</ul>
</li>
</ol>
</li>
<li><ol start="3">
<li>更新PC寄存器的内容</li>
</ol>
</li>
</ul>
<p>访存指令、分支指令同理</p>
<h3 id="控制信号的集成"><a href="#控制信号的集成" class="headerlink" title="控制信号的集成"></a>控制信号的集成</h3><p>把之前的控制信号集成起来，形成完整的控制逻辑。</p>
<h2 id="流水线处理器"><a href="#流水线处理器" class="headerlink" title="流水线处理器"></a>流水线处理器</h2><h3 id="流水线的基本原理"><a href="#流水线的基本原理" class="headerlink" title="流水线的基本原理"></a>流水线的基本原理</h3><p>执行MIPS指令的主要步骤：</p>
<ul>
<li>取值</li>
<li>译码</li>
<li>执行</li>
<li>访存</li>
<li>回写</li>
</ul>
<p>分工明确好似非常适合使用流水线，每个人专注于自己的工作，每个硬件都有使用。</p>
<p>我们需要将每个部分的输出放入一个流水线寄存器，这样当输出保存在流水线寄存器后，前面的寄存器就可以开始新的工作而不影响后面的工作。下一个硬件又从流水线寄存器中取上一个硬件的输入。</p>
<p>虽然每条指令要经历的时间不变，但是当流水线填满是，每个时钟周期都能产生一条指令，性能提升不少。</p>
<h3 id="流水线的优化"><a href="#流水线的优化" class="headerlink" title="流水线的优化"></a>流水线的优化</h3><p>如果只是简单的按照指令执行的步骤取切分流水线的话不能充分发挥流水线的优势。</p>
<p>时钟周期的大小取决于耗时最长的那个步骤，如果流水线平衡性较差，性能提升幅度下降。</p>
<p>流水线的深度并非越深越好，应用流水线寄存器也会产生时延。越深的流水线说明需要的流水线寄存器越多。单条指令的执行时间越长。</p>
<h3 id="超标量流水线"><a href="#超标量流水线" class="headerlink" title="超标量流水线"></a>超标量流水线</h3><p>除了增加流水线深度来提供速度，还有一种方式就是拓宽流水线，这样的流水线就称为超标量流水线。通常具有两条或以上并行工作的流水线称为超标量结构。也可称为超量。</p>
<h3 id="流水线的”冒险”"><a href="#流水线的”冒险”" class="headerlink" title="流水线的”冒险”"></a>流水线的”冒险”</h3><ul>
<li>“冒险”(Hazard)：阻止下一条指令在下一个时钟周期开始执行的情况<ul>
<li>结构冒险<ul>
<li>所有的硬件部件正在位之前的指令工作</li>
<li>对于只读存储器，一次只能有一个硬件进行读取<ul>
<li>解决方案1：流水线停顿(不同时使用这个硬件)，产生空泡(不会影响状态的值)<ul>
<li>但如果等待后有与另一个硬件冲突则又要停顿，这样效率很低</li>
</ul>
</li>
<li>解决方案2：指令和数据放在不同的存储器中</li>
</ul>
</li>
<li>对于可读写的寄存器，读写同时发生显然不是一个明智的选择<ul>
<li>解决方案：前半个时钟周期写，后半个读，并设置独立的读写口</li>
<li>支持这么做的原因是寄存器的读写速度较快</li>
</ul>
</li>
</ul>
</li>
<li>数据冒险<ul>
<li>需要等待之前的指令完成数据的读写</li>
<li>如果下一条指令需要上一条指令的数据，但是上一条指令可能还没写回<ul>
<li>解决方案1：停顿</li>
</ul>
</li>
</ul>
</li>
<li>控制冒险<ul>
<li>需要根据之前指令的结果决定下一步的行为</li>
<li>类似数据冒险，指令不能确定是否发生分支，需要几个周期后才知道<ul>
<li>解决方案1：停顿</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="数据冒险的处理"><a href="#数据冒险的处理" class="headerlink" title="数据冒险的处理"></a>数据冒险的处理</h3><ul>
<li>软件解决方案(停顿)：插入nop指令，什么都不干<ul>
<li>插入几条nop指令存在问题，不同的处理器的流水线深度可能不同，导致兼容。因此一般不通过软件层面解决硬件问题</li>
</ul>
</li>
<li>流水线停顿，产生空泡<ul>
<li>这样的空泡由硬件产生</li>
<li>检查数据冒险，如果有则插入空泡</li>
</ul>
</li>
<li>数据前递(或称为旁路)<ul>
<li>如加法运算，即使没有写回，它的运算结果其实已经在流水线寄存器中了，我们只需引用流水线寄存器上的值</li>
<li>但对于load指令数据前递不适用，因为load指令的值较迟产生</li>
</ul>
</li>
</ul>
<h3 id="控制冒险的处理"><a href="#控制冒险的处理" class="headerlink" title="控制冒险的处理"></a>控制冒险的处理</h3><ul>
<li>当执行了转移指令，并确实发生转移时，产生如下的开销，称为”转移开销”<ul>
<li><ol>
<li>将按顺序预取的指令废除(排空流水线)</li>
</ol>
</li>
<li><ol start="2">
<li>从转移目标地址重新取指定</li>
</ol>
</li>
</ul>
</li>
<li>转移开销的构成<ul>
<li>要不要转移，判断条件引起的开销</li>
<li>转移到哪，生成目标地址引起的开销</li>
</ul>
</li>
</ul>
<h2 id="存储层次结构"><a href="#存储层次结构" class="headerlink" title="存储层次结构"></a>存储层次结构</h2><h3 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h3><ul>
<li>冯诺依曼计算机结构：<ul>
<li>运算器CA</li>
<li>控制器CC</li>
<li>存储器M<ul>
<li>层次结构：<ul>
<li>通用寄存器：CPU</li>
<li>高速缓存：SRAM</li>
<li>主存：DRAM</li>
<li>本地二级存储：Disk</li>
<li>越往上越快、容量越小价格越高</li>
</ul>
</li>
</ul>
</li>
<li>输入I</li>
<li>输出O</li>
</ul>
</li>
</ul>
<h3 id="DRAM和SRAM"><a href="#DRAM和SRAM" class="headerlink" title="DRAM和SRAM"></a>DRAM和SRAM</h3><table>
<thead>
<tr>
<th></th>
<th>DRAM</th>
<th>SRAM</th>
</tr>
</thead>
<tbody><tr>
<td>储存单元</td>
<td>电容</td>
<td>双稳态触发器</td>
</tr>
<tr>
<td>集成度</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>功耗</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>价格</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>速度</td>
<td>慢</td>
<td>块</td>
</tr>
<tr>
<td>刷新</td>
<td>有</td>
<td>无</td>
</tr>
</tbody></table>
<h3 id="主存-内存-的工作原理"><a href="#主存-内存-的工作原理" class="headerlink" title="主存(内存)的工作原理"></a>主存(内存)的工作原理</h3><p>DRAM芯片以一个存储阵列位核心，通过指定行列地址取出对应的存储单元(4比特或8比特)。一个内存条往往有多个DRAM芯片(4的倍数)，构成一个内存模组。从外部给入行列地址后地址会同时送到每个DRAM芯片，每个DRAM芯片同时选择储存器单元，存储单元同时输出，组成一个64/32位的数。</p>
<p>缓存速度很快，一般放在CPU中。CPU访问内存的过程：SDRAM(同步DRAM)的访存过程为例：</p>
<ul>
<li>CPU通过系统总线连接到内存控制器，内存控制器再通过存储总线连接到内存条<ul>
<li>CPU需要访问控制器时：<ul>
<li>申请系统总线，获得总线控制权后把地址发到控制器中</li>
</ul>
</li>
<li>控制器对地址分解形成行地址和列地址，然后向DRAM发起访存操作<ul>
<li><ol>
<li>预充电</li>
</ol>
</li>
<li><ol start="2">
<li>行访问:DRAM中的行译码芯片，选出对应行，所有单元的信号放大后放在一个缓冲区</li>
</ol>
</li>
<li><ol start="3">
<li>缓冲区信号稳定后，才能发出列地址，其中tRCD是冲行选到列选的延迟</li>
</ol>
</li>
<li><ol start="4">
<li>列译码器接受到列地址后，从缓冲区读出对应的列，放到数据接受接口。其中从发出列地址到选出对应存储单元的数的过程称为列访问，这段时间称为CL</li>
</ol>
</li>
</ul>
</li>
<li>内存送出数据后，控制器采样并送到CPU<ul>
<li>如果CPU的下次请求是同一行，则控制器不再发送行地址，而是直接发送列地址</li>
<li>如果下次访问不是同一行则需把缓冲区的行关闭，这个过程就叫做 <strong>预充电</strong> </li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="主存技术的发展"><a href="#主存技术的发展" class="headerlink" title="主存技术的发展"></a>主存技术的发展</h3><ul>
<li>DDR:Double Data Rate<ul>
<li>时钟的上升沿和下降沿都传输</li>
</ul>
</li>
<li>SDR:Single Data Rate<ul>
<li>只在时钟的上升沿传输</li>
</ul>
</li>
</ul>
<p>building</p>
<h3 id="高速缓存的工作原理"><a href="#高速缓存的工作原理" class="headerlink" title="高速缓存的工作原理"></a>高速缓存的工作原理</h3><p>$$Cpu \leftrightarrow Cache \leftrightarrow Main Memory$$</p>
<ul>
<li>程序的局部性原理:计算机程序从空间和时间都表现出局部性<ul>
<li>时间局部性<ul>
<li>最近被访问的存储器单元(指令或数据)很快会被访问</li>
</ul>
</li>
<li>空间局部性<ul>
<li>正在被访问的存储器单元附近的单元很快会被访问到</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>举个例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">10</span>; i++)&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;<span class="number">10</span>; i++)&#123;</span><br><span class="line">        sum+=a[i][j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// i很快会(频繁)被访问</span></span><br><span class="line"><span class="comment">// a数组附件的单元很快会被访问</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>cache的基本原理</p>
<ul>
<li>cache对空间局部性的利用<ul>
<li>从主存中取回待访问数据时，会同时取回与位置相邻的主存单元的数据</li>
<li>以数据块(Block)为单位和主存进行数据交换</li>
</ul>
</li>
<li>cache对时间局部性的利用<ul>
<li>保存近期频繁被访问的主存单元的数据</li>
</ul>
</li>
<li>这样如果cache中有数据(cache命中)则从cache中获取</li>
</ul>
</li>
<li><p>cache的写策略</p>
<ul>
<li>cache命中时的写策略<ul>
<li>写穿透：数据同时写入cache和主存</li>
<li>写返回：数据只写入cache，仅当改数据块被替换时才写入主存</li>
</ul>
</li>
<li>cache失效时的写策略<ul>
<li>写不分配：直接写入主存</li>
<li>写分配：将该数据所在的块读入cache后，在将数据写入cache，利用局部性原理</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="高速缓存的设计要点"><a href="#高速缓存的设计要点" class="headerlink" title="高速缓存的设计要点"></a>高速缓存的设计要点</h3><ul>
<li>平均访存时间(Average Memory Access Time)=Hit Time + Miss Penalty x Miss Rate<ul>
<li>Hit Time：命中时间，从cache将命中数据返回的时间</li>
<li>Miss Penalty：失效代价，从主存读取数据并返回的时间</li>
<li>Miss Rate：失效率，未命中的概率</li>
<li>降低访存时间主要就是降低这3个参数</li>
</ul>
</li>
<li>cache失效的原因<ul>
<li>义务失效：第一次访问<ul>
<li>无法避免</li>
</ul>
</li>
<li>容量失效：无法保存程序所需的所有数据块<ul>
<li>可增加cache容量缓解，但会增加命中时间</li>
</ul>
</li>
<li>冲突失效：多个存储器位置映射到同一个cache位置<ul>
<li>需要精心设计映射策略</li>
</ul>
</li>
</ul>
</li>
<li>映射策略<ul>
<li>直接映射</li>
<li>多路组相联(相当于用几个表来保存，但是表越多就要用越复杂的电路判断是否在其中一个表中)</li>
<li>常见的cache替换算法<ul>
<li>随机</li>
<li>轮换</li>
<li>最近最少使用(LRU)：效果最好但设计复杂</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="存储器容量的计算"><a href="#存储器容量的计算" class="headerlink" title="存储器容量的计算"></a>存储器容量的计算</h3><table>
<thead>
<tr>
<th>&lt;++&gt;</th>
<th>&lt;++&gt;</th>
</tr>
</thead>
<tbody><tr>
<td>Ki:kibi</td>
<td>$1024^1$</td>
</tr>
<tr>
<td>Mi:mebi</td>
<td>$1024^2$</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
</tr>
</tbody></table>
<h2 id="中断和异常"><a href="#中断和异常" class="headerlink" title="中断和异常"></a>中断和异常</h2><h3 id="中断向量表的结构"><a href="#中断向量表的结构" class="headerlink" title="中断向量表的结构"></a>中断向量表的结构</h3><p>不同的中断产生不同的中断码，根据中断向量表查询得到对应的处理方法。</p>
<ul>
<li>中断向量：中断服务程序的入口地址</li>
<li>中断向量表存放在固定的地址</li>
<li>处理方法会事先存放在中断向量对应的地址处</li>
</ul>
<h3 id="中断的处理过程"><a href="#中断的处理过程" class="headerlink" title="中断的处理过程"></a>中断的处理过程</h3><ul>
<li><ol>
<li>关中断<ul>
<li>CPU关闭中断响应，不再接受其他外部中断请求</li>
</ul>
</li>
</ol>
</li>
<li><ol start="2">
<li>保存断点<ul>
<li>将发送中断处理的指令压入堆栈，处理完后正确返回</li>
</ul>
</li>
</ol>
</li>
<li><ol start="3">
<li>识别中断源<ul>
<li>确定中断类型号，从而找到相应的中断处理程序的入口地址</li>
</ul>
</li>
</ol>
</li>
<li><ol start="4">
<li>保存现场<ul>
<li>保存正在处理的程序</li>
</ul>
</li>
</ol>
</li>
<li><ol start="5">
<li>执行中断服务程序<ul>
<li>转到中断服务程序入口开始执行，可在适当的时刻重新开放中断，以便允许相应较高优先级的外部中断</li>
<li>重新开放由标识寄存器控制</li>
</ul>
</li>
</ol>
</li>
<li><ol start="6">
<li>恢复现场(8086为例)<ul>
<li>IRET指令(中断返回)，从栈顶弹出3个字分别送入IP、CS和FLAGS寄存器</li>
<li>放在中断服务程序的末尾</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="基于中断的功能调用"><a href="#基于中断的功能调用" class="headerlink" title="基于中断的功能调用"></a>基于中断的功能调用</h3><ul>
<li>指令<code>int N</code><ul>
<li>调用n号中断,由运行指令主动触发</li>
</ul>
</li>
</ul>
<h2 id="输入输出设备"><a href="#输入输出设备" class="headerlink" title="输入输出设备"></a>输入输出设备</h2><h3 id="输入输出接口的基本功能"><a href="#输入输出接口的基本功能" class="headerlink" title="输入输出接口的基本功能"></a>输入输出接口的基本功能</h3><ul>
<li>I/O接口改的基本功能<ul>
<li>数据缓冲<ul>
<li>解决CPU和外设之间的速度差距</li>
</ul>
</li>
<li>提供联络信息<ul>
<li>协调与同步数据交换过程</li>
</ul>
</li>
<li>信号与信息格式的转换<ul>
<li>模/数、数/模交换，串/并、并/串交换，电平转换</li>
</ul>
</li>
<li>设备选择</li>
<li>中断管理</li>
<li>可编程功能</li>
</ul>
</li>
</ul>
<h3 id="输入输出接口的编址方式"><a href="#输入输出接口的编址方式" class="headerlink" title="输入输出接口的编址方式"></a>输入输出接口的编址方式</h3><ul>
<li>I/O端口和存储器分开编址<ul>
<li>I/O映像的I/O方式，I/O Mapped I/O</li>
<li>x86就是这种方式</li>
<li>I/O指令<ul>
<li>IN指令<ul>
<li><code>IN AC, PORT</code></li>
<li>把外设端口内容输入到AL或AX</li>
</ul>
</li>
<li>OUT指令<ul>
<li><code>OUT PORT, AC</code></li>
<li>把AL或AX的内容输出到外设端口</li>
</ul>
</li>
<li>端口地址小于255时可以用立即数，否则需要寄存器</li>
</ul>
</li>
</ul>
</li>
<li>I/O端口和存储器统一编址<ul>
<li>存储器映像的I/O方式，Memory Mapped I/O</li>
<li>MIPS就是这种方式</li>
<li>优点<ul>
<li>可以用访问存储器的指令访问I/O端口，可以实现直接对I/O端口内的数据进行处理</li>
<li>CPU中的I/O操作与访问存储器的操作统一为一套控制逻辑，简化内部结构，减少PCU引脚的数目</li>
</ul>
</li>
<li>缺点<ul>
<li>I/O端口占用一部分存储器地址空间，使得存储器地址空间减小</li>
<li>由于利用访问存储器的指令来进行IO操作，指令的长度通常比单独IO指令要长，执行时间也较长</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="输入输出的控制方式"><a href="#输入输出的控制方式" class="headerlink" title="输入输出的控制方式"></a>输入输出的控制方式</h3><ul>
<li>IO控制方式的分类<ul>
<li>程序控制方式<ul>
<li>无条件传送方式<ul>
<li>假设外设已经准备号</li>
<li>CPU直接使用指令与外设传送数据</li>
<li>不查询外设的工作状态</li>
</ul>
</li>
<li>程序查询传送方式<ul>
<li>CPU通过指令一段程序，不断查询外设的工作状态<ul>
<li>握手信号，检查输入输出缓冲</li>
</ul>
</li>
<li>在外设准备就绪后草进行数据传送</li>
<li>CPU的不断查询浪费了很多资源</li>
</ul>
</li>
</ul>
</li>
<li>中断控制方式<ul>
<li>通过中断的方式，将数据”一块一块”地传送，当输入输出缓冲达到一定条件时，引发中断，提醒CPU的继续输入或读取等</li>
<li>优点<ul>
<li>CPU可和外设并行工作</li>
<li>外围设备具有申请父亲的主动权</li>
<li>一定程度上满足了IO处理的实时性要求</li>
</ul>
</li>
<li>缺点<ul>
<li>输入输出的数据仍由CPU承担</li>
<li>进入和退出中断增加消耗</li>
</ul>
</li>
</ul>
</li>
<li>直接存储器访问(DMA)方式<ul>
<li>前面的方式的共同确定是数据传输仍由CPU承担，但是如果是显示器，网络等需要大量数据传输的设备就难以应对了</li>
<li>Direct Memory Access(DMA)<ul>
<li>数据传送过程不需要CPU干预(不需要指令程序指令)</li>
<li>由专门的硬件控制电路控制，进行外设与存储器间直接数据传送</li>
<li>该专门硬件控制电路称为DMA控制器，简称DMAC</li>
</ul>
</li>
<li>DMAC的基本工作步骤(以使用独立DMAC进行外设到内存传送为例)<ul>
<li><ol>
<li>CPU设置DMAC内部配置寄存器<ul>
<li>源地址的初始值以及传送是的地址增减方式</li>
<li>目的地址的初始值以及传送是的地址增减方式</li>
<li>待传送数据的长度</li>
</ul>
</li>
</ol>
</li>
<li><ol start="2">
<li>DMAC处于空闲等待状态</li>
</ol>
</li>
<li><ol start="3">
<li>IO接口向DMAC传送申请</li>
</ol>
</li>
<li><ol start="4">
<li>DMAC响应IO接口的申请</li>
</ol>
</li>
<li><ol start="5">
<li>DMAC向IO接口发起总线读传输</li>
</ol>
</li>
<li><ol start="6">
<li>DMAC向存储器发起总线写传输</li>
</ol>
</li>
<li><ol start="7">
<li>重复5～6直到本次DMA传送完成</li>
</ol>
</li>
<li><ol start="8">
<li>返回2，等待下一次DMA传送申请</li>
</ol>
</li>
</ul>
</li>
<li>通常，DMA传送完成后DMAC会通过中断信号通知CPU</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/26/Major/arithmetic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/11/26/Major/arithmetic/" class="post-title-link" itemprop="url">算法学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-11-26 00:00:00" itemprop="dateCreated datePublished" datetime="2019-11-26T00:00:00+08:00">2019-11-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-29 21:10:47" itemprop="dateModified" datetime="2020-06-29T21:10:47+08:00">2020-06-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><ul>
<li>比较大小,如果符合条件(升序)就交换两个元素的位置  <ul>
<li>每次执行N-1次</li>
<li>严格大/小,保证了原序(稳定性)</li>
<li>没次能保证最大/最小的元素会在最后</li>
</ul>
</li>
<li>如果全程无交换,则说明有序了,跳出即可</li>
<li>$T=O(x),x\in(N,N^2)$</li>
</ul>
<h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><ul>
<li>每次抽取一个元素,然后从序列末尾开始进行比较</li>
<li>若符合条件,往后移位,直到不符合条件跳出</li>
<li>然后插入元素</li>
</ul>
<h4 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h4><p>对插入排序的改进,每次消除多个逆序对以达到加速的效果  </p>
<ul>
<li>按照一定增量序列,每次进行D排序 $D_N &gt; D_{N-1}…&gt;D_1$ ,这样一来一趟就有可能消除多个逆序对<ul>
<li>按照$D_N &gt; D_{N-1}…&gt;D_1$进行排序,后一次会保持前一次的顺序,故可用</li>
<li>但最终都要进行1排序</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(D=N/<span class="number">2</span>;D&gt;<span class="number">0</span>;D/=<span class="number">2</span>)&#123;  <span class="comment">// 希尔增量序列。Hibbard增量序列:Dk=2^k-1...等等</span></span><br><span class="line">    <span class="keyword">for</span>(p=D;p&lt;N;p++)&#123;  <span class="comment">// 插入排序</span></span><br><span class="line">        Tmp = A[p];</span><br><span class="line">        <span class="keyword">for</span>(i=p;i&gt;=D&amp;&amp;A[i-D]&gt;Tmp;i-=D)&#123;</span><br><span class="line">            A[i] = A[i-D];</span><br><span class="line">        &#125;</span><br><span class="line">        A[i] = Tmp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><h4 id="小-大顶堆"><a href="#小-大顶堆" class="headerlink" title="小/大顶堆"></a>小/大顶堆</h4><p>子节点比父节点小/大的二叉树  </p>
<p><strong>构建方法</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 法一：上浮下沉法(小顶堆为例)</span></span><br><span class="line"><span class="comment">// 从第一个非叶子节点开始，以它为子树，先自下而上把小的节点上浮，到达子树根节点后自上而下把大的节点下沉</span></span><br><span class="line"><span class="comment">// 知道根节点结束</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createHeap</span><span class="params">(<span class="keyword">int</span> *heap,<span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=len/<span class="number">2</span><span class="number">-1</span>;j&gt;=<span class="number">0</span>;j--)&#123;</span><br><span class="line">        <span class="keyword">int</span> t = j;</span><br><span class="line">        <span class="keyword">while</span>((t+<span class="number">1</span>)*<span class="number">2</span>&lt;=len)&#123;</span><br><span class="line">            <span class="keyword">int</span> <span class="built_in">min</span> = (t+<span class="number">1</span>)*<span class="number">2</span><span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">min</span>+<span class="number">1</span>&lt;len)&#123;</span><br><span class="line">                <span class="keyword">if</span>(heap[<span class="built_in">min</span>+<span class="number">1</span>]&lt;heap[<span class="built_in">min</span>])&#123;</span><br><span class="line">                    <span class="built_in">min</span>++; </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(heap[<span class="built_in">min</span>]&lt;heap[t])&#123;</span><br><span class="line">                swop(<span class="built_in">min</span>,t,heap);</span><br><span class="line">                t = <span class="built_in">min</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 法二：插入法</span></span><br><span class="line"><span class="comment">// 从根节点出发，若父节点比插入元素大，则调整位置，如此循环，保证父节点小于子节点</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createHeap</span><span class="params">(<span class="keyword">int</span> *heap,<span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">    heap[<span class="number">0</span>] = <span class="number">-1000</span>;</span><br><span class="line">    <span class="keyword">int</span> temp;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=len;i++)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;temp);</span><br><span class="line">        <span class="keyword">int</span> j;</span><br><span class="line">        <span class="keyword">for</span>(j=i;heap[j/<span class="number">2</span>]&gt;temp;j/=<span class="number">2</span>)&#123;</span><br><span class="line">            heap[j] = heap[j/<span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        heap[j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="利用小-大顶堆排序"><a href="#利用小-大顶堆排序" class="headerlink" title="利用小/大顶堆排序"></a>利用小/大顶堆排序</h4><ul>
<li>根据小/大顶堆的性质，可以确定顶部一定是最大或最小的元素</li>
<li>交换根节点和最后一个节点，那么最后一个节点一定是最大/最小</li>
<li>把最后的节点排除，剩下节点构成的子树再调整成小/大顶堆，重复以上步骤</li>
</ul>
<h3 id="快速排序算法"><a href="#快速排序算法" class="headerlink" title="快速排序算法"></a>快速排序算法</h3><p>通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列    </p>
<ul>
<li>先从数列中取出一个数作为主元<ul>
<li>主元选不好会影响速度</li>
<li>法1.选头,中,尾三个数的中位数做主元</li>
</ul>
</li>
<li>分区过程，交替移动，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边</li>
<li>再对左右区间重复第二步，直到各区间只有一个数</li>
</ul>
<h3 id="擂台法"><a href="#擂台法" class="headerlink" title="擂台法"></a>擂台法</h3><ul>
<li>适用于找最值</li>
</ul>
<h3 id="归并法"><a href="#归并法" class="headerlink" title="归并法"></a>归并法</h3><ul>
<li>把两个有序的序列合并</li>
<li>法1.递归的进行下去(有点类似快速排序)</li>
<li>法2.每个元素看成一段序列,合并合并…</li>
<li>$T=N\log{N}$</li>
<li>缺点:需要开额外一份空间</li>
</ul>
<h2 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h2><h3 id="AOV-activity-on-vertex"><a href="#AOV-activity-on-vertex" class="headerlink" title="AOV(activity on vertex)"></a>AOV(activity on vertex)</h3><p>节点代表事件<br>若v到w连通,则v一定在w的前面  </p>
<ul>
<li>有向图</li>
<li>有优先级限制<br>按照此法输出就是拓扑排序  </li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Queuezero Q;   <span class="comment">// 储存入度为零的,即前头没有限制了的</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;|V|;i++)&#123;    <span class="comment">// 记录最先的入度为0的节点</span></span><br><span class="line">    <span class="keyword">if</span>(indegree[V]==<span class="number">0</span>)&#123;</span><br><span class="line">        Enqueue(V,Q);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span>(!isEmpty(Q))&#123;</span><br><span class="line">    V = Dequeue(Q);  <span class="comment">//cnt++,记录或者输出什么的(拓扑排序)</span></span><br><span class="line">    <span class="keyword">for</span>(V的每个邻接点W)&#123;</span><br><span class="line">        indegree(W)--;</span><br><span class="line">        <span class="keyword">if</span>(degree(w)==<span class="number">0</span>)&#123;</span><br><span class="line">            Enqueue(W,Q);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(cnt!=|V|)</span><br><span class="line">    图有回路,无法拓扑排序</span><br></pre></td></tr></table></figure>

<h3 id="AOE-activity-on-edge"><a href="#AOE-activity-on-edge" class="headerlink" title="AOE(activity on edge)"></a>AOE(activity on edge)</h3><p>例:关键路径问题  </p>
<h3 id="表排序"><a href="#表排序" class="headerlink" title="表排序"></a>表排序</h3><p>当移动的成本很高时(如移动一部电影)就用表来储存他的顺序</p>
<ul>
<li>table[N]指向N,故用table[N]进行访问\排序</li>
</ul>
<h3 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h3><p>基本原理:假如有10个数分别是0<del>9让你排序,那建立10个桶ar[10],根据情况0</del>9放到对应的桶了,最后顺序输出桶就是有序的了</p>
<h4 id="LSD-Least-Significant-Digit-次位优先"><a href="#LSD-Least-Significant-Digit-次位优先" class="headerlink" title="LSD(Least Significant Digit)次位优先"></a>LSD(Least Significant Digit)次位优先</h4><p>排10个在0~999的整数难道要建1000个桶吗？</p>
<ul>
<li>根据低位到高位建通(实际情况肯更抽象)<ul>
<li>这里是从个位到百位,没位置建10桶</li>
<li>个位桶建装好后再遍历桶,装十位的桶,以此类推</li>
<li>因为是遍历有序桶来填入新桶的,所以最后的桶只需按顺序输出就是有序了</li>
</ul>
</li>
</ul>
<hr>
<h1 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h1><h3 id="散列-hash-查找"><a href="#散列-hash-查找" class="headerlink" title="散列(hash)查找"></a>散列(hash)查找</h3><p>把关键词看成变量,通过哈希函数运算赋予地址</p>
<h4 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h4><p>关键词是数字时的常见方法</p>
<ul>
<li>折叠法</li>
<li>平方取中法</li>
<li>数字分析法</li>
<li>除留余数法</li>
</ul>
<p>关键词是字符时的常见方法</p>
<ul>
<li>位移法(变成整数移位&lt;&lt;求余)</li>
</ul>
<p><strong>核心思想就是当一位改变时尽可能多的影响位数,避免浪费</strong></p>
<h4 id="处理冲突"><a href="#处理冲突" class="headerlink" title="处理冲突"></a>处理冲突</h4><p>产生冲突就添加偏移量到别的位置  </p>
<ul>
<li>线性探测<ul>
<li>偏移量是一增量序列: 1.2.3.4…</li>
<li>容易产生聚集</li>
</ul>
</li>
<li>平方探测<ul>
<li>偏移量是一增量序列: 1^2.2^2.3^2.4^2…</li>
<li>容易产生死循环<ul>
<li>定理:散列表长是某个4k+3的素数时,一定能探测整个表</li>
</ul>
</li>
</ul>
</li>
<li>双散列探测<ul>
<li>$d_i = i\times h_2(kay)$</li>
<li>$h_2(key)=p-(key mod p)$ 效果最好</li>
</ul>
</li>
<li>再散列<ul>
<li>装填因子太大是查找效率下降</li>
<li>那就扩大散列表,在把原来的元素搬进去</li>
</ul>
</li>
<li>分离链接法<ul>
<li>有冲突的关键字都放在(同一个关键字的)一个链表中</li>
</ul>
</li>
</ul>
<p><strong>删除时不能直接删除,会影响后续的查找。正确的删除是标记为删除,新的元素来时再替换</strong></p>
<h3 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h3><p><strong>要点：</strong> </p>
<ul>
<li>前缀表next(或者说match)函数的创建</li>
</ul>
<p>利用前缀表的原理：对于一个子串(如：ababc)，所有可能的前缀:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a</span><br><span class="line">a b</span><br><span class="line">a b a</span><br><span class="line">a b a b</span><br><span class="line">a b a b c</span><br></pre></td></tr></table></figure>

<p>我们需要找出每种可能中最长的、非本身的公共前后缀，因为如果前后缀相同的话，当后缀失去匹配时，可从前缀结束的地方开始匹配，而不是从头开始。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a               null    0</span><br><span class="line">a b             null    0</span><br><span class="line">a b a           a       1</span><br><span class="line">a b a b         ab      2</span><br><span class="line">a b a b c       null    0  &lt;一般剔除字符串本身,在开头填-1</span><br><span class="line"></span><br><span class="line">这些最长公共前后缀的长度就构成了前缀表</span><br><span class="line"> a b a b c</span><br><span class="line">-1 0 0 1 2</span><br><span class="line">这样就表示了当，str[j]失去匹配时，从match[j](前缀结束的地方)尝试匹配</span><br></pre></td></tr></table></figure>

<p><strong>前缀表如何创建</strong></p>
<ul>
<li>可将创建一个子串前缀表的问题划分为一系列子问题：<ul>
<li>创建每种前缀的前缀表</li>
<li>为每种前缀构造前缀表又是一个个子串匹配问题：前1为是否匹配(是否有公共后缀)、前2位是否匹配，…，前n位是否</li>
<li>又因为从最短开始尝试，最短的又为次短的做了铺垫。最短串的KMP创建了次短所需的前缀表</li>
</ul>
</li>
</ul>
<p>对于ababc，可以划分为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">a</span><br><span class="line">长的1,不需要前缀表辅助匹配。得到前缀表：</span><br><span class="line">[-1]</span><br><span class="line"></span><br><span class="line">a b</span><br><span class="line">对于ab，找最长公共前后缀。找前1位(a)时，相当与在串ab中找匹配的子串a，而子串a的前缀表已经由上一步得出，前2位ab是它本身，结束匹配。得</span><br><span class="line">[-1, 0]</span><br><span class="line"></span><br><span class="line">a b a</span><br><span class="line">对于aba，找最长公共前后缀。找前1位(a)时，相当与在串aba中找匹配的子串a，而子串a的前缀表已经由上一步得出，前2位同理。得</span><br><span class="line">[-1 0 1]</span><br><span class="line"></span><br><span class="line">a b a b</span><br><span class="line">a b a b c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for(j&#x3D;1;j&lt;len;j++)&#123;</span><br><span class="line">    p &#x3D; m[j-1];</span><br><span class="line">    &#x2F;&#x2F;尝试利用前缀表找到匹配的公共前后缀</span><br><span class="line">    while(p&gt;&#x3D;0&amp;&amp;pattern[p+1]!&#x3D;pattern[j])&#123;</span><br><span class="line">        p &#x3D; m[p];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;如果下一位匹配，公共前后缀长的等于当前匹配的公共前后缀长度加1</span><br><span class="line">    &#x2F;&#x2F;否则不匹配</span><br><span class="line">    if(pattern[p+1]&#x3D;&#x3D;pattern[j])&#123;</span><br><span class="line">        m[j] &#x3D; p+1;</span><br><span class="line">    &#125;else &#123;</span><br><span class="line">        m[j] &#x3D; -1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<hr>
<h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><h3 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h3><ul>
<li>左边孩子比根节点小</li>
<li>右边孩子比根节点大</li>
</ul>
<p><strong>查找</strong>  </p>
<ul>
<li>左小右大，递归或循环  </li>
</ul>
<p><strong>插入</strong></p>
<ul>
<li>左小右大，递归或循环  </li>
</ul>
<p><strong>删除</strong></p>
<ul>
<li>没有孩子<ul>
<li>直接插入</li>
</ul>
</li>
<li>只有一个孩子<ul>
<li>子承父业</li>
</ul>
</li>
<li>有两个孩子<ul>
<li>找到左子树的最大或右子树的最小替换被删除节点…有效降低树的高度</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">BinTree <span class="title">Delete</span><span class="params">( BinTree BST, ElementType X )</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    Position Tmp; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span>( !BST ) </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"要删除的元素未找到"</span>); </span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>( X &lt; BST-&gt;Data ) </span><br><span class="line">            BST-&gt;Left = Delete( BST-&gt;Left, X );   <span class="comment">/* 从左子树递归删除 */</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>( X &gt; BST-&gt;Data ) </span><br><span class="line">            BST-&gt;Right = Delete( BST-&gt;Right, X ); <span class="comment">/* 从右子树递归删除 */</span></span><br><span class="line">        <span class="keyword">else</span> &#123; <span class="comment">/* BST就是要删除的结点 */</span></span><br><span class="line">            <span class="comment">/* 如果被删除结点有左右两个子结点 */</span> </span><br><span class="line">            <span class="keyword">if</span>( BST-&gt;Left &amp;&amp; BST-&gt;Right ) &#123;</span><br><span class="line">                <span class="comment">/* 从右子树中找最小的元素填充删除结点 */</span></span><br><span class="line">                Tmp = FindMin( BST-&gt;Right );</span><br><span class="line">                BST-&gt;Data = Tmp-&gt;Data;</span><br><span class="line">                <span class="comment">/* 从右子树中删除最小元素 */</span></span><br><span class="line">                BST-&gt;Right = Delete( BST-&gt;Right, BST-&gt;Data );</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123; <span class="comment">/* 被删除结点有一个或无子结点 */</span></span><br><span class="line">                Tmp = BST; </span><br><span class="line">                <span class="keyword">if</span>( !BST-&gt;Left )       <span class="comment">/* 只有右孩子或无子结点 */</span></span><br><span class="line">                    BST = BST-&gt;Right; </span><br><span class="line">                <span class="keyword">else</span>                   <span class="comment">/* 只有左孩子 */</span></span><br><span class="line">                    BST = BST-&gt;Left;</span><br><span class="line">                <span class="built_in">free</span>( Tmp );</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> BST;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h3><h3 id="哈夫曼树"><a href="#哈夫曼树" class="headerlink" title="哈夫曼树"></a>哈夫曼树</h3><h3 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h3><ul>
<li>特征<ul>
<li>根节点是黑色</li>
<li>所有叶子搜索黑色</li>
<li>每个红色节点的两个字节点都是黑色(不存在两个连续的红色节点)</li>
<li>从任意节点到其每个叶子的所有路径都包含相同数目的黑色节点</li>
</ul>
</li>
<li>搜索<ul>
<li>比节点小就找左子树，否则右子树</li>
</ul>
</li>
</ul>
<hr>
<h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><h2 id="DFS深度优先搜索"><a href="#DFS深度优先搜索" class="headerlink" title="DFS深度优先搜索"></a>DFS深度优先搜索</h2><ul>
<li>从一节点出发<ul>
<li>非连通图分而治之</li>
</ul>
</li>
<li>依次从访问邻接点,直至所有邻接点都被访问<ul>
<li>例:迷宫  </li>
</ul>
</li>
</ul>
<h2 id="BFS广度优先搜索"><a href="#BFS广度优先搜索" class="headerlink" title="BFS广度优先搜索"></a>BFS广度优先搜索</h2><ul>
<li>从一节点出发</li>
<li>把他所有的邻接点入队列,并检测目标节点</li>
<li>依次把节点出队列,并递归的把他的邻接点入队列,直到访问所有点<ul>
<li>例:树的层序遍历  </li>
</ul>
</li>
</ul>
<h3 id="并查集"><a href="#并查集" class="headerlink" title="并查集"></a>并查集</h3><p>若存在两点在同一个连通集合中，则这两点存在回路</p>
<ul>
<li>Find() 找根节点</li>
<li>Union() 合并成集合</li>
</ul>
<h2 id="最短路问题"><a href="#最短路问题" class="headerlink" title="最短路问题"></a>最短路问题</h2><h3 id="Dijkstra算法"><a href="#Dijkstra算法" class="headerlink" title="Dijkstra算法"></a>Dijkstra算法</h3><p>解决单源路非递减顺序(没有负)最短路径问题</p>
<ul>
<li>对所有未检索的点进行标记:collected[v] = false</li>
<li>从一点出发,记录所有邻接点,若邻接点加入后路径最短,则更新<ul>
<li>类似BFS</li>
</ul>
</li>
<li>所有邻接点访问完后colleceted[v]=true,从下一个未检索的点继续循环,直到检索所有节点</li>
</ul>
<h3 id="Floyd算法"><a href="#Floyd算法" class="headerlink" title="Floyd算法"></a>Floyd算法</h3><p>解决多源路非递减顺序最短路径问题   </p>
<p>稠密图有优势  </p>
<p>$T=O(V^3)$  </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 核心</span></span><br><span class="line"><span class="comment">// 顶点i到顶点j,顶点间的最短路就在矩阵显示出来了</span></span><br><span class="line"><span class="keyword">for</span>(k = <span class="number">0</span>;k&lt;N;k++)&#123;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;N;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;N;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(D[i][k]+D[k][j]&lt;D[i][j])&#123;</span><br><span class="line">                D[i][j] = D[i][k]+D[k][j];</span><br><span class="line">                path[i][j] = k;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="Prim算法"><a href="#Prim算法" class="headerlink" title="Prim算法"></a>Prim算法</h3><p>解决稠密图的最小生成树问题  </p>
<ul>
<li>从任意点出发</li>
<li>寻找与这个整体相邻,且不构成回路的权最小点</li>
<li>加入该整体,继续搜索,直至所有点都收录(生成树必须包含所有点)</li>
</ul>
<h3 id="Kruskal算法"><a href="#Kruskal算法" class="headerlink" title="Kruskal算法"></a>Kruskal算法</h3><p>解决稀疏图的最小生成树问题  </p>
<p>$T=E\log{E}$  </p>
<ul>
<li>核心思想,每个顶点都是一棵树,把森林连成树</li>
<li>找最短且不构成回路的边,又因为每个顶点都是一棵树,每个边都把森林连成树</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">MST=&#123;&#125;;  <span class="comment">// 最小生成树</span></span><br><span class="line">E;   <span class="comment">// 边集</span></span><br><span class="line"><span class="keyword">while</span>(没够V<span class="number">-1</span>条边&amp;&amp;E没空)&#123;</span><br><span class="line">    findmin();  <span class="comment">// 找最小边  用最小堆</span></span><br><span class="line">    delet(E(v,w));  <span class="comment">// 把该边移除边集E</span></span><br><span class="line">    <span class="keyword">if</span>(E(v,w)加入MST不构成回路)   <span class="comment">// 并查集</span></span><br><span class="line">        join(E(v,w));  <span class="comment">// 加入并查集</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        单纯的删除</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(MST中边不够V<span class="number">-1</span>条)</span><br><span class="line">    生成树不存在</span><br></pre></td></tr></table></figure>


<hr>
<h1 id="效率问题"><a href="#效率问题" class="headerlink" title="效率问题"></a>效率问题</h1><h3 id="联机算法"><a href="#联机算法" class="headerlink" title="联机算法"></a>联机算法</h3><p>在任意时刻，算法对要操作的数据只读入（扫描）一次，一旦被读入并处理，它就不需要在被记忆了。而在此处理过程中算法能对它已经读入的数据立即给出相应子序列问题的正确答案。具有这种特性的算法叫做联机算法（on-line algorithm。</p>
<h3 id="分治算法"><a href="#分治算法" class="headerlink" title="分治算法"></a>分治算法</h3><p>在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。这个技巧是很多高效算法的基础，如排序算法(快速排序，归并排序)，傅立叶变换(快速傅立叶变换)……</p>
<ul>
<li>该问题的规模缩小到一定的程度就可以容易地解决</li>
<li>该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质</li>
<li>利用该问题分解出的子问题的解可以合并为该问题的解</li>
<li>该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题</li>
</ul>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/19/universe/tensorflow_learning/Tensorflow_learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/19/universe/tensorflow_learning/Tensorflow_learning/" class="post-title-link" itemprop="url">Tensorflow</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-19 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-19T00:00:00+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-15 21:34:14" itemprop="dateModified" datetime="2020-06-15T21:34:14+08:00">2020-06-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><h3 id="图片读取展示"><a href="#图片读取展示" class="headerlink" title="图片读取展示"></a>图片读取展示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2  <span class="comment"># 引入OpenCV</span></span><br><span class="line">img = cv2.imread(<span class="string">'path'</span>,<span class="number">1</span>)  <span class="comment"># 读取图片，0是灰图，1是彩图</span></span><br><span class="line">cv2.imshow(<span class="string">'image'</span>,img)  <span class="comment"># 'image'打开的窗体的标题，img展示的内容</span></span><br><span class="line">cv2.waitKey(<span class="number">0</span>)  <span class="comment"># 暂停</span></span><br></pre></td></tr></table></figure>
<p>cv.imread 过程：1文件读取 2封装格式解析 3数据解码 4数据加载  </p>
<h3 id="读写操作"><a href="#读写操作" class="headerlink" title="读写操作"></a>读写操作</h3><h4 id="图片读写"><a href="#图片读写" class="headerlink" title="图片读写"></a>图片读写</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(<span class="string">'path'</span>,<span class="number">1</span>)  <span class="comment"># 读取图片，0是灰图，1是彩图</span></span><br><span class="line">cv2.imwrite(<span class="string">"path"</span>,img)  <span class="comment"># 1,图片名 2.图片数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同质量的图片写入</span></span><br><span class="line"><span class="comment"># jpg,有损压缩</span></span><br><span class="line"><span class="comment"># 压缩比参数范围为0~100，越低压缩比越高</span></span><br><span class="line">cv2.imwrite(<span class="string">"path.jpg"</span>,img,[cv2.IMWRITE_JPEG_QUALITY,<span class="number">0</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># png是无损压缩，有透明度属性</span></span><br><span class="line"><span class="comment"># 压缩比参数0~9,越低压缩比越低</span></span><br><span class="line">cv2.imwrite(<span class="string">"path.png"</span>,img,[cv2.IMWRITE_PNG_QUALITY,<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<h4 id="操作像素"><a href="#操作像素" class="headerlink" title="操作像素"></a>操作像素</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(<span class="string">"img.jpg"</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># OpenCv读取图片是bgr(rgb倒过来)，左上角开始的坐标轴</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取像素点</span></span><br><span class="line">(b,g,r) = img[x,y]</span><br><span class="line">print(b,g,r)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入像素</span></span><br><span class="line">img[x,y] = (b,g,r)</span><br></pre></td></tr></table></figure>





<hr>
<h1 id="OpenCv"><a href="#OpenCv" class="headerlink" title="OpenCv"></a>OpenCv</h1><h3 id="OpenCv模块结构"><a href="#OpenCv模块结构" class="headerlink" title="OpenCv模块结构"></a>OpenCv模块结构</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">to be continued</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Tensotflow"><a href="#Tensotflow" class="headerlink" title="Tensotflow"></a>Tensotflow</h1><h4 id="基本操作-1"><a href="#基本操作-1" class="headerlink" title="基本操作"></a>基本操作</h4><h5 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 定义常量</span></span><br><span class="line">data1 = tf.constant(<span class="number">2.5</span>)  <span class="comment"># 指定数据类型可以加参数(2,dtype=tf.int32)</span></span><br><span class="line"><span class="comment"># 定义变量</span></span><br><span class="line">data2 = tf.Variable(b,name=<span class="string">"name"</span>)</span><br><span class="line"><span class="comment"># 打印出来的是描述信息</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有操作要session会话进行</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(data1))  <span class="comment"># 通过会话进行的就可以打印了</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有变量都要用session进行初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)  <span class="comment"># 初始化</span></span><br><span class="line"><span class="comment"># session打印多个内容</span></span><br><span class="line">sess.run([x1,x2,x3])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭session</span></span><br><span class="line"><span class="comment"># 法一</span></span><br><span class="line">sess.close()</span><br><span class="line"><span class="comment"># 法二  with</span></span><br><span class="line"><span class="keyword">with</span> sees:</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>

<h5 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensorflow运算的每个类型都要是tensor</span></span><br><span class="line"><span class="comment"># 转换为tensor,如 a=np.arange(1)</span></span><br><span class="line">aa = tf.convert_to_tensor(a,dtye=tf.int32) <span class="comment">#dtype=数据类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor类型间转换</span></span><br><span class="line">tf.cast(aa,dtype=tf.double)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Variable</span></span><br><span class="line"><span class="comment"># Variable包装过的变量会具有一些特殊的属性,如可导</span></span><br><span class="line">b=tf.Variable(b,name=<span class="string">"name"</span>)</span><br><span class="line">b.name</span><br><span class="line">b.trainable</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor变numpy</span></span><br><span class="line"><span class="comment"># tensor一般在GPU,当有时我们要在CPU上处理默写逻辑时就要转成numpy</span></span><br><span class="line">a.numpy()  <span class="comment"># tensor:a 就变成了numpy</span></span><br></pre></td></tr></table></figure>

<h5 id="创建tensor"><a href="#创建tensor" class="headerlink" title="创建tensor"></a>创建tensor</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a.convert_to_tensor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">tf.zeros(shape)  <span class="comment"># tf.zeros_like(a) 初始化一个和a一样维度的(shape)</span></span><br><span class="line">tf,ones(shape)</span><br><span class="line">tf.fill(shape,elem)</span><br><span class="line">tf.random.normal(shape,mean=<span class="number">1</span>,stddev=<span class="number">1</span>)  <span class="comment"># 用正态分布采样(normal,其他分部同理)初始化一个,其中mean,stddev正太分部的参数,其他分部同理</span></span><br><span class="line">tf.random.truncated_normal(...)  <span class="comment"># 截断的正态分布</span></span><br><span class="line">tf.random.uniform(shape,minval=<span class="number">0</span>,maxval=<span class="number">1</span>)  <span class="comment"># 均匀分布采样</span></span><br><span class="line"><span class="comment"># shape表示维度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打散</span></span><br><span class="line"><span class="comment"># 就是random了,但是如果是两组有一一对应关系的东西,怎么打散才不会破坏那个一一对应关系?</span></span><br><span class="line">idx = tf.range(<span class="number">10</span>)  <span class="comment"># 假设有10组数据</span></span><br><span class="line">idx = rf.random.shuffle(idx)  <span class="comment"># (就好比生成了10组随机的通道(每个通道代表一种一一对应关系)通道两边绑定了,所以对应关系不变)</span></span><br></pre></td></tr></table></figure>

<h5 id="索引与切片"><a href="#索引与切片" class="headerlink" title="索引与切片"></a>索引与切片</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 索引</span></span><br><span class="line"><span class="comment"># numpy风格的索引，如：</span></span><br><span class="line">a.shape() = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">a[<span class="number">1</span>,<span class="number">2</span>].shape = [<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"><span class="comment"># 索引写在一个[]内，用逗号隔开</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切片</span></span><br><span class="line"><span class="comment"># 对于某个维度</span></span><br><span class="line">a[<span class="number">-1</span>:]  <span class="comment"># 到数第一个到最后一个,就是python的切片</span></span><br><span class="line"><span class="comment"># 对多个维度的切片</span></span><br><span class="line">a[<span class="number">0</span>,<span class="number">1</span>,:,<span class="number">1</span>:<span class="number">3</span>,:]  <span class="comment"># (取a01的全部的1到3的全部。。。很灵活)</span></span><br><span class="line"><span class="comment"># step,步长.... [::] 同理, 步长为负，实现倒叙</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 省略号:省略多个:(自动识别)</span></span><br><span class="line">a[<span class="number">1</span>,<span class="number">2</span>,...,<span class="number">0</span>,:]  <span class="comment"># 中间的没有切片操作,但是倒数第二有切片操作,用...就不用人为的把中间的:不上了</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Selective Indexing </span></span><br><span class="line"><span class="comment"># 可以乱序取样</span></span><br><span class="line"><span class="comment"># 假设a.shape = [4,32,8] ,a[4个班,35个学生,8门科目成绩]</span></span><br><span class="line">a = tf.gather(a,axis=<span class="number">0</span>,indices=[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 1.取样的样本 2.抽取的维度,上面就是从第一个维度中乱序的抽取,随机抽取一个班查看 3.抽取的顺序,抽2班1班3班0班</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还是上面的例子,如果想要取n个学生的m门成绩呢？</span></span><br><span class="line">aa = tf.gather(a,axis=<span class="number">1</span>,indices=[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">0</span>])  <span class="comment"># 取4个班2，1，3，0号学生</span></span><br><span class="line">aaa = tf.gather(aa,axis=<span class="number">2</span>,indices=[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">0</span>])  <span class="comment"># 取这4个班2，1，3，0号学生,的2，1，3，0号成绩</span></span><br><span class="line"><span class="comment"># 多个gather嵌套</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.gather_nd !!!比较难理解</span></span><br><span class="line">gather_nd(a,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])  <span class="comment"># 1班1号同学的1号成绩,标量</span></span><br><span class="line">gather_nd(a,[[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]])  <span class="comment"># 0班0号同学的8门成绩,和1班1号同学的8门成绩,组成的矩阵,shape = [2,8] 2个同学,8门成绩</span></span><br><span class="line">gather_nd(a,[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>]])  <span class="comment"># shape = [2]</span></span><br><span class="line">gather_nd(a,[[[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>]]])  <span class="comment"># shape = [1,2]</span></span><br><span class="line"><span class="comment"># 体会标量放[]里和矩阵放[]里的区别,差不多就是这个意思</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.boolean_mask</span></span><br><span class="line"><span class="comment"># 通过boolean来取样 假设a.shape = [4,28,28,3]</span></span><br><span class="line">tf.boolean_mask(a,mask=[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>])  <span class="comment"># 默认从最外层(mask嘛)</span></span><br><span class="line"><span class="comment"># 结果shape = [2,28,28,3]</span></span><br><span class="line"><span class="comment"># 多维遮罩 例:a.shape = [2,3,4]</span></span><br><span class="line">tf.boolean_mask(a,mask=[[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>],[<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">True</span>]])  <span class="comment"># mask.shape=[2,3] 采样的元素取对应关系,根据mask,第0行第一个元素是True，所以要...</span></span><br><span class="line"><span class="comment"># 结果shape = [3,4]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然也可以指定,遮罩哪个维度 </span></span><br><span class="line">tf.boolean_mask(a,mask=[<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>],axis = <span class="number">3</span>)  <span class="comment"># shape = [4,28,28,2]</span></span><br></pre></td></tr></table></figure>

<h5 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a.shape = [4,28,28,3]</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">784</span>,<span class="number">3</span>])  <span class="comment"># 4*28*28*3  ==  4*784*3 才能保证所有数据充分利用</span></span><br><span class="line"><span class="comment"># 如果先偷懒的话可以用-1</span></span><br><span class="line">tf.reshape(a,[<span class="number">4</span>,<span class="number">-1</span>,<span class="number">3</span>])  <span class="comment"># 一个式子只能有一个-1,-1就相当于x,保证4*28*28*3 == 4*x*3</span></span><br><span class="line"><span class="comment"># 变换前要理清楚物理含义</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵变换,改变格式</span></span><br><span class="line"><span class="comment"># a.shape = [4,3,2,1] </span></span><br><span class="line">tf.transpose(a)  <span class="comment"># 矩阵转置</span></span><br><span class="line">tf.transpose(a,perm=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>])  <span class="comment"># 原来的0维放在新的0维...原来的3维放在新的2维...</span></span><br><span class="line"><span class="comment"># 结果 shape = [4,3,1,2]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 维度的增加</span></span><br><span class="line"><span class="comment"># a.shape=[4,35,8]</span></span><br><span class="line">tf.expand_dims(a,axis=<span class="number">0</span>)  <span class="comment"># 插入的(一个)维度相当于插入后维度的第0维,a.shape=[1,4,35,8]</span></span><br><span class="line">tf.expand_dims(a,axis=<span class="number">3</span>)  <span class="comment"># 插入的维度相当于插入后维度的第3维,a.shape=[4,35,8,1]</span></span><br><span class="line"><span class="comment"># 负数同理</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 维度减少</span></span><br><span class="line"><span class="comment"># 元素个数为1的维度是可以去掉的,a.shape=[1,2,1,1,3]</span></span><br><span class="line">tf.squeeze(a)  <span class="comment"># 不加axis参数就是把所有1去掉</span></span><br><span class="line">tf.squeeze(a,axis=<span class="number">2</span>)  <span class="comment"># 把第二维度去掉</span></span><br></pre></td></tr></table></figure>

<h5 id="Broadcasting"><a href="#Broadcasting" class="headerlink" title="Broadcasting"></a>Broadcasting</h5><ul>
<li>expand without copying data:扩张了一个数据,但实际上并没有复制出来多份<img src="./static/broadcasting.png" style="zoom:50%">

</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tf.broadcast_to</span><br><span class="line"><span class="comment"># ape=[3,5]</span></span><br><span class="line">aa = broadcast_to(a,[<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>])</span><br><span class="line">aa.shape = [<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如前面的 x@w+b,b是一个一维的，但却能加上去,就是broadcast的功劳</span></span><br><span class="line"><span class="comment"># 如a.shape=[4,16,16,32] b.shape=[32]</span></span><br><span class="line"><span class="comment"># 如果a+b 那么b就会相当于自动变成[4,16,16,32],以满足相应的运算(包括加减乘除</span></span><br><span class="line"><span class="comment"># 先从小维度开始匹配,自动扩张是满足运算</span></span><br><span class="line"><span class="comment"># 但却不会生成4*16*16个b</span></span><br><span class="line"><span class="comment"># 判断方法:右对其,用1把维度补相同,然后把1是维度变成和另一个匹配的</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># a.shape=[1,3,4]</span></span><br><span class="line"><span class="comment"># tf.tile(a,[2,1,3]) 第一个维度复制2ci，第二个1次，第三个4次</span></span><br><span class="line"><span class="comment"># a.shape = [2,3,12]</span></span><br></pre></td></tr></table></figure>

<h5 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># element-wise: +-*/</span></span><br><span class="line"><span class="comment"># shape一样，对应元素运算</span></span><br><span class="line"><span class="comment"># (一般的运算,非矩阵...吧)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># matrix-wise: @,matmul</span></span><br><span class="line"><span class="comment"># 如 [b,3,4]@[b,4,5]</span></span><br><span class="line"><span class="comment"># 相当于把后两个当成矩阵然后来运算[3,4]*[4,5] = [3,5]</span></span><br><span class="line"><span class="comment"># 相当于一下子b个矩阵相乘</span></span><br><span class="line"><span class="comment"># (矩阵运算...)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># dim-wise: reduce_mean/max/min/sum</span></span><br></pre></td></tr></table></figure>

<h5 id="手写数字识别-你可能用到"><a href="#手写数字识别-你可能用到" class="headerlink" title="手写数字识别,你可能用到"></a>手写数字识别,你可能用到</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">(xs, ys),_ = datasets.mnist.load_data()</span><br><span class="line">xs = tf.convert_to_tensor(xs, dtype=tf.float32) / <span class="number">255.</span>    <span class="comment"># 除以255是为了优化,这样0&lt;x&lt;1</span></span><br><span class="line">ys = ....  <span class="comment"># 变成tensor</span></span><br><span class="line"></span><br><span class="line">train_db = tf.data.Dataset.from_tenfor_slices((x,y)).batch(<span class="number">128</span>)</span><br><span class="line">train_iter = iter(train_db)</span><br><span class="line">sample = next(train_iter)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>,<span class="number">256</span>]),stddev=<span class="number">0.1</span>)  <span class="comment"># stddev=0.1是为了......</span></span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))   <span class="comment"># 变成tf.Variable才能被Gradient跟踪</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):   <span class="comment"># 对整个数据集循环,反复使用用一个数据集不断优化</span></span><br><span class="line">	<span class="keyword">for</span> step,(x, y) <span class="keyword">in</span> enumerate(train_db):  <span class="comment"># step,方便记录,查enumerate用法</span></span><br><span class="line">		x = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># 默认只会跟踪tf.Variable的类型</span></span><br><span class="line">			h1 = x@w1 + b1</span><br><span class="line">			h1 = tf.nn.relu(h1)</span><br><span class="line">			...</span><br><span class="line">			out = ...</span><br><span class="line">			</span><br><span class="line">			y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)  <span class="comment"># y:[b] =&gt; [b,10]</span></span><br><span class="line">		</span><br><span class="line">			loss = tf.square(y_onehot - out)</span><br><span class="line">			loss = tf.reduce_mean(loss)</span><br><span class="line">			</span><br><span class="line">		grads = tape.gradient(loss,[w1,b1,w2,b2,w3,b3])</span><br><span class="line">		<span class="comment"># 更新w,b</span></span><br><span class="line">		w1.assign_sub(lr*grads[<span class="number">0</span>])  <span class="comment"># 原地更新,引用不变,类型不变</span></span><br><span class="line">		...</span><br><span class="line">		...</span><br><span class="line">		<span class="keyword">if</span> step % <span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">			print(float(loss))</span><br></pre></td></tr></table></figure>

<h5 id="合并与拼接"><a href="#合并与拼接" class="headerlink" title="合并与拼接"></a>合并与拼接</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">c =tf.concat([a,b],axis=<span class="number">0</span>)   <span class="comment"># a和b第0维度合并</span></span><br><span class="line"><span class="comment"># 在原有维度上累加,不能生成新的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果要创造新的维度</span></span><br><span class="line"><span class="comment"># a.shape = [4,3,5] b.shape = [4,3,5]</span></span><br><span class="line">c = tf.stack([a,b]axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># c.shape = [4,2,3,5]  </span></span><br><span class="line"><span class="comment"># 根据表示意义理解 如[chool,class,student,scores]</span></span><br><span class="line"><span class="comment">### 以上对维度都有要求,有一定的局限性</span></span><br><span class="line"><span class="comment"># 同样用[class,student,scores] 模型举例</span></span><br><span class="line"><span class="comment"># 每个学校，班等都可能不同,stack就操作不了</span></span><br><span class="line"></span><br><span class="line">tf.unstack(a,axis=<span class="number">0</span>)   <span class="comment"># 全部拆开,返回几个tensor取决于有几个</span></span><br><span class="line">tf.unstack(a,axis=<span class="number">3</span>,num_or_size_splits=<span class="number">2</span>)   <span class="comment"># 在指定维度拆开拆开,参数是2所以拆成两个</span></span><br><span class="line">tf.unstack(a,axis=<span class="number">3</span>,num_or_size_splits=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>])   <span class="comment"># 指定拆开,拆开的低0个有2份,地2个有3份...</span></span><br></pre></td></tr></table></figure>

<h5 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h5><ul>
<li>范数<ul>
<li>二范数<br>$${||x||}_2 = [\sum_k{x^2_k}]^\frac{1}{2}$$  </li>
<li>无穷范数  </li>
<li>一范数..等等<br>$${||x||}_1 = \sum_k{|x_k|}$$  </li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###  这里讨论的都是向量的范数(非矩阵)</span></span><br><span class="line">tf.norm(a)  <span class="comment"># 二范数</span></span><br><span class="line">tf.norm(a,ord=<span class="number">1</span>,axis=<span class="number">1</span>)  <span class="comment"># 一范数,同时把某维度看做整体来做范数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># reduce_mean/min/max</span></span><br><span class="line"><span class="comment"># reduce说明,这操作会有个减维的过程:相当于每组选出了指定的数,那组的大小就成了1</span></span><br><span class="line">tf.reduce_mean(a,axis=<span class="number">1</span>)  <span class="comment"># 2.不指定维度的话会打平成以维度</span></span><br><span class="line"><span class="comment"># 指定了维度就会在指定维度取  $注意,这里讨论的都是向量,不用矩阵来理解</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 就最大最小值的位置</span></span><br><span class="line"><span class="comment"># a.shape = [4,10]</span></span><br><span class="line">tf.argmax(a)  <span class="comment"># 默认第0维比较,a有10组,所以会返回10个结果[2,3,4..]</span></span><br><span class="line">tf.argmin(a,axis=<span class="number">1</span>)  <span class="comment"># 指定维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 比较</span></span><br><span class="line">tf.equal(a,b) <span class="comment"># 返回[True,False,True,...]</span></span><br><span class="line"><span class="comment"># 准确度:把上面的返回结果dtype成0,1然后累加</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tf.unique</span></span><br><span class="line">tf,unique(a)</span><br><span class="line"><span class="comment"># 返回两个值,第一个是无重复值的tensor,第二个是tensor是值表示原tensor的元素在新tensor中的位置</span></span><br><span class="line"><span class="comment"># 这么一来可以用tf.gather来吧原tensor还原出来</span></span><br></pre></td></tr></table></figure>

<h5 id="张量排序"><a href="#张量排序" class="headerlink" title="张量排序"></a>张量排序</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">tf.sort(a,direction=<span class="string">'DESCENDING'</span>)  <span class="comment"># 降序,  direction='ASCENDING'就能升序</span></span><br><span class="line">tf.argsort(a,direction=<span class="string">'DESCENDING'</span>)  <span class="comment"># 降序,返回的是位置:如[最大值位置，次大..]</span></span><br><span class="line"><span class="comment"># 同理可与gather配合</span></span><br><span class="line"><span class="comment"># 高维的话就按每维排列完全排序</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但有时候我们只需要最大最小(不用完全排序,耗时)</span></span><br><span class="line">res = tf.max.top_k(a,<span class="number">2</span>)  <span class="comment"># 返回最大的两个</span></span><br><span class="line">res.indices   <span class="comment"># 返回索引值,像argsort</span></span><br><span class="line">res.values  <span class="comment"># 返回值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用</span></span><br><span class="line"><span class="comment"># 预测问题:0,1,2,3的预测分别是 prob[0.1,0.2,0.3,0.4]</span></span><br><span class="line"><span class="comment"># 真实值是2</span></span><br><span class="line"><span class="comment"># top-1 prediction(正确答案在前1个的概率):0%   (预测对的样本个数/总样本数(这了只用应该样本)) </span></span><br><span class="line"><span class="comment"># top-2 prediction(正确答案在前2个的概率):100% </span></span><br><span class="line"><span class="comment"># top-3 prediction(正确答案在前3个的概率):100% </span></span><br><span class="line"><span class="comment"># 举例</span></span><br><span class="line"><span class="comment"># prob = tf.constant([[0.1,0.2,0.7],[0.2,0.7,0.1]]) #样本1最可能是2,样本2最可能是1</span></span><br><span class="line"><span class="comment"># target = tf.constant([2,0])  # 样本1正式值应该是2，样本2真实值应该是0</span></span><br><span class="line"><span class="comment"># 所以: top-1 prediction=1/2  = 50%</span></span><br><span class="line"><span class="comment"># top-2 prediction = 2/2 = 100%</span></span><br><span class="line"><span class="comment"># top-3 prediction = 2/2 = 100%</span></span><br></pre></td></tr></table></figure>

<h5 id="填充与复制"><a href="#填充与复制" class="headerlink" title="填充与复制"></a>填充与复制</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 填充 pad</span></span><br><span class="line">tf.pad(a,[[<span class="number">2</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]])  <span class="comment"># 行上边边填充2行下边0行;列左0右1</span></span><br><span class="line"><span class="comment">#          ^行  ^列  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制 tile</span></span><br><span class="line"><span class="comment"># a.shape = [3,3]</span></span><br><span class="line">tf.tile(a,[<span class="number">1</span>,<span class="number">2</span>])  <span class="comment"># 第一维复制一次(不变),第二维复制2次 </span></span><br><span class="line"><span class="comment"># res.shape = [3,6]</span></span><br><span class="line"><span class="comment"># 会真实的复制到内存</span></span><br></pre></td></tr></table></figure>

<h5 id="张量的限幅"><a href="#张量的限幅" class="headerlink" title="张量的限幅"></a>张量的限幅</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 限制最小值</span></span><br><span class="line">tf.maximum(a,<span class="number">2</span>)  <span class="comment"># 返回a,2间的最大值,故a不会小于2,限制的最小值</span></span><br><span class="line"><span class="comment"># 限制最大值</span></span><br><span class="line">tf.minimum(a,<span class="number">8</span>)  <span class="comment"># 返回a,8间的最小值 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 限制范围</span></span><br><span class="line">tf.clip_by_value(a,<span class="number">2</span>,<span class="number">8</span>)  <span class="comment"># 2&lt;x&lt;8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># relu函数,x小于0时取0，大于0是取本身</span></span><br><span class="line"><span class="comment"># 可用maximum(a,0)实现</span></span><br><span class="line"><span class="comment"># 也可用封装好的relu函数</span></span><br><span class="line">tf.relu(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等比例放缩,希望把grad缩小方便学习,但又不希望改变gred值</span></span><br><span class="line"><span class="comment"># 可用除以模再乘以一个值来控制范围来,也可用函数</span></span><br><span class="line">tf.clipe_by_norm(a,<span class="number">15</span>)  <span class="comment"># 相当于除模后乘15,改变了a的模</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Gradient Exploding 梯度太大,一步学习跨越太大,来回震荡</span></span><br><span class="line"><span class="comment"># Gradient Vanishing 梯度太小,学习太慢，长时间没有变化</span></span><br><span class="line"><span class="comment"># tf.clipe_by_global_norm(grads,25)  # 整体缩放,避免方向改变</span></span><br><span class="line"><span class="comment"># 梯度向量表示[2,5,3],那么整体缩小就不会改变方向</span></span><br></pre></td></tr></table></figure>

<h5 id="高级操作"><a href="#高级操作" class="headerlink" title="高级操作"></a>高级操作</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 筛选 mask = [True,False,True]</span></span><br><span class="line">tf.where(mask)  <span class="comment"># 没有参数,返回tensor中值是True的值的对应坐标tensor</span></span><br><span class="line">tf.where(mask,A,B)  <span class="comment"># True时对A采样,False时对B采样</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有目的性的更新</span></span><br><span class="line">tf.scatter_nd(indices,updates,shape) </span><br><span class="line"><span class="comment"># 1.只能在全0的底板上更新,就是上面的shape</span></span><br><span class="line"><span class="comment"># 2.indices表示要更新的位置,把对应位置上updates的值更新过去</span></span><br><span class="line"><span class="comment"># 一般用作给指定位置加减(因为只能全0为底板)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 快速生成坐标轴系(GPU加速的,区别于传统for循环的)</span></span><br><span class="line">point_x,point_y = tf.meshgrid(x,y)</span><br><span class="line"><span class="comment"># 返回两个值,个存取x的所有值和y的所有值</span></span><br><span class="line"><span class="comment"># 对应位置的祝贺就是(x,y) </span></span><br><span class="line"><span class="comment"># 重新组合: tf.stack([point_x,point_y],axis=2)</span></span><br></pre></td></tr></table></figure>

<h4 id="神经网络与全连接层"><a href="#神经网络与全连接层" class="headerlink" title="神经网络与全连接层"></a>神经网络与全连接层</h4><h5 id="数据集的加载-小型"><a href="#数据集的加载-小型" class="headerlink" title="数据集的加载(小型)"></a>数据集的加载(小型)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集准备</span></span><br><span class="line">(x,y),(x_test,y_test) = keras.datasets.mnist.load_data()  <span class="comment"># 获取mninst数据集,返回各有不同</span></span><br><span class="line"><span class="comment"># 返回的是numpy的格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将numpy转换成对象</span></span><br><span class="line">db = tf.data.Dataset.from_tenfor_slices(x_test,y_test)</span><br><span class="line">next(iter(db))[<span class="number">0</span>].shape  <span class="comment"># 转换成对象后就可进行的一系列操作,支持多线程等</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打散</span></span><br><span class="line">db = db.shuffle(<span class="number">10000</span>)  <span class="comment"># 打散,但x和y的对应关系不打撒(gather),参数?给大点就是了</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">db2 = db.map(func)  <span class="comment"># 对db里的每个元素进行func里的操作</span></span><br><span class="line"><span class="comment"># 如每个元素是(x,y),func函数的参数的x,y返回的是处理后的x,y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch</span></span><br><span class="line">db3 = db2.batch(<span class="number">42</span>)  <span class="comment"># 不再一次读取一组数据,一次读取指定数量的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重复迭代</span></span><br><span class="line">db4 = db3.repeat(<span class="number">2</span>)  <span class="comment"># 重复迭代2次</span></span><br><span class="line">db4 = db3.repeat()  <span class="comment"># 无限重复</span></span><br></pre></td></tr></table></figure>

<h5 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个节点跟每个节点连接——Dense</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">728</span>])  <span class="comment"># 输入</span></span><br><span class="line">net = tf.keras.layers.Dense(<span class="number">512</span>)  <span class="comment"># 创建输出512的层</span></span><br><span class="line">out = net(x)  <span class="comment"># out.shape = [4,512]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多层嵌套——Multi-Layers</span></span><br><span class="line"><span class="comment"># keras.Sequential([layer1,layer2,...])  # layer-&gt;Dense</span></span><br><span class="line">network = keras.Sequential([</span><br><span class="line">        keras.layers.Dense(<span class="number">2</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">        keras.layers.Dense(<span class="number">2</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">        keras.layers.Dense(<span class="number">2</span>)</span><br><span class="line">    ])</span><br><span class="line">network.build(input_shape=[<span class="literal">None</span>,<span class="number">3</span>])  <span class="comment"># 创建，给定输入维度3</span></span><br><span class="line">network.summary()   <span class="comment"># 打印信息</span></span><br><span class="line">network.trainable_variables   <span class="comment"># list[],可训练参数</span></span><br></pre></td></tr></table></figure>

<h5 id="输出方式"><a href="#输出方式" class="headerlink" title="输出方式"></a>输出方式</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出范围压缩</span></span><br><span class="line"><span class="comment"># sigmod函数(同理relu)</span></span><br><span class="line">y = tf.sigmod(x)   <span class="comment"># x属于R,y属于[0,1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tanh函数,压缩范围到[-1,1]</span></span><br><span class="line">tf.tanh(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出概率(所有的和为1)</span></span><br><span class="line"><span class="comment"># softmax函数</span></span><br><span class="line">tf.softmax(a)</span><br></pre></td></tr></table></figure>

<h5 id="损失函数的计算"><a href="#损失函数的计算" class="headerlink" title="损失函数的计算"></a>损失函数的计算</h5><ul>
<li>MSE<br>$$loss=\frac{1}{N}\sum(y-out)^2$$<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss1 = tf.reduce_mean(tf.square(y-out))</span><br><span class="line">loss2 = tf.reduce_mean(tf.losses.MSE(y,out))</span><br><span class="line"><span class="comment"># loss1 = loss2 等价</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="标差熵"><a href="#标差熵" class="headerlink" title="标差熵"></a>标差熵</h5><ul>
<li>熵 $Entropy = -\sum P(i)\log_2{P(i)}$<ul>
<li>不确定度 Uncertainty</li>
<li>惊奇度 measure of surprise</li>
<li>lower entropy -&gt; more info</li>
</ul>
</li>
</ul>
<h5 id="交叉熵-Cross-Entropy"><a href="#交叉熵-Cross-Entropy" class="headerlink" title="交叉熵 Cross Entropy"></a>交叉熵 Cross Entropy</h5><ul>
<li><p>描述两个集合p,q的惊奇度</p>
<ul>
<li>$H(p,q) = -\sum{p(x) \log_2{q(x)}}$</li>
<li>$H(p,g) = H(p) + D(p|q)$ <ul>
<li>$D(p|q)$ 表示p和q的离散度</li>
<li>当p=q时$D(p|q)=0$</li>
</ul>
</li>
</ul>
</li>
<li><p>for p:one_hot encoding</p>
<ul>
<li>$h(p:[0,1,0]) = -1\log_2{1}=0$</li>
<li>$H([0,1,0],[q_1,q_2,q_3]) = 0+D(p|q)=-1\log{q_1}$</li>
<li>即要使p逼近与q用交叉熵的方法的可行的  </li>
</ul>
</li>
<li><p>具体解法<br>设一组分类的one_hot encoding是$P_1[1,0,0,0,0]$;<br>一组输出为$Q_1[0.4,0.3,0.05,0.05,0.5]$;<br>则:</p>
</li>
</ul>
<p>$$\begin{aligned}<br>loss &amp;= H(p,q) \<br>&amp;= -\sum{P_1(x) \log_2{Q_1(x)}} \<br>&amp;= -\log_2{0.4}  \<br>&amp;= 0.916<br>\end{aligned}<br>$$</p>
<p>然后lr,w1,b2…,多次学习后发现loss越来越小,即q = p  </p>
<ul>
<li>在tensorflow中的使用</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.losses.categorical_crossentropy(p,q) <span class="comment"># 函数的形式</span></span><br><span class="line">tf.losses.BinaryCrossentropy()(p,q)  <span class="comment"># 类的形式</span></span><br><span class="line">tf.losses.binary_crossentropy(p,q) <span class="comment"># 函数的形式 </span></span><br><span class="line"><span class="comment"># p是真实在的one_hot encodingq是预测值</span></span><br><span class="line"><span class="comment"># 如tf.losses.categorical_crossentropy([1,0,0,0],[0.25,0.25,0.25,0.25])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 通常的用法 ###</span></span><br><span class="line">tf.losses.categorical_crossentropy(one_hot,logits,from_logits=<span class="literal">True</span>)  <span class="comment"># 这样能处理logits转换成prob时的错误</span></span><br><span class="line">tf.losses.categorical_crossentropy(one_hot,prob)  <span class="comment"># 等价但不推荐</span></span><br></pre></td></tr></table></figure>


<h3 id="梯度下降-Gradient-Descent"><a href="#梯度下降-Gradient-Descent" class="headerlink" title="梯度下降 Gradient Descent"></a>梯度下降 Gradient Descent</h3><ul>
<li>梯度:向量grad<ul>
<li>用梯度下降来逼近<br>$$ w_n = w - lr \times \frac{\partial{loss}}{\partial{w}} $$</li>
</ul>
</li>
<li>在tensorflow中的使用</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:  <span class="comment"># 把计算过程包在里面</span></span><br><span class="line">    tape.watch([w,b])  <span class="comment"># 如果参数不是tf.variable类型话要用这个函数声明</span></span><br><span class="line">    loss = f(x)</span><br><span class="line">[w_grad] = tape.gradient(loss,[w])  <span class="comment"># 自动求解参数的梯度,并返回相应的列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tape.gradient调用一次后会把资源释放掉,可用参数persistent改变</span></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape(persistent=<span class="literal">True</span>) <span class="keyword">as</span> tape:  <span class="comment"># 用完后会保留资源</span></span><br><span class="line">grad1 = tape.gradient(loss,[w]) </span><br><span class="line">grad2 = tape.gradient(loss,[w])  <span class="comment"># 可调用多次</span></span><br><span class="line"><span class="comment"># 但要记得手动释放资源！！！</span></span><br></pre></td></tr></table></figure>


<h4 id="激活函数-Activation-Function"><a href="#激活函数-Activation-Function" class="headerlink" title="激活函数 Activation Function"></a>激活函数 Activation Function</h4><p>科学家在研究青蛙神经是发现，当刺激到达一定程度是青蛙才会做出相应的反应，是个离散的过程<br>因此在深度学习中就可模仿设点，设计神经网络，因此有了激活函数  </p>
<p>连续的光滑的激活函数</p>
<ul>
<li><strong>sigmoid(logistic)</strong><ul>
<li>$f(x)=\delta(x)=\frac{1}{1+e^{-x}}$</li>
<li><code>y = tf.sigmoid(a)</code></li>
<li>可以将范围压缩到[0,1]</li>
<li>但当x接近无穷时，导数几乎为零，导致梯度离散，使得长期得不到更新</li>
</ul>
</li>
<li><strong>Tanh</strong><ul>
<li>$f(x)=tanh(x)=\frac{(e^x-e^{-x})}{e^x+e^{-x}}=2sigmoid(2x)-1$</li>
<li><code>y = tf.tanh(a)</code></li>
</ul>
</li>
<li><strong>ReLU(Rectified Linear Unit)</strong><ul>
<li>$<br>f(x) = \begin{cases}<br>0, &amp; \text{if } x &lt; 0  \<br>x, &amp; \text{if } x \geq 0<br>\end{cases}<br>$</li>
<li><code>tf.nn.relu()</code></li>
<li>深度学习最常用的<ul>
<li>优势</li>
<li>求导简单</li>
<li>不会放大或缩小梯度(reLU的导数为1)</li>
</ul>
</li>
</ul>
</li>
<li><strong>Softmax</strong><ul>
<li>$S(y_i)=\frac{e^{y_i}}{\sum_j{e^{y_i}}}$</li>
<li>常用于多分类问题，因为它把logits转换为prob</li>
<li>区别于一般的转换成prob的方法，Softmax会把大的放大，小的缩小；拉大差距(sotf version of max)</li>
<li>求导:把先把分子分母看做整体<code>f(x)和g(x)</code>然后相当于$\frac{\partial p_i}{\partial a_j}=\frac{f’(x)g(x)-f(x)g’(x)}{g(x)^2}$;注意i和j不同的情况要分开讨论<ul>
<li>结果$<br>\frac{\partial p_i}{\partial a_j} = \begin{cases}<br>p_i(1-p_1), &amp; \text{if } i=j  \</li>
<li>p_jp_i, &amp; \text{if } i\neq j<br>\end{cases}<br>$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Loss函数的梯度"><a href="#Loss函数的梯度" class="headerlink" title="Loss函数的梯度"></a>Loss函数的梯度</h4><p>经典的loss函数</p>
<ul>
<li>Mean Squared Error(MSE,均方差)<ul>
<li>$loss=\frac{1}{N}\sum(y-out)^2$</li>
<li><code>loss1 = tf.reduce_mean(tf.square(y-out))</code></li>
<li><code>loss2 = tf.reduce_mean(tf.losses.MSE(y,out))</code></li>
</ul>
</li>
<li>Cross Entropy Loss<ul>
<li>Softmax</li>
</ul>
</li>
</ul>
<h4 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h4><p>$\frac{\partial y}{\partial x} = \frac{\partial y}{\partial u}\frac{\partial u}{\partial x}$</p>
<h4 id="感知机梯度传导"><a href="#感知机梯度传导" class="headerlink" title="感知机梯度传导"></a>感知机梯度传导</h4><p>利用链式法则从输出往输入退就可以知道梯度信息，然后更新  </p>
<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ul>
<li>tensorboard<ul>
<li><code>pip install tensorboard</code></li>
<li>在代码中写入<code>summary_writer = tf.summary.create_file_writer(DIR)</code></li>
<li>拿到<code>summary_writer</code>后就可以忘里面喂数据</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1,喂数据点</span></span><br><span class="line"><span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">    tf.summary.scalar(<span class="string">'NAME1'</span>, float(LOSS), step=STEP)  <span class="comment"># (图的名字,数据,坐标(默认是x轴))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2,喂一个图片</span></span><br><span class="line"><span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">    tf.summary.image(<span class="string">'NAME1'</span>, IMG, step=STEP)  <span class="comment"># (图的名字,数据,坐标(默认是x轴))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3,给多个图片</span></span><br><span class="line"><span class="comment"># 最好的办法是认为的拼接图片,然后传一张拼接的图片(google)</span></span><br></pre></td></tr></table></figure>

<ul>
<li>visdom </li>
</ul>
<h2 id="Keras高层API"><a href="#Keras高层API" class="headerlink" title="Keras高层API"></a>Keras高层API</h2><h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><p>在计算loss,accuracy的时候经常会发现数据忽高忽低,所以可借助keras的api来优化</p>
<ul>
<li>metrics测量<ul>
<li>keras会将数据放在一个list,然后取平均值来优化?</li>
<li>如<code>loss_meter = metrics.Mean()</code>,<code>acc_meter = metrics.Accuracy()</code></li>
</ul>
</li>
<li>update_state更新数据<ul>
<li><code>loss_meter.update_state(loss)</code>,<code>acc_meter.update_state(y, pred)</code></li>
</ul>
</li>
<li>result().numpy()获取结果,转换成numpy输出<ul>
<li><code>loss_meter.result().numpy()</code>result得到tensor，再转换成numpy</li>
</ul>
</li>
<li>reset_states释放数据<ul>
<li>当要废弃旧的数据时<code>loss_meter.reset_states()</code></li>
</ul>
</li>
</ul>
<h4 id="Compile-amp-Fit"><a href="#Compile-amp-Fit" class="headerlink" title="Compile&amp;Fit"></a>Compile&amp;Fit</h4><ul>
<li>Compile,类似装载弹药,可以指定loss,优化器,评估指标</li>
<li>Fix,完成标准创立</li>
<li>Evaluate,测试</li>
<li>Predic,拿创建好的模型来预测</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 一般的流程</span></span><br><span class="line">epoch <span class="keyword">in</span> range(num):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(db):</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:   <span class="comment"># 循环网络</span></span><br><span class="line">            <span class="comment"># [b, 784] =&gt; [b, 10]</span></span><br><span class="line">            logits = model(x)</span><br><span class="line">            y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">            loss_ce = tf.losses.categorical_crossentropy(y_onehot, logits, from_logits=<span class="literal">True</span>)</span><br><span class="line">            loss_ce = tf.reduce_mean(loss_ce)</span><br><span class="line"></span><br><span class="line">        grads = tape.gradient(loss_ce, model.trainable_variables)    <span class="comment"># 更新</span></span><br><span class="line">        optimizer.apply_gradients(zip(grads, model.trainable_variables))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:   </span><br><span class="line">            <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">for</span> (x_test, y_test) <span class="keyword">in</span> test_db:    <span class="comment"># 测试</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 使用Keras的api快速建立标准化的神经网络</span></span><br><span class="line"><span class="comment"># 称network或model</span></span><br><span class="line">network = Sequential([...])   <span class="comment"># 如果是别的没学到的话...</span></span><br><span class="line">network.compile(</span><br><span class="line">        optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),    <span class="comment"># 指定优化器</span></span><br><span class="line">        loss=tf.loss.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),   <span class="comment"># 指定loss函数</span></span><br><span class="line">        metrics=[<span class="string">'accuracy'</span>]     <span class="comment"># 指定测试标准</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.fit(</span><br><span class="line">        db,   <span class="comment"># 要训练的数据集</span></span><br><span class="line">        epochs=<span class="number">10</span>,    <span class="comment"># 训练的周期</span></span><br><span class="line">        validation_data=db_test,    <span class="comment"># 用于做测试的数据集,一般写作ds_val</span></span><br><span class="line">        validation_freq=<span class="number">2</span>    <span class="comment"># 测试的周期,如这里一共10个epochs,每2个epochs就进行一次测试</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.evaluate(ds_val)    <span class="comment"># 训练完后对模型的评估,传入一个数据集</span></span><br><span class="line"></span><br><span class="line">pred = network(x)</span><br><span class="line"><span class="comment"># 或 pred = network.predict(x)    预测</span></span><br></pre></td></tr></table></figure>


<h4 id="自定义网络"><a href="#自定义网络" class="headerlink" title="自定义网络"></a>自定义网络</h4><ul>
<li>keras.Sequential(layer1, layer2, …)<ul>
<li>参数要继承自<code>keras.layers.Layer()</code></li>
<li>建立好网络后variable(w和b)是没有的<ul>
<li>法1:指定输入shape<code>network.build(input_shape=(None, 28*28))</code></li>
<li>法2:自动识别<code>network(x)</code><ul>
<li>这个的原理是调用了类中的call()方法,相当于network.<strong>call</strong>(x)。同理自定义类中也可如此</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>keras.layers.Layer()<ul>
<li>任何要自定义的层要继承自它</li>
</ul>
</li>
<li>keras.Model()<ul>
<li>compile/fit/evaluate</li>
<li>Sequential也是继承自该类，所以自定义的网络应该继承这个</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span><span class="params">(layers.Layer)</span>:</span>    <span class="comment"># 自定义层继承</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inp_dim, outp_dim)</span>:</span></span><br><span class="line">        super(MyDense, self).__init__() </span><br><span class="line">        self.kernel = self.add_weight(<span class="string">'name1'</span>, [inp_dim, outp_dim])   <span class="comment"># 用母类的add_weight而不是用tf.variable</span></span><br><span class="line">        self.bias = self.add_weight(<span class="string">'name2'</span>, [outp_dim])    <span class="comment"># name是给母类管理用的</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs, training=None)</span>:</span></span><br><span class="line">        out = inputs @ self.kernel + self.bias</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比</span></span><br><span class="line">layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同理Model自定义方法也一样</span></span><br></pre></td></tr></table></figure>

<h4 id="模型的加载与保持"><a href="#模型的加载与保持" class="headerlink" title="模型的加载与保持"></a>模型的加载与保持</h4><ul>
<li>save/load weights<ul>
<li>只保存模型参数</li>
<li>缺点是没有源代码，网络不得而知</li>
</ul>
</li>
<li>save/load entire model<ul>
<li>简单粗暴的</li>
</ul>
</li>
<li>saved_model <ul>
<li>通用的保存格式</li>
</ul>
</li>
</ul>
<p><strong>save/load weights</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save</span></span><br><span class="line">model.save_weights(<span class="string">'PATH'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">model = create_model()    <span class="comment"># 需要人工创建网络</span></span><br><span class="line">model.load_weights(<span class="string">'PATH'</span>)</span><br></pre></td></tr></table></figure>

<p><strong>save/load entire model</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save</span></span><br><span class="line">model.save(<span class="string">'PATH'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">model = tf.keras.models.load_model(<span class="string">'PATH'</span>)  <span class="comment"># 不需要人工创建网络</span></span><br></pre></td></tr></table></figure>

<p><strong>saved model</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save</span></span><br><span class="line">tf.saved_model.saved(model, <span class="string">'PATH'</span>)   <span class="comment"># 标准的，可供其他模型使用的保存</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load</span></span><br><span class="line">imported = tf.saved_model.load(path)   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 还原除网络</span></span><br><span class="line">f = imported.signature[<span class="string">'serving_defaut'</span>]</span><br></pre></td></tr></table></figure>



<h3 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h3><p>现实情况是我们并不知道模型的符合什么分布  </p>
<ul>
<li>model capacity,模型的学习能力<ul>
<li>显然项越多越高</li>
</ul>
</li>
<li>underfitting<ul>
<li>模型的表达能力弱于真实数据，如用直线拟合双曲线</li>
</ul>
</li>
<li>overfitting<ul>
<li>模型的表达能力大于真实数据，把不必要的噪声也拟合进来了</li>
<li>最常见</li>
</ul>
</li>
</ul>
<h4 id="检查overfitting"><a href="#检查overfitting" class="headerlink" title="检查overfitting"></a>检查overfitting</h4><h5 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h5><p>检查欠拟合和过拟合的方法   </p>
<p>一般情况下会把数据集切分(splitting)成三份,作用分别是train set，val set，test set<br>数据集一部分用来训练，一部分用来验证accuracy这是是显然的，那为什么有第三份呢？<br>因为在真实的需求中，是不是有取巧的人会把test用的数据集也用来训练，从而过拟合来达到很高的准确度(但实际它们已经过拟合了)<br>所以第三份是用来防止这种情况发生的，不参与训练的，最终检验模型的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">network.compile(</span><br><span class="line">        optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),   </span><br><span class="line">        loss=tf.loss.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),   </span><br><span class="line">        metrics=[<span class="string">'accuracy'</span>]   </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.fit(</span><br><span class="line">        db,    <span class="comment"># training</span></span><br><span class="line">        epochs=<span class="number">10</span>,</span><br><span class="line">        validation_data=db_test,   <span class="comment"># val set</span></span><br><span class="line">        validation_freq=<span class="number">2</span>   </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">network.evaluate(ds_val)   <span class="comment"># test set</span></span><br></pre></td></tr></table></figure>

<h5 id="K-fold-cross-validation"><a href="#K-fold-cross-validation" class="headerlink" title="K-fold cross-validation"></a>K-fold cross-validation</h5><p>由上面知，test set是完全不能动的，所以在切分的时候train set和val set可以随机的切分，可以防止网络记忆特性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在tensorflow中可以表现为</span></span><br><span class="line">shuffle(db)  <span class="comment"># 打散</span></span><br><span class="line">splices()   <span class="comment"># 切割</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可用keras的功能</span></span><br><span class="line">network.fit(db, validation_split=<span class="number">0.1</span>)   <span class="comment"># 按照9:1随机切分</span></span><br></pre></td></tr></table></figure>

<h4 id="减轻overfitting"><a href="#减轻overfitting" class="headerlink" title="减轻overfitting"></a>减轻overfitting</h4><h5 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h5><ul>
<li>L1-regularization<ul>
<li>loss加上lambda约束的一范式</li>
<li>$j(\theta) = -\sum^m_1{y_i\log_e{\bar y_i} + (1-y_i)\log_e{(1-\bar y_i)}} + \lambda \sum_i^n{|\theta_i|}$</li>
</ul>
</li>
<li>L2-regularization<ul>
<li>loss加上lambda约束的一范式</li>
<li>$J(W;x,y)+\frac{1}{2} \times ||W||^2$</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 法一：在一层网络中添加kernel_regularizer参数</span></span><br><span class="line">keras.layers.Dense(<span class="number">16</span>,</span><br><span class="line">                    kernel_regularizer=keras.regularizers.L2(<span class="number">0.001</span>)   <span class="comment"># 0.001就是 lambda</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 法二：更加灵活的自己控制范式</span></span><br><span class="line">loss_regularization = []   </span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> network.trainable_variables:     <span class="comment"># 取范式里面的参数w1,w2...b1,b2...取法很灵活</span></span><br><span class="line">    loss_regularization.append(tf.nn.l2_loss(p))</span><br><span class="line">loss_regularization = tf.reduce_sum(tf.stack(loss_regularization))  <span class="comment"># 做一范式还是二范数...</span></span><br><span class="line"></span><br><span class="line">loss = loss + <span class="number">0.0001</span>*loss_regularization</span><br></pre></td></tr></table></figure>

<h4 id="动量与学习率"><a href="#动量与学习率" class="headerlink" title="动量与学习率"></a>动量与学习率</h4><h5 id="Momentum-动量"><a href="#Momentum-动量" class="headerlink" title="Momentum 动量"></a>Momentum 动量</h5><p>由于梯度的更新，会有大幅的反复跳跃的现象，动量就是在更新方向的基础上结合上一阶段的方向进行梯度更新，从而使得更平缓，像踩刹车一样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = SGD(learing_rate=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>)   <span class="comment"># momentum 就在超参数lambda</span></span><br><span class="line">optimizer = RMSprop(learing_rate=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">optimizer = Adam(learing_rate=<span class="number">0.02</span>,   <span class="comment"># Adam没有momentum(内置),但有beta_1,beta_2</span></span><br><span class="line">        beta_1=<span class="number">0.9</span>,</span><br><span class="line">        beta_2=<span class="number">0.999</span>)</span><br></pre></td></tr></table></figure>

<h5 id="Learning-rate-学习率"><a href="#Learning-rate-学习率" class="headerlink" title="Learning rate 学习率"></a>Learning rate 学习率</h5><p>学习率动态调整来优化网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">optimizer = SGD(learing_rate=<span class="number">0.02</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    <span class="comment"># get loss</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># change learing_rate 比较简单粗暴</span></span><br><span class="line">    optimizer.learing_rate = <span class="number">0.2</span>*(<span class="number">100</span>-epoch)/<span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># update weights</span></span><br></pre></td></tr></table></figure>

<h4 id="Early-Stopping-amp-Dropout"><a href="#Early-Stopping-amp-Dropout" class="headerlink" title="Early Stopping &amp; Dropout"></a>Early Stopping &amp; Dropout</h4><h5 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h5><p>很多情况下虽然training accuracy还在上升，但是validation accuracy以及达到最优甚至开始下降了，这是就需要以前终止</p>
<h5 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h5><p>和overfitting的情况一样，为减少噪声的干扰，可以减少节点数(?矩阵里面的?),learning less to learning better</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">                      layers.Dropout(<span class="number">0.5</span>),    <span class="comment"># 0.5 rate to dropout</span></span><br><span class="line">                      layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">                      layers.Dropout(<span class="number">0.5</span>),    <span class="comment"># 0.5 rate to dropout</span></span><br><span class="line">                      ...</span><br><span class="line">                    ])</span><br></pre></td></tr></table></figure>
<p>因为training和test的策略不同(training时为得到更好的w,b，而使用dropout的方法来减小overfitting,所以开启dropout，test是测试模型，所以不用开)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># training</span></span><br><span class="line">network(x, training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># validation || test</span></span><br><span class="line">network(x, training=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h5 id="Stochastic"><a href="#Stochastic" class="headerlink" title="Stochastic"></a>Stochastic</h5><h5 id="Deterministic"><a href="#Deterministic" class="headerlink" title="Deterministic"></a>Deterministic</h5><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>在处理图像问题时，使用全连接的方式会导致大量的资源占用.<br>于是由生物学上眼睛可视域的启发，我们采用局部连接，然后滑动直至扫描全部输入。特点在于对于相同的层如(RGB),每次扫描的观察方式(卷积核)是一样的(weight sharing)<br>所以学习的时候就大大减少了参数量  </p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>信号的叠加叫做卷积,得到的结果叫做<strong>feature map</strong>  </p>
<p>$$<br>y(t)=x(t) * h(t)=\int^\infty _ {-\infty}  x(\tau)h(t-\tau)\mathrm{d}x<br>$$</p>
<p>* 表示卷积操作,x就相当于输入,h就相当于观察方式(卷积核),t就相当偏移量，扫过整个图片t发生改变x和h卷积出信号输出y</p>
<h4 id="Padding-amp-Stride"><a href="#Padding-amp-Stride" class="headerlink" title="Padding &amp; Stride"></a>Padding &amp; Stride</h4><ul>
<li>Padding<ul>
<li>把输入层扩大(虚的)然后扫描后就能得到维度与输入相等的输出</li>
</ul>
</li>
<li>Stride<ul>
<li>把扫描的步长加大，就能减少输出的维度</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layers.Conv2D(<span class="number">4</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="string">'samd'</span>)  <span class="comment"># 卷积核个数,5*5,步长,'same'可以保证输入维度等于输出</span></span><br></pre></td></tr></table></figure>

<h4 id="Channels"><a href="#Channels" class="headerlink" title="Channels"></a>Channels</h4><ul>
<li>设输入是[1, 32, 32, 3],32*32的图片,3个通道<ul>
<li>那我们的一个卷积核可以是[3, 5, 5] 3表示输入通道的数量(RGB)</li>
<li>最后可以得到一个[b, 30, 30, 1]的输出</li>
</ul>
</li>
<li>如果使用多个核如[N, 3, 5, 5]那就能得到N个[b, 30, 30, 1]即[b, 30, 30, N]</li>
</ul>
<p>多通道输出，多通道输入</p>
<h4 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h4><p>$$<br>O _ {mn} = \sum {x _ {ij} * w _ {ij}} + b  \<br>\frac{\delta Loss}{\delta w _ {ij}}<br>$$</p>
<h3 id="Classic-Network"><a href="#Classic-Network" class="headerlink" title="Classic Network"></a>Classic Network</h3><h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><p>When the network get deeper, above 20, is get harder to training, even make trains revoke.</p>
<h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>Residual</p>
<h2 id="Sequence"><a href="#Sequence" class="headerlink" title="Sequence"></a>Sequence</h2><p>Signal with time order</p>
<ul>
<li>sequence embed<ul>
<li>turn digital signal into a sequence</li>
</ul>
</li>
</ul>
<p>Many sets can be like a sequence. mnist for example[b, 28, 28]. can expand like [b, time, 28] or [time, b, 28] and so on.</p>
<p>But a sequence better to expand like a time orde things [time, b, 28] is much better. It depend on how you expand.</p>
<p>Here are some rules:</p>
<ul>
<li>semantic similarity</li>
<li>trainable</li>
</ul>
<h3 id="Cycle-network"><a href="#Cycle-network" class="headerlink" title="Cycle network"></a>Cycle network</h3><p>Two question:</p>
<ul>
<li><p>Long sentence</p>
<ul>
<li>weight sharing</li>
<li>We can do like a conv_net</li>
</ul>
</li>
<li><p>Context information</p>
<ul>
<li>It is a pertinence bettween word and word</li>
<li>Here is the example formulation</li>
</ul>
</li>
</ul>
<p>$$\begin{aligned}<br>h_t &amp;= f_w(h_{t-1}, x_t) \<br>h_t &amp;= tanh(W_{hh}h_{t-1} + W{xh}x_t) \<br>y_t &amp;= W_{hy}h_t \<br>\end{aligned}$$</p>
<h3 id="RNNlayer"><a href="#RNNlayer" class="headerlink" title="RNNlayer"></a>RNNlayer</h3><h4 id="SimpleRNN"><a href="#SimpleRNN" class="headerlink" title="SimpleRNN"></a>SimpleRNN</h4><p>$$<br>\begin{aligned}<br>call &amp;= xw_{xh} + h_tw_{hh}, (for\ each\ item\ in\ timeline) \<br>out_1, h_1 &amp;= call(x, h_0) \<br>out_2, h_2 &amp;= call(x, h_1) \<br>out_t, h_t &amp;= call(x, h_{t-1})<br>\end{aligned}<br>$$</p>
<p>$h_t$ and $out_t$ is the same thing(id) but have difference meaning </p>
<h4 id="Optimize"><a href="#Optimize" class="headerlink" title="Optimize"></a>Optimize</h4><ul>
<li>Step 1:Gradient Exploding<ul>
<li>Gradient Clipping</li>
<li>$grad = \frac{|grad|}{grad}$ ,shrink to 1 and mult $15\times{lr}$</li>
<li><code>grads = [tf.clipe_by_norm(g, 15) for g in grads]</code></li>
</ul>
</li>
<li>Step 2:Gradient Vanishing<ul>
<li><em>LSTM</em> \ <em>GRU</em>  </li>
</ul>
</li>
</ul>
<h5 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h5><p>Compare with RNN(short term memory), which can only remenber nearly sentence.<em>LSTM</em> is long short term memory.</p>
<p>LSTM use three gates(sigmoid) to contral the signal. </p>
<ul>
<li>Forget gate<ul>
<li>$f_t = \sigma(W_f\cdot[h_{t-1}, x_t]+b_f)$</li>
<li><img src="./static/forget_gate.png" style="zoom:50%"></li>
</ul>
</li>
<li>Input gate<ul>
<li>$$<br>\begin{aligned}<br>  i_t &amp;= \sigma(W_i\cdot[h{t-1}, x_t] + b_i) \<br>  \widetilde{C_t} &amp;= tanh(W_C\cdot[h_{t-1}, x_t] + b_C)<br>\end{aligned}<br>$$</li>
<li><img src="./static/input_gate.png" style="zoom:50%"></li>
</ul>
</li>
<li>Cell state<ul>
<li>$C_t = f_f * C_{t-1} + i_t * \widetilde{C_t}$</li>
<li><img src="./static/cell_state.png" style="zoom:50%"></li>
</ul>
</li>
<li>Output gate<ul>
<li>$$<br>  \begin{aligned}<br>  O_t &amp;= \sigma(W_o[h_{t-1}, x_t] + b_o) \<br>  h_t &amp;= O_t * tanh(C_t)<br>  \end{aligned}$$</li>
<li><img src="./static/output_gate.png" style="zoom:50%">

</li>
</ul>
</li>
</ul>
<h5 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h5><h2 id="Auto-Encoder"><a href="#Auto-Encoder" class="headerlink" title="Auto-Encoder"></a>Auto-Encoder</h2><p>Why we need:</p>
<ul>
<li>Dimension reduction</li>
<li>Visualization</li>
<li>Take advantages of <em>unsupervised</em> date<ul>
<li>Unsupervise</li>
<li><em>Reconstruct</em> itself</li>
</ul>
</li>
</ul>
<h3 id="Denoising-AutoEncoder"><a href="#Denoising-AutoEncoder" class="headerlink" title="Denoising AutoEncoder"></a>Denoising AutoEncoder</h3><p>Add some noise and can still reconstruct well. Means model can dig out information from a mass data.</p>
<h3 id="Dropout-AutoEncoder"><a href="#Dropout-AutoEncoder" class="headerlink" title="Dropout AutoEncoder"></a>Dropout AutoEncoder</h3><p>Use dropout to autoencoder. It the hard dropouted network can than the disdropout network do better.</p>
<h3 id="Adversarial-AutoEncoder"><a href="#Adversarial-AutoEncoder" class="headerlink" title="Adversarial AutoEncoder"></a>Adversarial AutoEncoder</h3><h3 id="Variational-AutoEncoder"><a href="#Variational-AutoEncoder" class="headerlink" title="Variational AutoEncoder"></a>Variational AutoEncoder</h3><h1 id="Gen"><a href="#Gen" class="headerlink" title="Gen"></a>Gen</h1><ul>
<li>Painter or Generator</li>
<li>Critic or Discriminator</li>
</ul>
<p>$$<br>\begin{aligned}<br>min_G\ max_D\ L(D,G) &amp;= E_{x<del>p_r(x)}[\log{D(x)}] + E_{z</del>p_r(z)}[\log{1-D(G(z))}] \<br>&amp;= E_{x<del>p_r(x)}[\log{D(x)}] + E_{x</del>p_r(x)}[\log{1-D(x)}] \<br>\end{aligned}<br>$$</p>
<p>Both of they want to maximum and than get a nash equilibrium</p>
<h3 id="Nash-Equilibrium"><a href="#Nash-Equilibrium" class="headerlink" title="Nash Equilibrium"></a>Nash Equilibrium</h3><ul>
<li>Q1.Where will D converge, given fixed G</li>
<li>Q2.Where will G converge, after optimal D</li>
</ul>
<h3 id="tensorflow运行机制"><a href="#tensorflow运行机制" class="headerlink" title="tensorflow运行机制"></a>tensorflow运行机制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本质 tf = tensor + 计算图</span></span><br><span class="line"><span class="comment"># tensor 数据</span></span><br><span class="line"><span class="comment"># op 操作</span></span><br><span class="line"><span class="comment"># graphs 数据操作</span></span><br><span class="line"><span class="comment"># session 会话核心</span></span><br></pre></td></tr></table></figure>

<h3 id="四则运算"><a href="#四则运算" class="headerlink" title="四则运算"></a>四则运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果是变量的话要先init</span></span><br><span class="line">tf.add(data1+data2)</span><br><span class="line">tf.multiply(data1,data2)</span><br><span class="line">tf.subtract(data1,data2)</span><br><span class="line">tf.divide(data1,data2)</span><br><span class="line"></span><br><span class="line">dataCopy = tf.assign(x1,x2)  <span class="comment"># 把x2的值赋给x1</span></span><br><span class="line">dataCopy.eval()  <span class="comment"># 相当于sess.run(dataCopy)</span></span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line">tf.get_default_session().run(dataCopy)</span><br></pre></td></tr></table></figure>

<h3 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 数据装载</span><br><span class="line">x1 &#x3D; tf.placeholder(tf.float32)</span><br><span class="line">x2 &#x3D; tf.placeholder(tf.float32)</span><br><span class="line">dataAdd &#x3D; tf.add(x1,x2)</span><br><span class="line">sess.run(dataAdd,feed_dict&#x3D;&#123;x1:2,x2:4&#125;)</span><br><span class="line"># 1.tensor张量dataAdd  2.追加的数据 语法同上</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 矩阵~&#x3D;数组 矩阵整体[] 每列都要[]包起来 每[]就是一行</span><br><span class="line">x1 &#x3D; tf.constant([2,2])</span><br><span class="line">x2 &#x3D; tf.constant([[2],</span><br><span class="line">				  [2]])</span><br><span class="line">x1.shape  #维度</span><br><span class="line">sess.run(x1)   # 打印整体</span><br><span class="line">sess.run(x1.[0])   # 打印第0行</span><br><span class="line">sess.run(x1.[:,0])   # 打印第0列</span><br><span class="line"></span><br><span class="line"># 运算</span><br><span class="line">tf.matmul(x1,x2)  # 矩阵乘法</span><br><span class="line">tf.multiply()  # 普通乘法 对应元素相乘</span><br><span class="line">tf.add()   # ..</span><br><span class="line"></span><br><span class="line"># 特殊矩阵的初始化</span><br><span class="line">tf.zeros([2,3])  # 两行三列空间矩阵</span><br><span class="line">tf.onex([2,3])   # 全一矩阵</span><br><span class="line">tf.fill([2,3],15)  # 填充矩阵,全为15的2*3矩阵</span><br><span class="line"></span><br><span class="line">tf.zeros_like(x1)  # 矩阵维度同x1的全零矩阵</span><br><span class="line">x3 &#x3D; tf.linspace(0.0,2.0,11)  # 生成一个矩阵，元素从0到2均匀分成11分</span><br><span class="line">x4 &#x3D; tf.random_uniform([2,3],-1,2)  # 生成2*3的一个矩阵，元素是-1到2的随机数</span><br></pre></td></tr></table></figure>

<h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>loss function:<br>$$loss = \sum_i(w\times x_i+b-y_i)^2 \tag{1}$$<br>loss 累加会很大，所以一般会除以元素个数n,结果还是一样的</p>
<p>$$w^<code>= w - lr \times \frac{\partial{loss}}{\partial{w}} \tag{2}$$
$$b^</code> = b - lr \times \frac{\partial{loss}}{\partial{b}}$$<br>这样就会得到新的w b,再返回第(1)步，如此循环就能得到最回事的w b</p>
<p>对loss的求导其实有规律可循:<br>$$\frac{\partial{loss}}{\partial{w}} = \frac{2}{n}\sum(wx + b - y)x$$<br>$$\frac{\partial{loss}}{\partial{b}} = \frac{2}{n}\sum(wx + b - y)$$</p>
<h3 id="Discrete-Prediction"><a href="#Discrete-Prediction" class="headerlink" title="Discrete Prediction"></a>Discrete Prediction</h3><p>离散值预测  </p>
<p>Classification (分类)为例<br>显然的离散的问题，那我们要怎么解决离散的问题呢？<br>激活函数 activation<br>常见的有ReLU和sigmoid<br>目的是为了把线性的值离散化，然后才能套用上面的公式  </p>
<p>但是就算用一个函数把线性模型离散化了，但还是太简单<br>所以引入隐藏层概念<br>input -&gt; h1 -&gt; h2 -&gt; out<br>经过多层隐藏层问题就更加离散了<br>$$h1 = relu(x@w_1 + b_1)$$<br>$$h2 = relu(h1@w_2 + b_2)$$<br>$$out = relu(h2@w_3 + b_3)$$<br>@表示矩阵乘法, 每道工序都有自己的参数   </p>
<p>那参数w和b怎么确定呢？<br>若我们想要识别0~9,那我们是不是应该希望最后输出是有10类(一个[1,10]的矩阵,每个元素可以代表一个数字)<br>那么根据矩阵运算的规则(nm*mt = nt),所以我们只要控制每层运算符合矩阵乘法规则且最后输出是我们想要的规模就好<br>最后再用out来计算loss(这里是欧氏距离(n维空间两点的距离)的loss)<br>然后就可以反复更新w` b`了</p>
<hr>
<h1 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h1><p>tensorflow的弟弟版,因为他不能GPU计算</p>
<h3 id="基本操作-2"><a href="#基本操作-2" class="headerlink" title="基本操作"></a>基本操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.array([第一行],[第二行]...)</span><br><span class="line">x1.shape   <span class="comment"># 打印规模</span></span><br><span class="line">np.zeros([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">np.ones([<span class="number">2</span>,<span class="number">3</span>])   <span class="comment"># 零矩阵和单位矩阵的初始化（2行3列）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 改查</span></span><br><span class="line">x1[<span class="number">1</span>,<span class="number">2</span>]=<span class="number">5</span>  <span class="comment"># 第二行第一列改成5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基本运算</span></span><br><span class="line">x1*x2   <span class="comment"># 加减乘除都是对应元素加减乘除</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 矩阵运算</span></span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><p><code>import matplotlib as plt</code></p>
<h3 id="基本操作-3"><a href="#基本操作-3" class="headerlink" title="基本操作"></a>基本操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line">y = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 折线图</span></span><br><span class="line">plt.plot(x,y,<span class="string">"r"</span>)  <span class="comment"># 1.x轴 2.y轴 3.颜色</span></span><br><span class="line">plt.plot(x,y,<span class="string">"g"</span>,lw=<span class="number">10</span>)  <span class="comment"># 1.x轴 2.y轴 3.颜色 4.折线的宽度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 柱状图</span></span><br><span class="line">plt.bar(x,y,<span class="number">0.9</span>,alpha=<span class="number">1</span>,color=<span class="string">'b'</span>)  <span class="comment"># 3.柱状图的宽 4.alpha通道,即透明度</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>













<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/15/universe/Maven_Note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/15/universe/Maven_Note/" class="post-title-link" itemprop="url">Maven 基本操作</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-15 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-15T00:00:00+08:00">2019-09-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-15 21:34:14" itemprop="dateModified" datetime="2020-06-15T21:34:14+08:00">2020-06-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><p>each project should have a pom.xml that is the setting of maven.<br>Add dependency.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>groupId<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>artifactId<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>version<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>This block of XML declares a list of dependencies for the project. Specifically, it declares a single dependency for the Joda Time library. Within the &lt;dependency&gt; element, the dependency coordinates are defined by three sub-elements:</p>
<ul>
<li><strong>&lt;groupId&gt;</strong>-The group or organization that the dependency belongs to.</li>
<li><strong>&lt;artifactId&gt;</strong>- The library that is required.</li>
<li><strong>&lt;version&gt;</strong>-The specific version of the library that is required.</li>
</ul>
<p>Creat a library package (such as JAR file),and install the library in the local Maven dependency repository.<br>When it finished,you should find the file in target/classes  directory.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn compile</span><br></pre></td></tr></table></figure>
<p>Package the code up in a JAR(setting in pom.xml) within the target directory.<br>The name of the JAR file will be baseed on the project’s &lt;artifactId&gt; and &lt;version&gt;.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn package</span><br></pre></td></tr></table></figure>

<p>To execute the JAR file run:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar target&#x2F;gs-maven-0.1.0.jar</span><br></pre></td></tr></table></figure>

<p>Maven also maintains a repository of dependencies on your local machine (usually in a <em>.m2/repository</em> directory in your home directory) for quick access to project dependencies. If you’d like to install your project’s JAR file to that local repository, then you should invoke the <em>install</em> goal:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn install</span><br></pre></td></tr></table></figure>
<p>The install goal will compile, test, and package your project’s code and then copy it into the local dependency repository, ready for another project to reference it as a dependency.</p>
<p>Maven uses a plugin called “surefire” to run unit tests. The default configuration of this plugin compiles and runs all classes in src/test/java with a name matching *Test. You can run the tests on the command line like this.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn test</span><br></pre></td></tr></table></figure>
<p>or just use mvn install step as we already showed above (there is a lifecycle definition where “test” is included as a stage in “install”).</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/14/universe/Spring_Boot_Note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/14/universe/Spring_Boot_Note/" class="post-title-link" itemprop="url">Spring Boot Note</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-14 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-14T00:00:00+08:00">2019-09-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-15 21:34:14" itemprop="dateModified" datetime="2020-06-15T21:34:14+08:00">2020-06-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Project that build with Maven</p>
<h2 id="Quick-buile-a-Spring-Boot-project"><a href="#Quick-buile-a-Spring-Boot-project" class="headerlink" title="Quick buile a Spring Boot project"></a>Quick buile a Spring Boot project</h2><p>Use your IDE and new a project with Spring Initializer</p>
<hr>
<h2 id="Some-basic-operations"><a href="#Some-basic-operations" class="headerlink" title="Some basic operations"></a>Some basic operations</h2><h3 id="Creat-an-excutable-jar"><a href="#Creat-an-excutable-jar" class="headerlink" title="Creat an excutable jar"></a>Creat an excutable jar</h3><p>To create an excutable jar we neen to add the <code>spring-boot-maven-plugin</code> to our pom.xml.  </p>
<p>Insert the following lines just below the <code>dependencis</code> section</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line">```  </span><br><span class="line">  </span><br><span class="line">and than run</span><br></pre></td></tr></table></figure>
<p>mvn package</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">If you look in the &#96;target&#96; directory,you should see a JAR file.</span><br><span class="line"></span><br><span class="line">To run the JAR use the &#96;java -jar&#96;command.</span><br><span class="line"></span><br><span class="line">### Run with Maven Plugin</span><br></pre></td></tr></table></figure>
<p>mvn spring-boot:run</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">## About POM file</span><br><span class="line">###1. &lt;parent&gt;</span><br><span class="line">&#96;&#96;&#96; xml</span><br><span class="line">&lt;!-- example --&gt;</span><br><span class="line">&lt;parent&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.1.8.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;relativePath&#x2F;&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">&lt;&#x2F;parent&gt;</span><br></pre></td></tr></table></figure>
<p>Which is like the arbitration center of Spring Boot  </p>
<p>###2. &lt;dependencis&gt;<br>This part is to import dependencis</p>
<h4 id="starter"><a href="#starter" class="headerlink" title="starter"></a>starter</h4><p>Starters are a set of convenient dependency descriptors that you can include in your application.<br><a href="https://docs.spring.io/spring-boot/docs/2.1.8.RELEASE/reference/html/using-boot-build-systems.html#using-boot-starter" target="_blank" rel="noopener">https://docs.spring.io/spring-boot/docs/2.1.8.RELEASE/reference/html/using-boot-build-systems.html#using-boot-starter</a></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		...       </span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Main-procedure-class-main-entrance-class"><a href="#Main-procedure-class-main-entrance-class" class="headerlink" title="Main procedure class,main entrance class"></a>Main procedure class,main entrance class</h2><h3 id="SpringBootApplication"><a href="#SpringBootApplication" class="headerlink" title="@SpringBootApplication"></a>@SpringBootApplication</h3><p>The <code>@SpringBootApplication</code> annotation is often placed on your main class, and it implicitly defines a base “search package” for certain items.  </p>
<p>For example, if you are writing a JPA application, the package of the <code>@SpringBootApplication</code> annotated class is used to search for <code>@Entity</code> items.  </p>
<p> Using a root package also allows component scan to apply only on your project. </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">public class Application &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(Application.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>below is the detail of @SpringBootApplication,which is like a gather.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@Target(&#123;ElementType.TYPE&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">@Documented</span><br><span class="line">@Inherited</span><br><span class="line">@SpringBootConfiguration</span><br><span class="line">@EnableAutoConfiguration</span><br><span class="line">@ComponentScan(</span><br><span class="line">    excludeFilters = &#123;@Filter(</span><br><span class="line">    type = FilterType.CUSTOM,</span><br><span class="line">    classes = &#123;TypeExcludeFilter.class&#125;</span><br><span class="line">), @Filter(</span><br><span class="line">    type = FilterType.CUSTOM,</span><br><span class="line">    classes = &#123;AutoConfigurationExcludeFilter.class&#125;</span><br><span class="line">)&#125;</span><br><span class="line">)</span><br><span class="line">public @interface SpringBootApplication &#123;</span><br></pre></td></tr></table></figure>

<h3 id="SpringBootConfiguration"><a href="#SpringBootConfiguration" class="headerlink" title="@SpringBootConfiguration"></a>@SpringBootConfiguration</h3><ul>
<li>@SpringBootConfiguration annotated class is an option class of Spring Boot.</li>
</ul>
<h3 id="EnableAutoConfiguration"><a href="#EnableAutoConfiguration" class="headerlink" title="@EnableAutoConfiguration"></a>@EnableAutoConfiguration</h3><p>Spring Boot auto-configuration attempts to automatically configure your Spring application based on the jar dependencies that you have added.    </p>
<p>You need to opt-in to auto-configuration by adding the <code>@EnableAutoConfiguration</code> or <code>@SpringBootApplication</code> annotations to one of your @Configuration classes.<br>(Because the <code>@SpringBootConfiguration</code> have included @EnableAutoConfiguration,the auto-configuration wil automatically configure all component that in the same package with the <code>@SpringBootConfiguration</code>)</p>
<hr>
<h2 id="Configuration-file"><a href="#Configuration-file" class="headerlink" title="Configuration file"></a>Configuration file</h2><p>Spring Boot default configuration in <em>src/main/resources/</em>.<br><code>application.yml</code> or <code>application.properties</code></p>
<h3 id="1-YAML-basic"><a href="#1-YAML-basic" class="headerlink" title="1.YAML basic"></a>1.YAML basic</h3><p>format like Python<br>key:(space)value </p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">	<span class="attr">port:</span> <span class="number">8081</span></span><br><span class="line">	<span class="attr">path:</span> <span class="string">/halo</span></span><br></pre></td></tr></table></figure>
<p>do not ignore case</p>
<h3 id="2-key-value"><a href="#2-key-value" class="headerlink" title="2. key: value"></a>2. key: value</h3><h4 id="Object-Map"><a href="#Object-Map" class="headerlink" title="Object,Map"></a>Object,Map</h4><p>key: value</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">friends:</span></span><br><span class="line">	<span class="string">name:ring</span></span><br><span class="line">	<span class="string">age:20</span></span><br><span class="line"><span class="string">```</span>  </span><br><span class="line"></span><br><span class="line"><span class="string">inline</span>	</span><br><span class="line"><span class="string">```</span> <span class="string">yml</span></span><br><span class="line"><span class="string">friends:&#123;name:ring,age:20&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h4><p>-value</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">pets:</span></span><br><span class="line">	<span class="string">-cat</span></span><br><span class="line">	<span class="string">-dog</span></span><br></pre></td></tr></table></figure>

<p>inline  </p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">pet:</span> <span class="string">[dog,cat]</span></span><br></pre></td></tr></table></figure>

<h3 id="ConfigurationProperties-prefix-“person”"><a href="#ConfigurationProperties-prefix-“person”" class="headerlink" title="@ConfigurationProperties(prefix = “person”)"></a>@ConfigurationProperties(prefix = “person”)</h3><p>Bind all properties in this class with the properties in configuration file<br><code>prefix = &quot;person&quot;</code> means bind class properties with person properties.  </p>
<p>Only the component props can use the component function<code>@ConfigurationProperties</code>.  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConfigurationProperties</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">XXX</span></span>&#123;</span><br></pre></td></tr></table></figure>

<h3 id="PropertySource-value-“classpath-application2-yml’"><a href="#PropertySource-value-“classpath-application2-yml’" class="headerlink" title="@PropertySource(value = {“classpath:application2.yml’})"></a>@PropertySource(value = {“classpath:application2.yml’})</h3><p>Like @ConfigurationProperties ,but this can select another configuration file.  </p>
<h3 id="ImportResource"><a href="#ImportResource" class="headerlink" title="@ImportResource"></a>@ImportResource</h3><p>Import Spring configuration file,and<br>……..</p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/08/universe/git%E6%93%8D%E4%BD%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/08/universe/git%E6%93%8D%E4%BD%9C/" class="post-title-link" itemprop="url">git操作</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-08 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-08T00:00:00+08:00">2019-09-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-15 21:34:14" itemprop="dateModified" datetime="2020-06-15T21:34:14+08:00">2020-06-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Git-操作"><a href="#Git-操作" class="headerlink" title="Git 操作"></a>Git 操作</h1><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure>

<h3 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure>
<p>###查看修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff BRANCHNAME</span><br></pre></td></tr></table></figure>

<p>###查看提交记录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure>
<h3 id="添加修改并追踪"><a href="#添加修改并追踪" class="headerlink" title="添加修改并追踪"></a>添加修改并追踪</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git add FILE</span><br><span class="line">git add .  &#x2F;&#x2F; 添加所有</span><br></pre></td></tr></table></figure>

<h3 id="退回"><a href="#退回" class="headerlink" title="退回"></a>退回</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git reset</span><br><span class="line">git reset --hard HEAD^ 退回上一个版本</span><br><span class="line">git reset --hard sjaieral 退回某个版本</span><br></pre></td></tr></table></figure>

<h3 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;NAME&quot;</span><br><span class="line">git config --global user.email &quot;EMAIL&quot;</span><br><span class="line">...等等</span><br></pre></td></tr></table></figure>

<h3 id="拉取项目"><a href="#拉取项目" class="headerlink" title="拉取项目"></a>拉取项目</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.获取工程</span><br><span class="line">git clone URL</span><br><span class="line"></span><br><span class="line">2.更新</span><br><span class="line">git pull</span><br></pre></td></tr></table></figure>

<h3 id="添加远程仓库"><a href="#添加远程仓库" class="headerlink" title="添加远程仓库"></a>添加远程仓库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.gibhub上创建一个仓库</span><br><span class="line"></span><br><span class="line">2.添加远程仓库</span><br><span class="line">git remote add origin ULR</span><br><span class="line"></span><br><span class="line">3.推到远程仓库</span><br><span class="line">git push --set-upstream origin master</span><br><span class="line">&#x2F;&#x2F; 然后登录</span><br><span class="line"></span><br><span class="line">4.记住密码</span><br><span class="line">git config credential.helper store</span><br><span class="line">&#x2F;&#x2F; 再次登录就可以记住了</span><br></pre></td></tr></table></figure>

<h3 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git commit &#x2F;&#x2F; 会打开文件让你添加描述</span><br><span class="line">git commit -m &quot;描述&quot; &#x2F;&#x2F; 快捷添加描述提交</span><br></pre></td></tr></table></figure>

<h3 id="不让git管理指定文件"><a href="#不让git管理指定文件" class="headerlink" title="不让git管理指定文件"></a>不让git管理指定文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.新建一个 .gitignore 文件</span><br><span class="line"></span><br><span class="line">2.写入不需要git管理等文件名</span><br><span class="line">&#x2F;&#x2F; 但是git一旦追踪某个文件那就会一只追踪</span><br><span class="line">&#x2F;&#x2F; 停止追踪 git rm --cached FILE</span><br></pre></td></tr></table></figure>

<h3 id="git分支"><a href="#git分支" class="headerlink" title="git分支"></a>git分支</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.创建分支</span><br><span class="line">git branch NAME</span><br><span class="line"></span><br><span class="line">2.切换分支</span><br><span class="line">git checkout NAME</span><br><span class="line"></span><br><span class="line">3.分支合并</span><br><span class="line">git merge NAME &#x2F;&#x2F; 会把NAME分支合并到当前分支</span><br><span class="line"></span><br><span class="line">4.删除分支</span><br><span class="line">git branch -d NAME &#x2F;&#x2F; -D强制删除</span><br><span class="line">&#x2F;&#x2F; 主分支叫master</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
