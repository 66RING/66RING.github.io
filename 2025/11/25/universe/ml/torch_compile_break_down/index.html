<!DOCTYPE html>
<html lang="en">
  <head hexo-theme='https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.0'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <link rel="preload" href="/css/first.css" as="style">
  

  <!-- 页面元数据 -->
  
  <title>Torch Compile解析 - 66Ring&#39;s Blog</title>
  
    <meta name="keywords" content="compiler,pytorch">
  

  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  

  <!-- import link -->
  

  
    
<link rel="stylesheet" href="/css/first.css">

  

  
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  

  <script id="loadcss"></script>

  
<script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        '<h1><b>抱歉，您的浏览器无法访问本站</b></h1>'+
        '<h3>微软已经于2016年终止了对 Internet Explorer (IE) 10 及更早版本的支持，<br/>'+
        '继续使用存在极大的安全隐患，请使用当代主流的浏览器进行访问。</h3><br/>'+
        '<a href="https://www.microsoft.com/zh-cn/WindowsForBusiness/End-of-IE-support" target="_blank" rel="noopener"><strong>了解详情 ></strong></a>'+
    '</div>');
</script>


<noscript>
	<style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
	</style>
    <div class="kill-noscript">
        <h1><b>抱歉，您的浏览器无法访问本站</b></h1>
        <h3>本页面需要浏览器支持（启用）JavaScript</h3><br/>
        <a href="https://www.baidu.com/s?wd=启用JavaScript" target="_blank" rel="noopener"><strong>了解详情 ></strong></a>
    </div>
</noscript>

</head>

  <body>
    

<header id="l_header" class="l_header auto shadow blur show" style='opacity: 0' >
  <div class='container'>
  <div id='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h m-phone' id="pjax-header-nav-list">
        <li><a id="s-comment" class="fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a id="s-toc" class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
            <img no-lazy class='logo' src='https://raw.githubusercontent.com/66RING/66RING/master/.github/images/the_dark_side_of_the_moon_tranp.png'/>
          
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h m-pc'>
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box header toggle-mode-btn">
                  <i class='fas fa-moon fa-fw'></i>Dark Mode
                </a>
              <li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h m-phone'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box header toggle-mode-btn">
                  <i class='fas fa-moon fa-fw'></i>Dark Mode
                </a>
              <li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

    <div id="l_body">
      <div id="l_cover">
  
    
        <div id="full" class='cover-wrapper post dock' style="display: none;">
          
            <div class='cover-bg lazyload placeholder' data-bg="https://uploadbeta.com/api/pictures/random/?key=BingEverydayWallpaperPicture"></div>
          
          <div class='cover-body'>
  <div class='top'>
    
    
      <p class="title">Mens et Manus</p>
    
    
  </div>
  <div class='bottom'>
    <div class='menu navigation'>
      <div class='list-h'>
        
      </div>
    </div>
  </div>
</div>

          <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
        </div>
    
  
  </div>

      <div id="safearea">
        <div class="body-wrapper" id="pjax-container">
          

<div class='l_main'>
  <article class="article post white-box reveal md shadow article-type-post" id="post" itemscope itemprop="blogPost">
  


  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title">
        Torch Compile解析
      </h1>
      <div class='new-meta-box'>
        
          
            
<div class='new-meta-item author'>
  <a class='author' href="/" rel="nofollow">
    <img no-lazy src="">
    <p>请设置文章作者</p>
  </a>
</div>

          
        
          
            

          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：Nov 25, 2025</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item browse leancloud">
    <a class='notlink'>
      
      <div id="lc-pv" data-title="Torch Compile解析" data-path="/2025/11/25/universe/ml/torch_compile_break_down/">
        <i class="fas fa-eye fa-fw" aria-hidden="true"></i>
        <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span>
        次浏览
      </div>
    </a>
  </div>


          
        
      </div>
    
  </div>


  
  
  <h1 id="Torch-Compile解析"><a href="#Torch-Compile解析" class="headerlink" title="Torch Compile解析"></a>Torch Compile解析</h1><blockquote>
<p>二次加工 from: <a href="https://mp.weixin.qq.com/s?__biz=MzYyNTg1OTA5MQ==&amp;mid=2247484015&amp;idx=1&amp;sn=1606439595d5049076c4c7664f4811bc&amp;chksm=f0208d13c7570405a915b78ab21b3a2d3a0c54db1e838ea8df4fa3afccf1bc9c29873cc1a606&amp;cur_album_id=4233444225359986690&amp;scene=190#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzYyNTg1OTA5MQ==&amp;mid=2247484015&amp;idx=1&amp;sn=1606439595d5049076c4c7664f4811bc&amp;chksm=f0208d13c7570405a915b78ab21b3a2d3a0c54db1e838ea8df4fa3afccf1bc9c29873cc1a606&amp;cur_album_id=4233444225359986690&amp;scene=190#rd</a></p>
</blockquote>
<p>commit: 69b05913fb0332f9a938c74e26b106e2bd24d82e</p>
<ol>
<li><strong>TorchDynamo</strong>: 字节码分析 + 图捕获<ul>
<li>生成FX Graph(逻辑的, 语义表示)</li>
</ul>
</li>
<li><strong>AOT Autograd</strong> (joint-graph): 前后向联合优化<ul>
<li>前向反向联合表示, 从而能做全局(fwd+bwd)的优化</li>
</ul>
</li>
<li><strong>TorchInductor</strong>: 分解 + 融合 + 调度 + 代码生成<ul>
<li>生成IR(具体的, 操作的实现), 实际操作的优化</li>
</ul>
</li>
<li>Runtime: 守卫检查 + 缓存管理</li>
</ol>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul>
<li>算子融合<ul>
<li>优化io和launch时间</li>
</ul>
</li>
<li>融合的限制<ul>
<li>可融合<ul>
<li>elementwise(pointwise)可以直接融合</li>
<li>reduction(规约)根据规约模式不同融合模式有区别</li>
</ul>
</li>
<li>开销(trade-off)<ul>
<li>寄存器压力 vs 融合粒度</li>
</ul>
</li>
</ul>
</li>
<li>AOT(Ahead-Of-Time Autograd) -&gt; 针对训练场景的优化<ul>
<li>背景: autograd机制<ul>
<li>fwd: 保存激活值</li>
<li>bwd: 根据激活值计算梯度</li>
</ul>
</li>
<li>问题:<ul>
<li>需要保存什么, 何时不再使用再单个fwd/bwd中是不知道的。优化器需要看到全局才能最优</li>
</ul>
</li>
<li>解决方案 ： AOT<ul>
<li>编译期生成fwd + bwd的计算图(joint-graph), 优化器就有了全局的视角</li>
</ul>
</li>
<li>好处:<ul>
<li>重计算感知和自动重计算</li>
<li>fwd, bwd融合</li>
<li>内存布局优化: 减少拷贝, 申请释放等内存操作的开销</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="编译流水线"><a href="#编译流水线" class="headerlink" title="编译流水线"></a>编译流水线</h2><p>四个核心阶段</p>
<ol>
<li><strong>TorchDynamo</strong>: 字节码分析 + 图捕获</li>
<li><strong>AOT Autograd</strong> (joint-graph): 前后向联合优化</li>
<li><strong>TorchInductor</strong>: 分解 + 融合 + 调度 + 代码生成</li>
<li>Runtime: 守卫检查 + 缓存管理</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Python → FX → Joint → IR → Kernel</span><br><span class="line"></span><br><span class="line">Python 函数</span><br><span class="line">    ↓</span><br><span class="line">[TorchDynamo] 字节码分析 + 图捕获</span><br><span class="line">    ↓</span><br><span class="line">FX Graph + Guards</span><br><span class="line">    ↓</span><br><span class="line">[AOT Autograd] 前后向联合（训练时）</span><br><span class="line">    ↓</span><br><span class="line">Joint Graph → Forward Graph + Backward Graph</span><br><span class="line">    ↓</span><br><span class="line">[IR 转换] FX → Core ATen → Prims</span><br><span class="line">    ↓</span><br><span class="line">[TorchInductor] 分解 + 融合 + 调度 + 代码生成</span><br><span class="line">    ↓</span><br><span class="line">设备内核 (Triton&#x2F;C++)</span><br><span class="line">    ↓</span><br><span class="line">[Runtime] 守卫检查 + 缓存管理</span><br><span class="line">    ↓</span><br><span class="line">执行</span><br></pre></td></tr></table></figure>

<ol>
<li>Python 调用 model(x)</li>
<li>TorchDynamo 拦截，分析字节码，构建 FX Graph，生成守卫</li>
<li>AOT Autograd 处理（如果是训练模式）</li>
<li>Inductor 分解算子、融合、生成 Triton 代码</li>
<li>调用 Triton/NVCC 编译器生成机器码</li>
<li>执行编译后的 kernel</li>
<li>返回结果</li>
</ol>
<p>功能解析</p>
<table>
<thead>
<tr>
<th>层次</th>
<th>输入</th>
<th>输出</th>
<th>核心职责</th>
<th>关键约束</th>
</tr>
</thead>
<tbody><tr>
<td>TorchDynamo</td>
<td>Python 字节码</td>
<td>FX Graph + Guards</td>
<td>捕获纯张量计算</td>
<td>遇到不支持构造时断图</td>
</tr>
<tr>
<td>AOT Autograd</td>
<td>FX Graph (forward)</td>
<td>Joint Graph / Forward + Backward</td>
<td>前后向联合优化</td>
<td>只在训练时启用</td>
</tr>
<tr>
<td>IR 转换</td>
<td>FX Graph</td>
<td>Core ATen IR / Prims IR</td>
<td>标准化表示</td>
<td>函数式语义，无 in-place</td>
</tr>
<tr>
<td>TorchInductor</td>
<td>Core ATen IR</td>
<td>Triton/C++ 代码</td>
<td>融合、调度、代码生成</td>
<td>特定硬件的优化策略</td>
</tr>
<tr>
<td>Runtime</td>
<td>编译后的函数</td>
<td>执行结果</td>
<td>守卫检查、缓存管理</td>
<td>维护正确性保证</td>
</tr>
</tbody></table>
<h2 id="TorchDynamo-FX-Graph"><a href="#TorchDynamo-FX-Graph" class="headerlink" title="TorchDynamo(FX Graph)"></a>TorchDynamo(FX Graph)</h2><blockquote>
<p>从python提取计算图生成FX Graph</p>
</blockquote>
<ul>
<li>FX Graph构建<ul>
<li>符号执行: 不真正的执行, “相当于符号推导”</li>
<li>处理控制流: 静态展开 + 运行时展开</li>
<li>守卫生成: “加assert”, 记录类型、形状等<ul>
<li>守卫检查会被编译成一个高效的函数</li>
</ul>
</li>
<li>断图策略: 如有数据依赖等场景需要运行时决定<ul>
<li>控制流: e.g. if -&gt; 拆分两部分</li>
<li>不支持的python操作: e.g. print</li>
<li>外部库</li>
<li>使用<code>fullgraph=True</code>可以在遇到段图时报错</li>
<li>使用<code>TORCH_LOGS=graph_breaks</code>环境变量可以显示段图原因和位置</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="FX-Graph"><a href="#FX-Graph" class="headerlink" title="FX Graph"></a>FX Graph</h3><blockquote>
<p>TorchDynamo的产物</p>
<p>FX: 用python对象描述图, 而不是其他抽象/库</p>
</blockquote>
<ul>
<li>Proxy + FakeTensor来捕获所有操作信息(操作对象, 操作内容)<ul>
<li>后续优化可以参考这些信息</li>
</ul>
</li>
<li>FX Graph变换<ul>
<li>节点增删改</li>
<li>PASS优化</li>
</ul>
</li>
</ul>
<h2 id="AOT-Autograd"><a href="#AOT-Autograd" class="headerlink" title="AOT Autograd"></a>AOT Autograd</h2><blockquote>
<p>Joint Graph: fwd, bwd联合优化</p>
</blockquote>
<p>e.g. 构建joint graph: fwd, bwd联合在一起</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">joint</span><span class="params">(x, weight, grad_h2)</span>:</span></span><br><span class="line">    <span class="comment"># === Forward ===</span></span><br><span class="line">    h1 = torch.matmul(x, weight)</span><br><span class="line">    h2 = h1.relu()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># === Backward ===</span></span><br><span class="line">    <span class="comment"># 注意：后向依赖前向的某些中间结果</span></span><br><span class="line">    grad_h1 = grad_h2.clone()</span><br><span class="line">    grad_h1[h1 &lt;= <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    grad_x = torch.matmul(grad_h1, weight.t())</span><br><span class="line">    grad_weight = torch.matmul(x.t(), grad_h1)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回：前向输出 + 梯度</span></span><br><span class="line">    <span class="keyword">return</span> h2, grad_x, grad_weight</span><br></pre></td></tr></table></figure>

<ul>
<li>优化内容:<ul>
<li>min-cut分区: 生命周期, 较少saved tensor</li>
<li>重计算 vs 保存 tradeoff</li>
<li>压缩保存: relu用bitmap保存</li>
<li>…</li>
</ul>
</li>
<li>效果收益:<ul>
<li>更少的activation占用 -&gt; 可以更大batch</li>
<li>提升GPU利用率</li>
</ul>
</li>
</ul>
<h2 id="TorchInductor"><a href="#TorchInductor" class="headerlink" title="TorchInductor"></a>TorchInductor</h2><blockquote>
<p>IR, PASS和代码生成</p>
<p>ATenIR生成目标代码</p>
</blockquote>
<h3 id="算子融合"><a href="#算子融合" class="headerlink" title="算子融合"></a>算子融合</h3><p>Inductor把算子分成三类做融合</p>
<ul>
<li>Pointwise（逐点）：输出的每个元素只依赖对应位置的输入<ul>
<li>例子：add, mul, relu, exp, tanh</li>
<li>融合策略：直接串联</li>
</ul>
</li>
<li>Reduction（规约）：输出元素依赖多个输入元素<ul>
<li>例子：sum, softmax, layer_norm</li>
<li>融合策略：persistent reduction（把 reduction 和后续 pointwise 融合）</li>
</ul>
</li>
<li>Template（模板）：复杂的结构化计算，有专门的实现<ul>
<li>例子：matmul, conv2d（调用 cuBLAS/cuDNN）</li>
<li>融合策略：通常不融合，直接调用库</li>
</ul>
</li>
</ul>
<h3 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h3><blockquote>
<p>资源如何分配</p>
</blockquote>
<p>一些关键考虑</p>
<ul>
<li>Block size：每个线程块处理多少元素<ul>
<li>太小：并行度不足</li>
<li>太大：寄存器压力过大，occupancy 下降</li>
</ul>
<ul>
<li>典型值：256-1024</li>
</ul>
</li>
<li>Tiling：如何分块访问数据<ul>
<li>目标：最大化 L1/L2 cache 命中率</li>
<li>对于大 tensor，需要分块处理</li>
</ul>
</li>
<li>向量化：一次加载多少元素<ul>
<li>GPU 内存访问是按 32/64/128 bytes 对齐的</li>
<li>合并访问可以提高带宽利用率</li>
</ul>
</li>
</ul>
<h3 id="模板系统"><a href="#模板系统" class="headerlink" title="模板系统"></a>模板系统</h3><blockquote>
<p>Inductor 使用 Jinja2 模板生成代码</p>
</blockquote>
<p>e.g.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">triton_template = <span class="string">"""</span></span><br><span class="line"><span class="string">@triton.jit</span></span><br><span class="line"><span class="string">def &#123;&#123;kernel_name&#125;&#125;(&#123;&#123;params&#125;&#125;):</span></span><br><span class="line"><span class="string">    pid = tl.program_id(0)</span></span><br><span class="line"><span class="string">    offsets = pid * &#123;&#123;BLOCK_SIZE&#125;&#125; + tl.arange(0, &#123;&#123;BLOCK_SIZE&#125;&#125;)</span></span><br><span class="line"><span class="string">    mask = offsets &lt; &#123;&#123;n_elements&#125;&#125;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &#123;% for load in loads %&#125;</span></span><br><span class="line"><span class="string">    &#123;&#123;load.name&#125;&#125; = tl.load(&#123;&#123;load.ptr&#125;&#125; + offsets, mask=mask)</span></span><br><span class="line"><span class="string">    &#123;% endfor %&#125;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &#123;% for op in ops %&#125;</span></span><br><span class="line"><span class="string">    &#123;&#123;op&#125;&#125;</span></span><br><span class="line"><span class="string">    &#123;% endfor %&#125;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    tl.store(&#123;&#123;output_ptr&#125;&#125; + offsets, &#123;&#123;output_var&#125;&#125;, mask=mask)</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

<h2 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h2><ul>
<li>守卫检查</li>
<li>变体缓存</li>
<li>重编译和泛化</li>
</ul>
<h2 id="三段式优化"><a href="#三段式优化" class="headerlink" title="三段式优化"></a>三段式优化</h2><ol>
<li>FX Graph层做python级别的算子优化<ul>
<li>规范化, 联合优化</li>
</ul>
</li>
<li>Inductor IR级别的优化: 计算模式, 内存布局<ul>
<li><strong>scheduler</strong></li>
</ul>
</li>
<li>代码生成优化: 具体设备相关优化</li>
</ol>
<h3 id="阶段1-FX-Graph-Passes-Lowering前"><a href="#阶段1-FX-Graph-Passes-Lowering前" class="headerlink" title="阶段1: FX Graph Passes(Lowering前)"></a>阶段1: FX Graph Passes(Lowering前)</h3><blockquote>
<p>操作Aten/Prims ops</p>
<p>Lowering前</p>
</blockquote>
<p>五个阶段</p>
<ol>
<li>Pre-Grad Passes<ul>
<li>结构规范化(消除split/cat)</li>
<li>形状传播</li>
<li>padding调整</li>
</ul>
</li>
<li>AOT Autograd<ul>
<li>fwd+bwd联合追踪</li>
</ul>
</li>
<li>Joint Graph Passes<ul>
<li>Peephole 优化（常量折叠、冗余视图消除） </li>
<li>随机数处理</li>
</ul>
</li>
<li>Min-Cut Partitioning<ul>
<li>拆分为 fw_graph + bw_graph </li>
</ul>
</li>
<li>Post-Grad Passes<ul>
<li>局部性重排（reorder_for_locality）</li>
<li>No-op 消除(e.g. 两次相同的transpose)</li>
<li>Reinplace（功能化→原地）</li>
</ul>
</li>
</ol>
<h4 id="Pre-Grad-Passes"><a href="#Pre-Grad-Passes" class="headerlink" title="Pre-Grad Passes"></a>Pre-Grad Passes</h4><blockquote>
<p>只能看到前向</p>
</blockquote>
<ul>
<li>不改变图结构, 加metadata</li>
<li>规范化<ul>
<li>e.g. 防止split/cat等在转换成IR后信息丢失</li>
</ul>
</li>
<li>消除冗余<ul>
<li>e.g. 减少处理的节点数</li>
</ul>
</li>
</ul>
<h4 id="AOT-Joint-Graph"><a href="#AOT-Joint-Graph" class="headerlink" title="AOT + Joint Graph"></a>AOT + Joint Graph</h4><blockquote>
<p>能看到前向和后向</p>
</blockquote>
<ul>
<li>AOT Autograd生成后续图</li>
<li>fwd, bwd两个图合并</li>
<li>Peephole 优化<ul>
<li>“通过一个小孔看代码”, 只关注局部模式</li>
<li>e.g. <code>y = x * 1.0</code>优化成<code>y = x</code></li>
</ul>
</li>
<li>继续消除冗余操作等…</li>
</ul>
<h4 id="Min-Cut-Partitioning拆分"><a href="#Min-Cut-Partitioning拆分" class="headerlink" title="Min-Cut Partitioning拆分"></a>Min-Cut Partitioning拆分</h4><p>拆分Joint Graph成fwd, bwd</p>
<ul>
<li>fwd包含fwd和saved tensor</li>
<li>bwd包含saved tensor</li>
<li>做一些能看到全图的优化</li>
</ul>
<h4 id="Post-Grad-Passes"><a href="#Post-Grad-Passes" class="headerlink" title="Post-Grad Passes"></a>Post-Grad Passes</h4><p>fwd, bwd已拆分。分别优化前后向图</p>
<ol>
<li>调整节点顺序, 局部性重排<ul>
<li>优化cache, 生命周期等</li>
</ul>
</li>
<li>消除no-op: e.g. 连续两次相同的transpose</li>
<li>用inplace优化避免新建tensor操作的开销</li>
<li>其他: 死代码, 分布式优化..<ul>
<li>Lowering前最后一个阶段, 所有多点优化</li>
</ul>
</li>
</ol>
<h3 id="阶段2-Inductor-IR-Passes-Lowering后-codegen前"><a href="#阶段2-Inductor-IR-Passes-Lowering后-codegen前" class="headerlink" title="阶段2: Inductor IR Passes(Lowering后, codegen前)"></a>阶段2: Inductor IR Passes(Lowering后, codegen前)</h3><blockquote>
<p>Lower fx graph到IR</p>
<p>FX Graph -&gt; torch/_inductor/lowering.py -&gt; IR</p>
</blockquote>
<p>遍历FX Graph, 查表生成IR</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch/torch/_inductor/lowering.py:115</span></span><br><span class="line">lowerings: Dict[OpOverload, Callable] = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># ... register_foreach_pointwise</span></span><br></pre></td></tr></table></figure>

<p>FX Graph表示了语义但是不知道具体应该怎么执行(e.g. 怎么加, 调库还是什么)。lower成Inductor IR后就知道了具体的操作:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># FX Graph: 知道语义, add和两个参数x, y</span></span><br><span class="line">%add = call_function[target=torch.ops.aten.add.default](</span><br><span class="line">    args=(%x, %y)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inductor IR: 知道具体操作, 计算模式</span></span><br><span class="line">Pointwise(</span><br><span class="line">    device=torch.device(<span class="string">'cuda'</span>),</span><br><span class="line">    dtype=torch.float32,</span><br><span class="line">    inner_fn=<span class="keyword">lambda</span> idx: ops.add(</span><br><span class="line">        x.make_loader()(idx), </span><br><span class="line">        y.make_loader()(idx)</span><br><span class="line">    ),</span><br><span class="line">    ranges=[SymInt(<span class="number">100</span>), SymInt(<span class="number">200</span>)]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Pointwise可以看成是Inductor IR对计算模式的抽象, scheduler根据这个信息(类型, 范围, 访存模式等)可以判断是否可以融合。</p>
<h4 id="Lowering"><a href="#Lowering" class="headerlink" title="Lowering"></a>Lowering</h4><ol>
<li>查表: Lowering Registry<ul>
<li>注册所有aten算子, e.g. <code>@register_lowering(aten.add)</code><ul>
<li>e.g. pointwise算子只需要循环 + 循环体(add, mul, div…)</li>
</ul>
</li>
</ul>
</li>
<li>Lowering方法: 算子分类pointwise, reduction, template<ul>
<li>Pointwise: 循环 + 循环体(op)</li>
<li>Reduction: 循环(外循环) + 规约维度 + 规约方式(op)</li>
<li>ExternKernel(调用外部库)</li>
</ul>
</li>
</ol>
<h4 id="内存布局决策"><a href="#内存布局决策" class="headerlink" title="内存布局决策"></a>内存布局决策</h4><blockquote>
<p>Layout 的类型（pytorch/torch/_inductor/ir.py:3882）</p>
<p>Lowering时要根据FX Graph记录的逻辑形状决定物理布局</p>
<p>复用逻辑视图(但引入额外索引计算), 还是物化视图(但需要额外拷贝)</p>
</blockquote>
<p>本质就是shape + stride。主要有两个抽象: <code>FlexibleLayout</code>(动态布局), <code>FixedLayout</code>(静态布局)。scheduler可以修改动态布局的信息, 供后续使用</p>
<p>e.g. reshape, tranpose等可以只改变布局信息</p>
<p><strong>什么时候会物化（materialize）？</strong> (1)当多次view被使用时, 避免重复的索引计算。(2) 无法处理的复杂stride时(非连续)</p>
<p><strong>物化的实现(生成一个copy kernel)</strong>: <code>物化的实现（pytorch/torch/_inductor/ir.py:8320）</code></p>
<h4 id="IR结构"><a href="#IR结构" class="headerlink" title="IR结构"></a>IR结构</h4><p>IR表示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IRNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_size</span><span class="params">(self)</span> -&gt; List[Expr]:</span></span><br><span class="line">        <span class="comment"># 返回输出的形状</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_stride</span><span class="params">(self)</span> -&gt; List[Expr]:</span></span><br><span class="line">        <span class="comment"># 返回输出的 stride</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">realize</span><span class="params">(self)</span> -&gt; Buffer:</span></span><br><span class="line">        <span class="comment"># 物化：将计算转换成实际的 Buffer</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_loader</span><span class="params">(self)</span> -&gt; Callable:</span></span><br><span class="line">        <span class="comment"># 返回一个 loader 函数，用于读取这个节点的输出</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>存储和视图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TensorBox</span>:</span></span><br><span class="line">    <span class="comment"># 顶层抽象，表示一个 tensor</span></span><br><span class="line">    <span class="comment"># 内部包含一个 StorageBox</span></span><br><span class="line">    data: StorageBox</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageBox</span>:</span></span><br><span class="line">    <span class="comment"># 可变存储，支持原地操作</span></span><br><span class="line">    data: IRNode  <span class="comment"># 可能是 View、Pointwise、Reduction 等</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">realize</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 物化：将 self.data 转换成 ComputedBuffer</span></span><br><span class="line">        <span class="comment"># 触发条件：</span></span><br><span class="line">        <span class="comment"># - 被多次使用</span></span><br><span class="line">        <span class="comment"># - 读取次数超过阈值（config.realize_acc_reads_threshold）</span></span><br><span class="line">        <span class="comment"># - 需要明确的内存分配</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Buffer</span><span class="params">(IRNode)</span>:</span></span><br><span class="line">    <span class="comment"># 已分配内存的 tensor</span></span><br><span class="line">    name: str</span><br><span class="line">    layout: Layout</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InputBuffer</span><span class="params">(Buffer)</span>:</span></span><br><span class="line">    <span class="comment"># 输入参数（来自 FX Graph 的 placeholder）</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ComputedBuffer</span><span class="params">(Buffer)</span>:</span></span><br><span class="line">    <span class="comment"># 计算结果（来自 Pointwise、Reduction 的物化）</span></span><br><span class="line">    data: Loops  <span class="comment"># 包含循环体代码</span></span><br></pre></td></tr></table></figure>


<h3 id="阶段3-Codegen-Passes"><a href="#阶段3-Codegen-Passes" class="headerlink" title="阶段3: Codegen Passes"></a>阶段3: Codegen Passes</h3><blockquote>
<p>根据目标设备生成目标代码</p>
<p>设备相关的关键优化参数: block size, tiling, avx等</p>
<p>IR -&gt; torch/_inductor/codegen/ -&gt; code(str)</p>
</blockquote>
<p>Codegen 接收这个 FusedSchedulerNode，生成 Triton Python 代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scheduler 输出</span></span><br><span class="line">fused_node = FusedSchedulerNode(</span><br><span class="line">    nodes=[pow_node, mul1_node, add1_node, ...],  <span class="comment"># 8 个融合的节点</span></span><br><span class="line">    device=<span class="string">'cuda'</span>,</span><br><span class="line">    group=(device, normalized_size)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Codegen 输出（Triton 代码）</span></span><br><span class="line"><span class="meta">@triton_heuristics.pointwise(</span></span><br><span class="line">    size_hints=&#123;<span class="string">'x'</span>: <span class="number">4096</span>&#125;, </span><br><span class="line">    filename=__file__,</span><br><span class="line">    triton_meta=&#123;<span class="string">'signature'</span>: &#123;...&#125;, <span class="string">'device'</span>: DeviceProperties(...)&#125;,</span><br><span class="line">)</span><br><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triton_poi_fused_gelu_0</span><span class="params">(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr)</span>:</span></span><br><span class="line">    xoffsets = tl.program_id(<span class="number">0</span>) * XBLOCK + tl.arange(<span class="number">0</span>, XBLOCK)</span><br><span class="line">    xmask = xoffsets &lt; xnumel</span><br><span class="line">    x0 = xoffsets</span><br><span class="line">    tmp0 = tl.load(in_ptr0 + x0, xmask)</span><br><span class="line">    <span class="comment"># ... 融合的计算 ...</span></span><br><span class="line">    tl.store(out_ptr0 + x0, tmp8, xmask)</span><br></pre></td></tr></table></figure>

<h4 id="Triton代码结构"><a href="#Triton代码结构" class="headerlink" title="Triton代码结构"></a>Triton代码结构</h4><ol>
<li>装饰器(Heuristics)<ul>
<li>大小, 类型, 怎么tune</li>
</ul>
</li>
<li>triton jit</li>
<li>kernel主体</li>
</ol>
<ul>
<li>block size选择<ul>
<li>sm利用率</li>
</ul>
</li>
<li>warp数</li>
<li>autotune</li>
</ul>
<h4 id="工程细节"><a href="#工程细节" class="headerlink" title="工程细节"></a>工程细节</h4><ul>
<li>装饰器选择<br>  装饰器的选择取决于 kernel 的特征（torch/_inductor/codegen/triton.py:5036）。</li>
<li>输入输出缓存(triton代码生成在哪)<ul>
<li>文件路径（torch/_inductor/codecache.py:1844）<ul>
<li>默认路径<code>/tmp/torchinductor_&lt;username&gt;/...</code></li>
</ul>
</li>
<li>命名策略（torch/_inductor/config.py:1384）<ul>
<li>e.g. <code>TORCHINDUCTOR_UNIQUE_KERNEL_NAMES=1</code>可以关闭唯一命名</li>
</ul>
</li>
<li>triton自己的缓存<ul>
<li><code>~/.triton/cache</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="调试与日志"><a href="#调试与日志" class="headerlink" title="调试与日志"></a>调试与日志</h4><blockquote>
<p>如何查看生成的 Triton 代码？</p>
</blockquote>
<ul>
<li>方法1: <code>export TORCH_LOGS=output_code</code></li>
<li>方法2：保留编译产物<code>export TORCHINDUCTOR_CACHE_DIR=/path/to/cache</code></li>
<li>方法3：Dump IR<code>torch._dynamo.config.output_code = True</code></li>
</ul>
<h2 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h2><blockquote>
<p>融合的决策: 资源(寄存器)压力和性能的tradeoff</p>
</blockquote>
<p>Scheduler决策的依据: 全融合(寄存器压力大)或部分融合</p>
<ul>
<li>Tensor 的大小</li>
<li>GPU 的寄存器数量</li>
<li>中间结果是否被多次使用</li>
<li>启发式的代价模型</li>
</ul>
<h3 id="依赖分析"><a href="#依赖分析" class="headerlink" title="依赖分析"></a>依赖分析</h3><ul>
<li>必须保持的依赖(MemoryDep)<ul>
<li>RAW(Read After Write)</li>
</ul>
</li>
<li>某种情况可以打破的依赖(WeakDep)<ul>
<li>WAR(Write After Read, 反依赖)</li>
<li>WAW(Write After Write, 输出依赖)</li>
</ul>
</li>
</ul>
<p>之后就是循环依赖检查, 拓扑排序</p>
<h3 id="融合决策"><a href="#融合决策" class="headerlink" title="融合决策"></a>融合决策</h3><p>遵循一套规则</p>
<ol>
<li>相同的迭代空间<ul>
<li>e.g. pointwise算子</li>
</ul>
</li>
<li>兼容的设备和dtype</li>
<li>依赖允许</li>
<li>启发式规则<ul>
<li>小节点优先融合: kernel开销大于计算本身</li>
<li>共享数据融合: 共享一次读</li>
<li>寄存器压力评估</li>
<li>基准驱动(现场跑个benchmark测试)<ul>
<li><code>torch/_inductor/scheduler.py:6168</code></li>
</ul>
</li>
</ul>
</li>
</ol>

  
  
    
    <div class='footer'>
      
      
      
        <div class='copyright'>
          <blockquote>
            
              
                <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

              
            
              
                <p>本文永久链接是：<a href=http://github.com/66ring/2025/11/25/universe/ml/torch_compile_break_down/>http://github.com/66ring/2025/11/25/universe/ml/torch_compile_break_down/</a></p>
              
            
          </blockquote>
        </div>
      
      
    </div>
  
  
    


  <div class='article-meta' id="bottom">
    <div class='new-meta-box'>
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/compiler/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>compiler</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/pytorch/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>pytorch</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
    
      
    
  </div>
</div>



        
      
    </div>
  </div>


  
  

  
    <div class="prev-next">
      
        <a class='prev' href='/2025/11/26/universe/python/asyncio/'>
          <p class='title'><i class="fas fa-chevron-left" aria-hidden="true"></i>python异步编程cheat sheet</p>
          <p class='content'>python异步编程本质: (1)创建协程后后台执行, 还是(2)创建协程后”等待”执行。两者抽象出了asyncio的语法糖

async def async_func()可以快速定义异步方便
...</p>
        </a>
      
      
        <a class='next' href='/2025/11/10/universe/ml/sglang_diffusion/'>
          <p class='title'>sglang diffusion走读<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
          <p class='content'>sglang diffusion走读Cheat sheet
generate
_send_to_scheduler_and_wait_for_response -&gt; event_loop
...</p>
        </a>
      
    </div>
  
</article>


  

  <article class="post white-box reveal shadow" id="comments">
    <p ct><i class='fas fa-comments'></i> 评论</p>
    
    <div id="valine_container" class="valine_thread">
  <i class="fas fa-cog fa-spin fa-fw fa-2x"></i>
</div>

  </article>





  <script>
  // https://github.com/theme-next/hexo-theme-next/blob/master/layout/_third-party/math/mathjax.swig
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.0/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    // 文章章节标题不能为 “MathJax” ，否则会报错。
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



</div>
<aside class='l_side'>
  
  
    
    



  <section class="widget toc-wrapper shadow desktop mobile" id="toc-div" >
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#背景"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#编译流水线"><span class="toc-text">编译流水线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TorchDynamo-FX-Graph"><span class="toc-text">TorchDynamo(FX Graph)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#FX-Graph"><span class="toc-text">FX Graph</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AOT-Autograd"><span class="toc-text">AOT Autograd</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TorchInductor"><span class="toc-text">TorchInductor</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#算子融合"><span class="toc-text">算子融合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#调度器"><span class="toc-text">调度器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模板系统"><span class="toc-text">模板系统</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Runtime"><span class="toc-text">Runtime</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三段式优化"><span class="toc-text">三段式优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#阶段1-FX-Graph-Passes-Lowering前"><span class="toc-text">阶段1: FX Graph Passes(Lowering前)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Pre-Grad-Passes"><span class="toc-text">Pre-Grad Passes</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOT-Joint-Graph"><span class="toc-text">AOT + Joint Graph</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Min-Cut-Partitioning拆分"><span class="toc-text">Min-Cut Partitioning拆分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Post-Grad-Passes"><span class="toc-text">Post-Grad Passes</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#阶段2-Inductor-IR-Passes-Lowering后-codegen前"><span class="toc-text">阶段2: Inductor IR Passes(Lowering后, codegen前)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Lowering"><span class="toc-text">Lowering</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#内存布局决策"><span class="toc-text">内存布局决策</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IR结构"><span class="toc-text">IR结构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#阶段3-Codegen-Passes"><span class="toc-text">阶段3: Codegen Passes</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Triton代码结构"><span class="toc-text">Triton代码结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#工程细节"><span class="toc-text">工程细节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#调试与日志"><span class="toc-text">调试与日志</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scheduler"><span class="toc-text">Scheduler</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#依赖分析"><span class="toc-text">依赖分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#融合决策"><span class="toc-text">融合决策</span></a></li></ol></li></ol>
    </div>
  </section>


  


</aside>



		  
		  <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="Torch Compile解析";
  pdata.commentPath="";
  pdata.commentPlaceholder="";

  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
</script>

        </div>
        
  
  <footer class="footer clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
          
            
          
            
          
        </div>
      
    
      
        <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
      
    
      
        
          <div><p><span id="lc-sv">本站总访问量为 <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span> 次</span> <span id="lc-uv">访客数为 <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span> 人</span></p>
</div>
        
      
    
      
        Use
        <a href="https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.0" target="_blank" class="codename">Volantis</a>
        as theme
      
    
      
        <div class='copyright'>
        <p><a href="/">Copyright © 2017-2020 XXX</a></p>

        </div>
      
    
  </footer>


        <a id="s-top" class="fas fa-arrow-up fa-fw" href="javascript:void(0)"></a>
      </div>
    </div>
    <div>
      <script>
/************这个文件存放不需要重载的全局变量和全局函数*********/
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/******************** Pjax ********************************/
function VPjax(){
	this.list=[] // 存放回调函数
	this.start=()=>{
	  for(var i=0;i<this.list.length;i++){
		this.list[i].run();
	  }
	}
	this.push=(fn,name)=>{
		var f=new PjaxItem(fn,name);
		this.list.push(f);
	}
	// 构造一个可以run的对象
	function PjaxItem(fn,name){
		// 函数名称
		this.name = name || fn.name
		// run方法
		this.run=()=>{
			fn()
		}
	}
}
volantis.pjax={}
volantis.pjax.method={
	complete: new VPjax(),
	error: new VPjax(),
	send: new VPjax()
}
volantis.pjax={
	...volantis.pjax,
	push: volantis.pjax.method.complete.push,
	error: volantis.pjax.method.error.push,
	send: volantis.pjax.method.send.push
}
/********************脚本懒加载函数********************************/
// 已经加入了setTimeout
function loadScript(src, cb) {
	setTimeout(function() {
		var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
		var script = document.createElement('script');
		script.setAttribute('type','text/javascript');
		if (cb) script.onload = cb;
		script.setAttribute('src', src);
		HEAD.appendChild(script);
	});
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script>
<script>
  
  loadCSS("https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14/css/all.min.css", window.volantis.loadcss);
  
  
  
  
</script>
<!-- required -->

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js"></script>

<script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
  };
  $(function () {
    SCload_fancybox();
  });
  function Pjax_SCload_fancybox(){
	if (typeof $.fancybox == "undefined") {
	 SCload_fancybox();
    } else {
	 pjax_fancybox();
    }
  }
  volantis.pjax.push(Pjax_SCload_fancybox)
  volantis.pjax.send(()=>{
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
  },'fancybox')
</script>


<!-- internal -->




<script>
  function loadIssuesJS() {
    if ($(".md").find(".issues-api").length == 0) return;
	
	  loadScript('/js/issues.js');
	
  };
  $(function () {
    loadIssuesJS();
  });
  volantis.pjax.push(()=>{
	if (typeof IssuesAPI == "undefined") {
	  loadIssuesJS();
	}
  },"IssuesJS")
</script>



  <script defer src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  

<script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: [],
	maxRPS: 5,
	hoverDelay: 25
  };
</script>
<script defer src="https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"></script>











  
  
<script src="/js/valine.js"></script>


<script>
  function emoji(path, idx, ext) {
    return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  function pjax_valine() {
    if(!document.querySelectorAll("#valine_container")[0])return;
    let pagePlaceholder = pdata.commentPlaceholder || "快来评论吧~";
    let path = pdata.commentPath;
    if (path.length == 0) {
      let defaultPath = '';
      path = defaultPath || decodeURI(window.location.pathname);
    }
    var valine = new Valine();
    valine.init(Object.assign({"path":null,"placeholder":"快来评论吧~","appId":"EKmusUsvxKTWym4LJnmkk1eU-gzGzoHsz","appKey":"sdWXsEnYQvIqRVoEPSMsLCr6","meta":["nick","mail","link"],"requiredFields":["nick","mail"],"enableQQ":true,"recordIP":false,"avatar":"robohash","pageSize":10,"lang":"zh-cn","highlight":true,"mathJax":false}, {
      el: '#valine_container',
      path: path,
      placeholder: pagePlaceholder,
      emojiCDN: 'https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/',
      emojiMaps: emojiMaps,
    }))
  }
  $(function () {
    pjax_valine();
  });
  volantis.pjax.push(pjax_valine);
</script>






  
<script src="/js/app.js"></script>



<!-- optional -->

  <script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
}
</script>











  <script defer>

  const LCCounter = {
    app_id: 'u9j57bwJod4EDmXWdxrwuqQT-MdYXbMMI',
    app_key: 'jfHtEKVE24j0IVCGHbvuFClp',
    custom_api_server: '',

    // 查询存储的记录
    getRecord(Counter, url, title) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({url})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {url, title: title, times: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    },

    // 发起自增请求
    increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    },

    // 构建自增请求体
    buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "times": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    },

    // 校验是否为有效的 UV
    validUV() {
      var key = 'LeanCloudUVTimestamp';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    },

    addCount(Counter) {
      var enableIncr = '' === 'true' && window.location.hostname !== 'localhost';
      enableIncr = true;
      var getterArr = [];
      var incrArr = [];
      // 请求 PV 并自增
      var pvCtn = document.querySelector('#lc-sv');
      if (pvCtn || enableIncr) {
        var pvGetter = this.getRecord(Counter, 'http://github.com/66ring' + '/#lc-sv', 'Visits').then((record) => {
          incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-sv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + 1;
              if (pvCtn) {
                pvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#lc-uv');
      if (uvCtn || enableIncr) {
        var uvGetter = this.getRecord(Counter, 'http://github.com/66ring' + '/#lc-uv', 'Visitors').then((record) => {
          var vuv = this.validUV();
          vuv && incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-uv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + (vuv ? 1 : 0);
              if (uvCtn) {
                uvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(uvGetter);
      }

      // 请求文章的浏览数，如果是当前页面就自增
      var allPV = document.querySelectorAll('#lc-pv');
      if (allPV.length > 0 || enableIncr) {
        for (i = 0; i < allPV.length; i++) {
          let pv = allPV[i];
          let title = pv.getAttribute('data-title');
          var url = 'http://github.com/66ring' + pv.getAttribute('data-path');
          if (url) {
            var viewGetter = this.getRecord(Counter, url, title).then((record) => {
              // 是当前页面就自增
              let curPath = window.location.pathname;
              if (curPath.includes('index.html')) {
                curPath = curPath.substring(0, curPath.lastIndexOf('index.html'));
              }
              if (pv.getAttribute('data-path') == curPath) {
                incrArr.push(this.buildIncrement(record.objectId));
              }
              if (pv) {
                var ele = pv.querySelector('#lc-pv #number');
                if (ele) {
                  if (pv.getAttribute('data-path') == curPath) {
                    ele.innerText = (record.times || 0) + 1;
                  } else {
                    ele.innerText = record.times || 0;
                  }
                  pv.style.display = 'inline';
                }
              }
            });
            getterArr.push(viewGetter);
          }
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && this.increment(Counter, incrArr);
        })
      }

    },


    fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': this.app_id,
            'X-LC-Key': this.app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      this.addCount(Counter);
    },

    refreshCounter() {
      var api_server = this.app_id.slice(-9) !== '-MdYXbMMI' ? this.custom_api_server : `https://${ this.app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;
      if (api_server) {
        this.fetchData(api_server);
      } else {
        fetch('https://app-router.leancloud.cn/2/route?appId=' + this.app_id)
          .then(resp => resp.json())
          .then(({api_server}) => {
            this.fetchData('https://' + api_server);
          });
      }
    }

  };

  LCCounter.refreshCounter();

  document.addEventListener('pjax:complete', function () {
    LCCounter.refreshCounter();
  });
</script>




  <script>
const rootElement = document.documentElement;
const darkModeStorageKey = "user-color-scheme";
const rootElementDarkModeAttributeName = "data-user-color-scheme";

const setLS = (k, v) => {
    localStorage.setItem(k, v);
};

const removeLS = (k) => {
    localStorage.removeItem(k);
};

const getLS = (k) => {
    return localStorage.getItem(k);
};

const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};

const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};

const validColorModeKeys = {
  dark: true,
  light: true,
};

const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);

  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};

const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};

/**
 * get target mode
 */
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);

  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};

/**
 * bind click event for toggle button
 */
function bindToggleButton() {
	var btn=$("#wrapper .toggle-mode-btn");
    btn.on('click',(e) => {
      const mode = toggleCustomDarkMode();
      applyCustomDarkModeSettings(mode);
    });
}

applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", bindToggleButton);
volantis.pjax.push(bindToggleButton);
volantis.pjax.send(()=>{
	$("#wrapper .toggle-mode-btn").unbind('click');
},'toggle-mode-btn-unbind');
</script>








<script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script>

<!-- more -->

 
	   
	    


<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          "#l_cover",
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）

      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
		// 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
		volantis.pjax.method.complete.start();
      } catch (e) {
        console.log(e);
      }
    });

    document.addEventListener('pjax:error', function (e) {
	  // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.error.start();
      window.location.href = e.triggerElement.href;
    });
</script>
 
	  
    </div>
  </body>
</html>
