<!DOCTYPE html>
<html lang="en">
  <head hexo-theme='https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.0'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <link rel="preload" href="/css/first.css" as="style">
  

  <!-- 页面元数据 -->
  
  <title>cutlass cute实现flash attention - 66Ring&#39;s Blog</title>
  
    <meta name="keywords" content="cuda,machine learning system,cutlass,mlsys">
  

  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  

  <!-- import link -->
  

  
    
<link rel="stylesheet" href="/css/first.css">

  

  
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  

  <script id="loadcss"></script>

  
<script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        '<h1><b>抱歉，您的浏览器无法访问本站</b></h1>'+
        '<h3>微软已经于2016年终止了对 Internet Explorer (IE) 10 及更早版本的支持，<br/>'+
        '继续使用存在极大的安全隐患，请使用当代主流的浏览器进行访问。</h3><br/>'+
        '<a href="https://www.microsoft.com/zh-cn/WindowsForBusiness/End-of-IE-support" target="_blank" rel="noopener"><strong>了解详情 ></strong></a>'+
    '</div>');
</script>


<noscript>
	<style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
	</style>
    <div class="kill-noscript">
        <h1><b>抱歉，您的浏览器无法访问本站</b></h1>
        <h3>本页面需要浏览器支持（启用）JavaScript</h3><br/>
        <a href="https://www.baidu.com/s?wd=启用JavaScript" target="_blank" rel="noopener"><strong>了解详情 ></strong></a>
    </div>
</noscript>

</head>

  <body>
    

<header id="l_header" class="l_header auto shadow blur show" style='opacity: 0' >
  <div class='container'>
  <div id='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h m-phone' id="pjax-header-nav-list">
        <li><a id="s-comment" class="fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a id="s-toc" class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
            <img no-lazy class='logo' src='https://raw.githubusercontent.com/66RING/66RING/master/.github/images/the_dark_side_of_the_moon_tranp.png'/>
          
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h m-pc'>
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box header toggle-mode-btn">
                  <i class='fas fa-moon fa-fw'></i>Dark Mode
                </a>
              <li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h m-phone'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box header toggle-mode-btn">
                  <i class='fas fa-moon fa-fw'></i>Dark Mode
                </a>
              <li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

    <div id="l_body">
      <div id="l_cover">
  
    
        <div id="full" class='cover-wrapper post dock' style="display: none;">
          
            <div class='cover-bg lazyload placeholder' data-bg="https://uploadbeta.com/api/pictures/random/?key=BingEverydayWallpaperPicture"></div>
          
          <div class='cover-body'>
  <div class='top'>
    
    
      <p class="title">Mens et Manus</p>
    
    
  </div>
  <div class='bottom'>
    <div class='menu navigation'>
      <div class='list-h'>
        
      </div>
    </div>
  </div>
</div>

          <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
        </div>
    
  
  </div>

      <div id="safearea">
        <div class="body-wrapper" id="pjax-container">
          

<div class='l_main'>
  <article class="article post white-box reveal md shadow article-type-post" id="post" itemscope itemprop="blogPost">
  


  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title">
        cutlass cute实现flash attention
      </h1>
      <div class='new-meta-box'>
        
          
            
<div class='new-meta-item author'>
  <a class='author' href="/" rel="nofollow">
    <img no-lazy src="">
    <p>请设置文章作者</p>
  </a>
</div>

          
        
          
            

          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：May 8, 2024</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item browse leancloud">
    <a class='notlink'>
      
      <div id="lc-pv" data-title="cutlass cute实现flash attention" data-path="/2024/05/08/universe/ml/cutlass_flash_attention_top_down/">
        <i class="fas fa-eye fa-fw" aria-hidden="true"></i>
        <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span>
        次浏览
      </div>
    </a>
  </div>


          
        
      </div>
    
  </div>


  
  
  <h1 id="用cutlass-cute实现flash-attention"><a href="#用cutlass-cute实现flash-attention" class="headerlink" title="用cutlass cute实现flash attention"></a>用cutlass cute实现flash attention</h1><p>flash attention自顶向下(虽然我学cutlass是自底向上学的但是感觉快速上手应该自顶向下学)。因为有了cutlass cute用户就可以方便的实现一些功能了, 即一些cuda编程的范式:</p>
<ul>
<li>cuda程序范式: global mem -&gt; share mem -&gt; reg -&gt; compute<ul>
<li>block tiling: <ul>
<li>aka 复用smem, gmem -&gt; smem的拷贝</li>
</ul>
</li>
<li>thread tiling:<ul>
<li>aka 复用reg, smem -&gt; reg的拷贝</li>
</ul>
</li>
<li>合并访存, 向量访存:<ul>
<li>aka 向量指令, LDSM, ldmatrix指令</li>
</ul>
</li>
<li>warp divergent线程束分化<ul>
<li>aka warp负载均衡, 同理流水线气泡问题</li>
</ul>
</li>
<li>bank conflict冲突消解: swizzle<ul>
<li>aka 利用内存的多路通道</li>
</ul>
</li>
<li>double buffering<ul>
<li>aka 加载和计算的流水线</li>
</ul>
</li>
<li>…</li>
</ul>
</li>
</ul>
<p>需要自底向上学的朋友推荐看<a href="https://www.zhihu.com/people/reed-84-49" target="_blank" rel="noopener">reed哥的系列教程</a></p>
<h2 id="flash-attention速通"><a href="#flash-attention速通" class="headerlink" title="flash attention速通"></a>flash attention速通</h2><p>TODO: 简单描述一下flash attention的本质: flash attention three easy pieces</p>
<ul>
<li>online safe softmax</li>
<li>两个gemm的融合</li>
<li>rescale的数学原理</li>
</ul>
<h2 id="自顶向下cute-flash-attention"><a href="#自顶向下cute-flash-attention" class="headerlink" title="自顶向下cute flash attention"></a>自顶向下cute flash attention</h2><p>在不考虑使用cutlass的情况下, 纯cuda应该怎么写高性能算子:</p>
<ol>
<li>多维block tiling: <ul>
<li>把数据从global memory拷贝到shared memory</li>
<li>复用smem中的数据, 减少访问gmem的此时</li>
</ul>
</li>
<li>多维thread tiling<ul>
<li>把数据从shared memory拷贝到global memory</li>
<li>复用寄存器中的数据</li>
</ul>
</li>
<li>进一步优化</li>
<li>使用向量指令异步加载<ul>
<li>LDSM</li>
<li>ldmatrix</li>
</ul>
</li>
<li>合并访存</li>
<li>bank conflict冲突消解</li>
<li>传算交叠流水线: 一边gmem -&gt; smem拷贝一边做reg的gemm计算</li>
</ol>
<p>而cutlass cute则把原本需要手写的thread协同工作的代码抽象封装好了, 如需要协同做拷贝时可以<code>make_tiled_copy</code>创建一个拷贝对象, 需要协同计算时可以用<code>TiledMMA&lt;T&gt;</code>创建mma(matrix multiply accumulate)对象来做计算。</p>
<p><strong>只需要看懂mma布局就知道thread间如何协同的</strong>, 后面<a href="#基础设施">基础设施</a>章节会介绍</p>
<h3 id="Terms-名词解释"><a href="#Terms-名词解释" class="headerlink" title="Terms 名词解释"></a>Terms 名词解释</h3><ul>
<li>命名习惯: <code>tQgQ</code><ul>
<li>看到cute的变量名可能一头雾水, 所以有必要解释一下</li>
<li>如<code>auto tQgQ = gmem_thr_copy_QKV.partition_S(gQ(_, _, 0))</code>, <code>t</code>(to)表示是给什么用的, 这里只是抽象了一层还是Q本身所以直接用tQ。<code>g</code>表示该变量的位置在global memory中</li>
<li>如<code>tSrQ</code>, <code>tSrK</code>表示是给attention <strong>S</strong>core计算使用的, 寄存器(reg)中的Q, K</li>
<li>如<code>tOrVt</code>表示是给最终output用的, 寄存器中的转置过了的V</li>
</ul>
</li>
<li>MNK矩阵乘法表述法<ul>
<li>两个矩阵相乘需要至少一个维度相同, K就表示这个相同的维度是多少</li>
<li><code>A[M, K] @ B[N, K]</code></li>
</ul>
</li>
<li>MMA(matrix multiply accumulate)<ul>
<li>简单的说就是用于表示thread tiling的规模, 即一个thread block中用多少个thread怎么计算, cute会抽象成一个个mma对象</li>
</ul>
</li>
<li>MMA描述法: 描述底层执行<code>D = AB + C</code>要使用的指令, 用户可以根据需要指定<ul>
<li>描述方法: DABC + MNK</li>
</ul>
<ul>
<li>DABC: 描述了寄存器类型, 如<code>SM75_16x8x8_F32F16F16F32_TN</code>中<code>F32F16F16F32</code>就是DABC描述。表示DABC寄存器分别是<code>F32</code>, <code>F16</code>, <code>F16</code>, <code>F32</code></li>
<li>MNK: 描述了矩阵乘法的规模, 如<code>SM75_16x8x8_F32F16F16F32_TN</code>中<code>16x8x8</code>就表示<code>D[M, N] = A[M, K] * B[N, K] + C[M, N]</code></li>
</ul>
</li>
<li>Tiled_MMA: 描述多个MMA_Atom如何协作来完成一个大任务<ul>
<li>AtomLayoutMNK: Tile内在MNK方向上重复几次Atom, <strong>通过多线程重复</strong></li>
<li>ValueLayoutMNK: Atom内在MNK方向上重复几次计算, <strong>单线程内重复计算</strong></li>
</ul>
</li>
<li>BlockM<ul>
<li>Q的分块计算的粒度</li>
</ul>
</li>
<li>BlockN<ul>
<li>KV的分块计算的粒度</li>
</ul>
</li>
</ul>
<h3 id="基础设施"><a href="#基础设施" class="headerlink" title="基础设施"></a>基础设施</h3><ul>
<li>查看MMA布局</li>
</ul>
<p>使用这个<a href="https://gist.github.com/66RING/2e188b73fdf703e9f9dfc7371814dd15" target="_blank" rel="noopener">mma布局打印脚本</a>可以打印, 使用方法如下: 修改不同mma指令<code>SM80_16x8x16_F32F16F16F32_TN</code>来测试。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="keyword">auto</span> tiled_mma = make_tiled_mma(SM80_16x8x16_F32F16F16F32_TN&#123;&#125;,</span><br><span class="line">                                  Layout&lt;Shape&lt;_1,_1, _1&gt;&gt;&#123;&#125;,  <span class="comment">// AtomLayoutMNK</span></span><br><span class="line">                                  Layout&lt;Shape&lt;_1,_2, _1&gt;&gt;&#123;&#125;   <span class="comment">// ValLayoutMNK</span></span><br><span class="line">  );</span><br><span class="line">  print_mma_content(<span class="string">"flash2: SM80_16x8x16_F32F16F16F32_TN"</span>, tiled_mma);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/mma.webp" class="lazyload" data-srcset="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/mma.webp" srcset="data:image/png;base64,666" alt=""></p>
<p>图片含义：T0, T1…表示thread，T0内V0, V1表示thread T0所负责的数据</p>
<ul>
<li>打印tensor</li>
</ul>
<p>直接使用cute提供的<code>print_tensor</code>, <code>print_layout</code>可以在命令行打印出tensor数据, 方便调试。e.g.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Convert a C pointer into cutlass Tensor</span></span><br><span class="line"><span class="comment">// with info like shape (M, K) and stride (K, 1)</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> M = <span class="number">4</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> K = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">Tensor A = make_tensor(c_host_ptr, make_shape(M, K), make_stride(K, <span class="number">1</span>));</span><br><span class="line">cute::print_tensor(A);</span><br><span class="line">cute::print_layout(A.layout());</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">ptr[32b](0x7ffe79dcbbe0) o (4,8):(8,1):</span></span><br><span class="line"><span class="comment">    0    1    2    3    4    5    6    7</span></span><br><span class="line"><span class="comment">    8    9   10   11   12   13   14   15</span></span><br><span class="line"><span class="comment">   16   17   18   19   20   21   22   23</span></span><br><span class="line"><span class="comment">   24   25   26   27   28   29   30   31</span></span><br><span class="line"><span class="comment">(4,8):(8,1)</span></span><br><span class="line"><span class="comment">       0    1    2    3    4    5    6    7 </span></span><br><span class="line"><span class="comment">    +----+----+----+----+----+----+----+----+</span></span><br><span class="line"><span class="comment"> 0  |  0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |</span></span><br><span class="line"><span class="comment">    +----+----+----+----+----+----+----+----+</span></span><br><span class="line"><span class="comment"> 1  |  8 |  9 | 10 | 11 | 12 | 13 | 14 | 15 |</span></span><br><span class="line"><span class="comment">    +----+----+----+----+----+----+----+----+</span></span><br><span class="line"><span class="comment"> 2  | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 |</span></span><br><span class="line"><span class="comment">    +----+----+----+----+----+----+----+----+</span></span><br><span class="line"><span class="comment"> 3  | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 |</span></span><br><span class="line"><span class="comment">    +----+----+----+----+----+----+----+----+</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p>使用<code>local_tile</code>打印一个tile(一个tensor切片)</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">cute::print_tensor(A);</span><br><span class="line"><span class="keyword">auto</span> A00 = local_tile(A, make_tile(<span class="number">2</span>, <span class="number">2</span>), make_coord(<span class="number">0</span>, <span class="number">0</span>));</span><br><span class="line"><span class="keyword">auto</span> A01 = local_tile(A, make_tile(<span class="number">2</span>, <span class="number">2</span>), make_coord(<span class="number">0</span>, <span class="number">1</span>));</span><br><span class="line"><span class="keyword">auto</span> A10 = local_tile(A, make_tile(<span class="number">2</span>, <span class="number">2</span>), make_coord(<span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line">cute::print_tensor(A00);</span><br><span class="line">cute::print_tensor(A01);</span><br><span class="line">cute::print_tensor(A10);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">cute::print_tensor(A);</span></span><br><span class="line"><span class="comment">ptr[32b](0x7ffc3fe94680) o (4,8):(1,4):</span></span><br><span class="line"><span class="comment">    0    4    8   12   16   20   24   28</span></span><br><span class="line"><span class="comment">    1    5    9   13   17   21   25   29</span></span><br><span class="line"><span class="comment">    2    6   10   14   18   22   26   30</span></span><br><span class="line"><span class="comment">    3    7   11   15   19   23   27   31</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">cute::print_tensor(A00);</span></span><br><span class="line"><span class="comment">ptr[32b](0x7ffc3fe94680) o (2,2):(1,4):</span></span><br><span class="line"><span class="comment">    0    4</span></span><br><span class="line"><span class="comment">    1    5</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">cute::print_tensor(A01);</span></span><br><span class="line"><span class="comment">ptr[32b](0x7ffc3fe946a0) o (2,2):(1,4):</span></span><br><span class="line"><span class="comment">    8   12</span></span><br><span class="line"><span class="comment">    9   13</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">cute::print_tensor(A10);</span></span><br><span class="line"><span class="comment">ptr[32b](0x7ffc3fe94688) o (2,2):(1,4):</span></span><br><span class="line"><span class="comment">    2    6</span></span><br><span class="line"><span class="comment">    3    7</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>


<h3 id="attention计算的线程模型"><a href="#attention计算的线程模型" class="headerlink" title="attention计算的线程模型"></a>attention计算的线程模型</h3><p>单线程的attention计算belike: <code>q[seqlen, headdim] @ k[seqlen, headdim].T @ v[seqlen, headdim]</code></p>
<p>而多线性的attention计算只需要从q的维度切分(想象成自回归场景下, 一次计算一个token的attention, 这里是并行的计算多个”单”query的attention)，每个thread负责BlockM个token的single head attention计算。即</p>
<p>如果输入的形状为<code>[bs, head, seqlen, headdim]</code>则总线程数为<code>bs x head x seqlen/BlockM</code>, 每个thread计算<code>[BlockM, headdim]</code>的query attention计算。在bs x head维度和seqlen维度都并行。</p>
<p>对应到每个独立的thread block上也是同理, 开辟<code>bs x head x seqlen/BlockM</code>个独立的线程块进行多个token的并行计算。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(ceil_div(params.seqlen, BlockM), params.bs * params.head, <span class="number">1</span>)</span></span>;</span><br></pre></td></tr></table></figure>

<p>TODO: 示意图</p>
<h3 id="二维block-tiling"><a href="#二维block-tiling" class="headerlink" title="二维block tiling"></a>二维block tiling</h3><p>flash attention 2的计算流程如下图所示, Q按inner loop顺序分别和K, V分开进行计算得到partial sum, 最后将partial sum累加得到和Q形状一样的输出。伪码描述为(先不用考虑online softmax和rescale的原理)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">flash_attention_2():</span><br><span class="line">    <span class="comment"># outter loop</span></span><br><span class="line">    parallel do q[NUM_BLOCK_M]:</span><br><span class="line">        <span class="comment"># inner loop</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_BLOCK_N):</span><br><span class="line">            qk = q @ k[i].T</span><br><span class="line">            score = online_softmax(qk)</span><br><span class="line">            out += score @ v[i]</span><br><span class="line">        rescale(out)</span><br></pre></td></tr></table></figure>

<p>你可能发现outter loop和inner loop和流传甚广的经典的flash attention那张三角形的图不一样。这是因为那张图的flash attention 1时期的实现。</p>
<p><img src="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/flash_attention2.png" class="lazyload" data-srcset="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/flash_attention2.png" srcset="data:image/png;base64,666" alt=""></p>
<p>利用cute的api可以快速制造q, k, v分块:</p>
<ol>
<li>用<code>make_tensor()</code>把裸指针封装成tensor方便后续操作</li>
<li>使用<code>local_tile(tensor, tile, coord)</code>从tensor中取出一组/一个分块</li>
<li>创建<code>Copy_Atom</code>拷贝对象实现global memory到shared memory的数据拷贝, 简单易用的多维block tiling</li>
</ol>
<p>首先使用<code>make_tensor</code>API可以把传入的裸指针转换成更方便使用的Tensor。这里把完整<code>seqlen x dim</code>的QKV对象创建了出来，方便后面使用cute的API做<code>q_slice[i++]</code>之类的操作。不用担心<code>make_tensor</code>会产生额外的开销, 因为它不会。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dim3 grid(ceil_div(params.seqlen, BlockM), params.bs * params.head, 1);</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> m_block = blockIdx.x;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> bs_head_offset = blockIdx.y * params.seqlen * params.dim;</span><br><span class="line"></span><br><span class="line">Tensor Q = make_tensor(</span><br><span class="line">    make_gmem_ptr(<span class="keyword">reinterpret_cast</span>&lt;Element *&gt;(params.q_ptr) + bs_head_offset),</span><br><span class="line">    make_shape(params.seqlen, params.dim),</span><br><span class="line">    make_stride(params.dim, Int&lt;<span class="number">1</span>&gt;&#123;&#125;));</span><br><span class="line">Tensor K = make_tensor(</span><br><span class="line">    make_gmem_ptr(<span class="keyword">reinterpret_cast</span>&lt;Element *&gt;(params.k_ptr) + bs_head_offset),</span><br><span class="line">    make_shape(params.seqlen, params.dim),</span><br><span class="line">    make_stride(params.dim, Int&lt;<span class="number">1</span>&gt;&#123;&#125;));</span><br><span class="line">Tensor V = make_tensor(</span><br><span class="line">    make_gmem_ptr(<span class="keyword">reinterpret_cast</span>&lt;Element *&gt;(params.v_ptr) + bs_head_offset),</span><br><span class="line">    make_shape(params.seqlen, params.dim),</span><br><span class="line">    make_stride(params.dim, Int&lt;<span class="number">1</span>&gt;&#123;&#125;));</span><br></pre></td></tr></table></figure>

<p>根据block id加载thread block对应的qkv分块。<code>local_tile(tensor, tile, coord)</code>可以把tensor抽象成由多个tile组成的数组(可以多多维), 然后使用coord去索引取出需要的部分。这里取出了当前thread block负责的Q分块，并取出第一个kv分块做后续”传算交叠流水线”的prefill.</p>
<p>因为这里Q的shape是<code>seqlen, kHeadDim</code>, 所以拆分成多个<code>[kBlockM, kHeadDim]</code>的块后可索引的coord为<code>[seqlen/kBlockM, kHeadDim/kHeadDim]</code>。取出<code>[m_block, _]</code>, 相当于python中的<code>[m_block, :]</code>这样的索引方式, 其中<code>m_block</code>索引维度的会被squeeze, 而<code>_</code>索引的维度会保留。所以最终的shape为<code>(kBlockM, kHeadDim, num_tile_n=1)</code></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 加载Q, K, V分块</span></span><br><span class="line"><span class="comment">// (kBlockM, kHeadDim, num_tile_n)</span></span><br><span class="line">Tensor gQ = local_tile(Q, make_tile(Int&lt;kBlockM&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(m_block, _));</span><br><span class="line"></span><br><span class="line"><span class="comment">// (kBlockN, kHeadDim, num_tile_n)</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> loading流水线, 初次加载所需K, V</span></span><br><span class="line">Tensor gK = local_tile(K, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(<span class="number">0</span>, _));</span><br><span class="line">Tensor gV = local_tile(V, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(<span class="number">0</span>, _));</span><br></pre></td></tr></table></figure>

<p><strong>将数据从global memory拷贝到shared memory来做多维的block tiling</strong>: 定义从global memory到share memory拷贝的对象, 这样可以减少用户直接使用gpu指令。具体拷贝对象怎么构造后续再说, 简单的说就是使用一个config来配置用什么方法拷贝(异步的, 向量的)。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Construct SMEM tensors.</span></span><br><span class="line">Tensor sQ = make_tensor(make_smem_ptr(shared_storage.smem_q.data()), SmemLayoutQ&#123;&#125;);</span><br><span class="line">Tensor sK = make_tensor(make_smem_ptr(shared_storage.smem_k.data()), SmemLayoutK&#123;&#125;);</span><br><span class="line">Tensor sV = make_tensor(make_smem_ptr(shared_storage.smem_v.data()), SmemLayoutV&#123;&#125;);</span><br><span class="line"><span class="comment">// Tensor for V Transpose; used in GEMM-II.</span></span><br><span class="line">Tensor sVt = make_tensor(make_smem_ptr(shared_storage.smem_v.data()), SmemLayoutVt&#123;&#125;);</span><br><span class="line">Tensor sVtNoSwizzle = make_tensor(make_smem_ptr(shared_storage.smem_v.data()), SmemLayoutVtNoSwizzle&#123;&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> 定义gmem -&gt; smem拷贝的src, dst</span></span><br><span class="line">Tensor tQgQ = gmem_thr_copy_QKV.partition_S(gQ(_, _, <span class="number">0</span>));</span><br><span class="line">Tensor tQsQ = gmem_thr_copy_QKV.partition_D(sQ);</span><br><span class="line">Tensor tKgK = gmem_thr_copy_QKV.partition_S(gK(_, _, <span class="number">0</span>));</span><br><span class="line">Tensor tKsK = gmem_thr_copy_QKV.partition_D(sK);</span><br><span class="line">Tensor tVgV = gmem_thr_copy_QKV.partition_S(gV(_, _, <span class="number">0</span>));</span><br><span class="line">Tensor tVsV = gmem_thr_copy_QKV.partition_D(sV);</span><br></pre></td></tr></table></figure>

<p>其中, <code>gmem_thr_copy_QKV.partition_S()</code>创建拷贝的源地址对象, <code>gmem_thr_copy_QKV.partition_D()</code>创建拷贝的目标地址对象。因为gQ我们在创建分块时第二个维度用满了, 所以<code>make_coord(m_block, _)</code>提取出来也只有一个元素, 直接用<code>0</code>索引掉。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; tQgQ: tQ: 用于(t)表示&#x2F;计算Q. gQ: 是global memory上的数据</span><br><span class="line">&#x2F;&#x2F; tQsQ: tQ: 用于(t)表示&#x2F;计算Q. sQ: 是shared memory上的数据</span><br></pre></td></tr></table></figure>

<p>然后使用API即可实现一个多维数据的拷贝。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> gmem_tiled_copy_QKV为cute抽象出来的拷贝对象Copy_Atom, 表示用一组thread来做拷贝</span></span><br><span class="line">cute::copy(gmem_tiled_copy_QKV, tQgQ, tQsQ);</span><br><span class="line"><span class="comment">// 开始执行异步拷贝</span></span><br><span class="line">cute::cp_async_fence();</span><br></pre></td></tr></table></figure>

<p>具体<code>gmem_thr_copy_QKV</code>拷贝对象的构造方法后面再说, 只需要传入一个异步拷贝的参数和规模布局即可用上向量指令做异步拷贝。</p>
<blockquote>
<p>这是不是比手写gpu指令的block tiling各种拷贝简单多了:</p>
</blockquote>
<h3 id="二维thread-tiling"><a href="#二维thread-tiling" class="headerlink" title="二维thread tiling"></a>二维thread tiling</h3><p>本章节开始进入inner loop部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">flash_attention_2():</span><br><span class="line">    <span class="comment"># outter loop</span></span><br><span class="line">    parallel do q[NUM_BLOCK_M]:</span><br><span class="line">        <span class="comment"># inner loop</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_BLOCK_N):</span><br><span class="line">            qk = q @ k[i].T</span><br><span class="line">            score = online_softmax(qk)</span><br><span class="line">            out += score @ v[i]</span><br><span class="line">        rescale(out)</span><br></pre></td></tr></table></figure>

<p>整体流程如下</p>
<ol>
<li>pipeline prefill: load(q), load(k[0])</li>
<li>pipeline start</li>
<li>async_load(next(v)) &amp;&amp; compute q @ k.T</li>
<li>softmax(qk)</li>
<li>async_load(next(k)) &amp;&amp; compute qk @ v</li>
<li>pipeline finish</li>
<li>rescale</li>
</ol>
<p>其中做gemm计算时都会从smem拷贝多维的数据到寄存器中做一个thread tiling。thread tiling可以复用已经拷贝到寄存器的数据，减少smem到reg拷贝的次数。如下图所示, 当gemm计算第0行时, BX0和A0X计算完成后, BX1可以直接利用已经在寄存器的A0X而不用再次做smem到reg的加载。</p>
<p><img src="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/thread_tiling.png" class="lazyload" data-srcset="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/thread_tiling.png" srcset="data:image/png;base64,666" alt=""></p>
<p>从gemm的角度出发看多维thread tiling的实现。使用<code>cute::copy</code>把smem中的数据<code>tCsA</code>拷贝到寄存器中<code>tCrA</code>后直接使用<code>cute::gemm</code>做多维thread tiling的gemm计算。具体thread tiling的布局通过可以通过<a href="#基础设施">打印mma</a>查看。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Tensor0, <span class="keyword">typename</span> Tensor1,</span><br><span class="line">         <span class="keyword">typename</span> Tensor2, <span class="keyword">typename</span> Tensor3, <span class="keyword">typename</span> Tensor4,</span><br><span class="line">         <span class="keyword">typename</span> TiledMma, <span class="keyword">typename</span> TiledCopyA, <span class="keyword">typename</span> TiledCopyB,</span><br><span class="line">         <span class="keyword">typename</span> ThrCopyA, <span class="keyword">typename</span> ThrCopyB&gt;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> __device__ <span class="keyword">void</span> <span class="title">gemm_smem</span><span class="params">(Tensor0 &amp;acc, Tensor1 &amp;tCrA, Tensor2 &amp;tCrB, Tensor3 <span class="keyword">const</span>&amp; tCsA,</span></span></span><br><span class="line"><span class="function"><span class="params">                            Tensor4 <span class="keyword">const</span>&amp; tCsB, TiledMma tiled_mma,</span></span></span><br><span class="line"><span class="function"><span class="params">                            TiledCopyA smem_tiled_copy_A, TiledCopyB smem_tiled_copy_B,</span></span></span><br><span class="line"><span class="function"><span class="params">                            ThrCopyA smem_thr_copy_A, ThrCopyB smem_thr_copy_B)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> 构造smem -&gt; reg拷贝的目的地址寄存器对象</span></span><br><span class="line">    Tensor tCrA_copy_view = smem_thr_copy_A.retile_D(tCrA);</span><br><span class="line">    Tensor tCrB_copy_view = smem_thr_copy_B.retile_D(tCrB);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> s -&gt; reg</span></span><br><span class="line">    cute::copy(smem_tiled_copy_A, tCsA(_, _, _0&#123;&#125;), tCrA_copy_view(_, _, _0&#123;&#125;));</span><br><span class="line">    cute::copy(smem_tiled_copy_B, tCsB(_, _, _0&#123;&#125;), tCrB_copy_view(_, _, _0&#123;&#125;));</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size&lt;<span class="number">2</span>&gt;(tCrA); ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i &lt; size&lt;<span class="number">2</span>&gt;(tCrA) - <span class="number">1</span>) &#123;</span><br><span class="line">            cute::copy(smem_tiled_copy_A, tCsA(_, _, i + <span class="number">1</span>), tCrA_copy_view(_, _, i + <span class="number">1</span>));</span><br><span class="line">            cute::copy(smem_tiled_copy_B, tCsB(_, _, i + <span class="number">1</span>), tCrB_copy_view(_, _, i + <span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        cute::gemm(tiled_mma, tCrA(_, _, i), tCrB(_, _, i), acc);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>for循环前先做一次<code>cute::copy</code>是为了构造传算交叠(communication compute overlap)的流水线。即做smem-&gt;reg拷贝的同时做gemm。</p>
<p>回到cutlass flash attention的代码。使用cute提供的API构造gemm需要的寄存器对象。TODO: 具体<code>SmemCopyAtom</code>拷贝对象的构造方法后面再说, 只需要传入一个异步拷贝的参数和规模布局即可。</p>
<p>使用<code>partition_fragment_A</code>, <code>partition_fragment_B</code>, <code>partition_fragment_C</code>创建寄存器对象, 准备做thread tiling: 把数据从smem拷贝到reg, 并利用reg中的数据做矩阵乘法。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> 定义smem -&gt; reg拷贝的dst</span></span><br><span class="line"><span class="comment">// partition_fragment与partition类似, 只是返回的是寄存器表示</span></span><br><span class="line">Tensor tSrQ  = thr_mma.partition_fragment_A(sQ); <span class="comment">// (MMA,MMA_M,MMA_K)</span></span><br><span class="line">Tensor tSrK  = thr_mma.partition_fragment_B(sK); <span class="comment">// (MMA,MMA_N,MMA_K)</span></span><br><span class="line">Tensor tOrVt  = thr_mma.partition_fragment_B(sVtNoSwizzle); <span class="comment">// (MMA, MMA_K,MMA_N)</span></span><br><span class="line"><span class="comment">// 创建输出的累加器accumulator output</span></span><br><span class="line">Tensor rAccOut = partition_fragment_C(tiled_mma, Shape&lt;Int&lt;kBlockM&gt;, Int&lt;kHeadDim&gt;&gt;&#123;&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> 准备拷贝Q, K, V到smem的copy对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建smem -&gt; reg的拷贝对象</span></span><br><span class="line"><span class="keyword">auto</span> smem_tiled_copy_Q = make_tiled_copy_A(<span class="keyword">typename</span> Kernel_traits::SmemCopyAtom&#123;&#125;, tiled_mma);</span><br><span class="line"><span class="comment">// 根据thread id找到当前thread负责的部分</span></span><br><span class="line"><span class="keyword">auto</span> smem_thr_copy_Q = smem_tiled_copy_Q.get_thread_slice(tidx);</span><br><span class="line"><span class="comment">// 用partition_S创建smem -&gt; reg的源地址对象</span></span><br><span class="line">Tensor tSsQ = smem_thr_copy_Q.partition_S(sQ);</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>inner loop部分代码如下。其中, 创建<code>auto rAccScore = partition_fragment_C()</code>来<strong>融合两个gemm</strong>: <code>score = q@k.T</code>的gemm和<code>out = score @ v</code>的gemm。</p>
<p>需要注意<strong>融合两个gemm的坑点</strong>, 因为要融合两个gemm, gemm-I的输出<code>score = q@k.T</code>要作为第二个gemm-II的输入<code>out = score @ v</code>, 所以<strong>gemm-I的输出C layout需要和gemm-II的输入A layout一致</strong>才能直接使用。通过打印mma指令发现<code>SM80_16x8x16_F32F16F16F32_TN</code>就符合这种要求。</p>
<p><img src="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/mma.webp" class="lazyload" data-srcset="https://raw.githubusercontent.com/66RING/66RING/master/.github/images/Notes/universe/ml/cutlass_flash_attention_top_down/mma.webp" srcset="data:image/png;base64,666" alt=""></p>
<p><a href="https://github.com/ColfaxResearch/cutlass-kernels/blob/c796d779c9991213252e9f0a07e5516c8d829e3f/src/fmha/fmha_forward.cu#L114">ColfaxResearch的实现</a>似乎不用考虑这点, 用<code>rs_op_selector</code>和<code>ss_op_selector</code>两个API就把MMA配置好了。如果有人知道是怎么回事pls let me know.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">flash_attention_2():</span></span><br><span class="line"><span class="comment">    # outter loop</span></span><br><span class="line"><span class="comment">    parallel do q[NUM_BLOCK_M]:</span></span><br><span class="line"><span class="comment">        # inner loop</span></span><br><span class="line"><span class="comment">        for i in range(NUM_BLOCK_N):</span></span><br><span class="line"><span class="comment">            qk = q @ k[i].T</span></span><br><span class="line"><span class="comment">            score = online_softmax(qk)</span></span><br><span class="line"><span class="comment">            out += score @ v[i]</span></span><br><span class="line"><span class="comment">        rescale(out)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> nbi = n_block_min; nbi &lt; n_block_max; nbi++) &#123;</span><br><span class="line">    <span class="keyword">auto</span> rAccScore = partition_fragment_C(tiled_mma, make_shape(Int&lt;kBlockM&gt;&#123;&#125;, Int&lt;kBlockN&gt;&#123;&#125;));</span><br><span class="line"></span><br><span class="line">    clear(rAccScore);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待Q, K的gmem -&gt; smem拷贝完成, 即Q, K就绪</span></span><br><span class="line">    <span class="comment">// wait&lt;0&gt;表示等待还剩0个未完成</span></span><br><span class="line">    flash::cp_async_wait&lt;<span class="number">0</span>&gt;();</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// gemm的同时异步加载V</span></span><br><span class="line">    gV = local_tile(V, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi, _));</span><br><span class="line">    tVgV = gmem_thr_copy_QKV.partition_S(gV(_, _, <span class="number">0</span>));</span><br><span class="line">    <span class="comment">// 异步加载V到smem</span></span><br><span class="line">    flash::copy(gmem_tiled_copy_QKV, tVgV, tVsV);</span><br><span class="line">    <span class="comment">// 发起异步拷贝</span></span><br><span class="line">    cute::cp_async_fence();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// O = Q@K.T</span></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> 加载smem中的数据到reg再做gemm, **加载期间执行retile**</span></span><br><span class="line">    flash::gemm_smem(rAccScore, tSrQ, tSrK, tSsQ, tSsK, tiled_mma, smem_tiled_copy_Q, smem_tiled_copy_K,</span><br><span class="line">        smem_thr_copy_Q, smem_thr_copy_K</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    Tensor scores = make_tensor(rAccScore.data(), flash::convert_layout_acc_rowcol(rAccScore.layout()));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> 2. mask within N BLOCKs</span></span><br><span class="line">    <span class="keyword">if</span> (Is_causal ==  <span class="literal">true</span> &amp;&amp; nbi * kBlockN &gt;= seqlen_start) &#123;</span><br><span class="line">      flash::mask_within_nblock&lt;kBlockM, kBlockN, kNWarps&gt;(scores, m_block, nbi);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> 等待V加载完成, 为下个K加载准备初始状态</span></span><br><span class="line">    flash::cp_async_wait&lt;<span class="number">0</span>&gt;();</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// advance K</span></span><br><span class="line">    <span class="keyword">if</span> (nbi != n_block_max - <span class="number">1</span>) &#123;</span><br><span class="line">      gK = local_tile(K, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi + <span class="number">1</span>, _));</span><br><span class="line">      tKgK = gmem_thr_copy_QKV.partition_S(gK(_, _, <span class="number">0</span>));</span><br><span class="line">      flash::copy(gmem_tiled_copy_QKV, tKgK, tKsK);</span><br><span class="line">      cute::cp_async_fence();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算softmax</span></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> rAccOut记录softmax后所有的分子</span></span><br><span class="line">    nbi == <span class="number">0</span> ? flash::softmax_rescale_o&lt;<span class="comment">/*Is_first=*/</span><span class="literal">true</span>&gt;(scores, scores_max, scores_sum, rAccOut, params.softmax_scale) :</span><br><span class="line">      flash::softmax_rescale_o&lt;<span class="comment">/*Is_first=*/</span><span class="literal">false</span>&gt;(scores, scores_max, scores_sum, rAccOut, params.softmax_scale);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 实际执行QK @ V</span></span><br><span class="line">    <span class="comment">// (score AKA rAccScore): QK[M, N] @ V[N, dim]</span></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> DABC: F32F16F16F32, convert D type(F32) to A type(F16)</span></span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> convert_type目前写死</span></span><br><span class="line">    Tensor rP = flash::convert_type_f32_to_f16(rAccScore);</span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> Convert from layout C to layout A</span></span><br><span class="line">    Tensor tOrP = make_tensor(rP.data(), flash::convert_layout_rowcol_Aregs&lt;TiledMMA&gt;(scores.layout()));</span><br><span class="line"></span><br><span class="line">    flash::gemm_A_in_regs(rAccOut, tOrP, tOrVt, tOsVt, tiled_mma, smem_tiled_copy_V, smem_thr_copy_V);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>伪码和代码的对应情况如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inner loop</span></span><br><span class="line"><span class="keyword">for</span> nbi <span class="keyword">in</span> range(NUM_BLOCK_N):</span><br><span class="line">    <span class="comment"># k[nbi]: gK = local_tile(K, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi + 1, _));</span></span><br><span class="line">    qk = q @ k[nbi].T <span class="comment"># flash::gemm_smem()</span></span><br><span class="line">    score = online_softmax(qk) <span class="comment"># softmax_rescale_o()</span></span><br><span class="line">    <span class="comment"># v[nbi]: gV = local_tile(V, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi, _));</span></span><br><span class="line">    out += score @ v[nbi] <span class="comment"># gemm_A_in_regs()</span></span><br></pre></td></tr></table></figure>

<h3 id="传算交叠流水线"><a href="#传算交叠流水线" class="headerlink" title="传算交叠流水线"></a>传算交叠流水线</h3><ul>
<li>异步拷贝</li>
</ul>
<p>创建gmem到smem的拷贝对象时使用<code>SM80_CP_ASYNC_CACHEGLOBAL</code>指令来创建异步拷贝的Copy atom对象。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> Gmem_copy_struct = <span class="built_in">std</span>::<span class="keyword">conditional_t</span>&lt;</span><br><span class="line">    Has_cp_async,</span><br><span class="line">    SM80_CP_ASYNC_CACHEGLOBAL&lt;cute::<span class="keyword">uint128_t</span>&gt;,</span><br><span class="line">    DefaultCopy</span><br><span class="line">&gt;;</span><br><span class="line"><span class="keyword">using</span> GmemTiledCopyQKV = <span class="keyword">decltype</span>(</span><br><span class="line">    make_tiled_copy(Copy_Atom&lt;Gmem_copy_struct, Element&gt;&#123;&#125;,</span><br><span class="line">                    GmemLayoutAtom&#123;&#125;,</span><br><span class="line">                    Layout&lt;Shape&lt;_1, _8&gt;&gt;&#123;&#125;));  <span class="comment">// Val layout, 8 vals per read</span></span><br></pre></td></tr></table></figure>


<ul>
<li>流水线</li>
</ul>
<p>伪码描述如下, 计算q@k时可以加载v, 计算qk@v时加载下一次迭代需要的k。目前只是用double buffering的方式预取1个kv. 如果每次预取多个kv还需要考虑smem大小对性能的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inner loop</span></span><br><span class="line">async_load(k[<span class="number">0</span>]) <span class="comment"># k[nbi]: gK = local_tile(K, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi + 1, _));</span></span><br><span class="line"><span class="keyword">for</span> nbi <span class="keyword">in</span> range(NUM_BLOCK_N):</span><br><span class="line">    <span class="comment"># 加载v的同时计算q@k</span></span><br><span class="line">    async_load(v[nbi]) <span class="comment"># v[nbi]: gV = local_tile(V, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi, _));</span></span><br><span class="line">    qk = q @ k[nbi].T <span class="comment"># flash::gemm_smem()</span></span><br><span class="line">    score = online_softmax(qk) <span class="comment"># softmax_rescale_o()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算qk @ v的同时加载下一次迭代需要的k</span></span><br><span class="line">    async_load(k[nbi]) <span class="comment"># k[nbi]: gK = local_tile(K, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi + 1, _));</span></span><br><span class="line">    out += score @ v[nbi] <span class="comment"># gemm_A_in_regs()</span></span><br></pre></td></tr></table></figure>

<p>在cutlass cute中使用也很简单, 构造好异步拷贝对象后发起异步拷贝即可。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// gemm的同时异步加载V</span></span><br><span class="line">gV = local_tile(V, make_tile(Int&lt;kBlockN&gt;&#123;&#125;, Int&lt;kHeadDim&gt;&#123;&#125;), make_coord(nbi, _));</span><br><span class="line">tVgV = gmem_thr_copy_QKV.partition_S(gV(_, _, <span class="number">0</span>));</span><br><span class="line"><span class="comment">// 异步加载V到smem</span></span><br><span class="line">flash::copy(gmem_tiled_copy_QKV, tVgV, tVsV);</span><br><span class="line"><span class="comment">// 发起异步拷贝</span></span><br><span class="line">cute::cp_async_fence();</span><br><span class="line"></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> 拷贝的同时执行gemm</span></span><br><span class="line"><span class="comment">// O = Q@K.T</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> 加载smem中的数据到reg再做gemm, **加载期间执行retile**</span></span><br><span class="line">flash::gemm_smem(rAccScore, tSrQ, tSrK, tSsQ, tSsK, tiled_mma, smem_tiled_copy_Q, smem_tiled_copy_K,</span><br><span class="line">    smem_thr_copy_Q, smem_thr_copy_K</span><br><span class="line">);</span><br></pre></td></tr></table></figure>


<h3 id="其他细节"><a href="#其他细节" class="headerlink" title="其他细节"></a>其他细节</h3><ul>
<li>causal模式的提前返回<ul>
<li>block间早退</li>
<li><strong>block内mask</strong>: thread在mma中的定位</li>
</ul>
</li>
<li>结果拷贝回global memory返回<ul>
<li>同样利用smem, 先从reg拷贝到smem再从smem拷贝到gmem</li>
<li>这样可以用更大的位宽</li>
</ul>
</li>
<li>online safe softmax</li>
<li>pybind和模板展开<ul>
<li>官方实现用了很多模板，本质就是1. 枚举所有可能的分块策略 2. 每个config写一个文件加速编译 3. 每个模板写个文件微调最佳config</li>
<li>python中接入cpp代码可以看这个<a href="https://github.com/66RING/pytorch-cuda-binding-tutorial">仓库</a></li>
</ul>
</li>
</ul>
<p>后面再展开补充，感兴趣的朋友可以先看源码注释。</p>
<h3 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h3><ul>
<li>bank conflict重复避免<ul>
<li>swizzle</li>
<li>cutlass cute封装好了用swizzle解决bank conflict, 在创建拷贝对象时使用即可</li>
</ul>
</li>
<li>转置优化<ul>
<li>拷贝时直接拷贝到转换后的目标地址, 从而不必开辟新的空间</li>
<li>创建拷贝对象时, 配置布局时把dst的布局转置掉即可</li>
</ul>
</li>
<li><a href="https://developer.nvidia.com/blog/faster-parallel-reductions-kepler/" target="_blank" rel="noopener">高性能的reduce实现</a><ul>
<li>优化线程束分化问题(warp divergent)</li>
</ul>
</li>
</ul>
<p>TODO: 细节展开</p>
<h3 id="稍微一点自底向上"><a href="#稍微一点自底向上" class="headerlink" title="稍微一点自底向上"></a>稍微一点自底向上</h3><blockquote>
<p>深入的自底向上可以看<a href="https://www.zhihu.com/people/reed-84-49" target="_blank" rel="noopener">reed哥的系列教程</a></p>
</blockquote>
<p>TODO: 挑选几个重要的</p>
<h3 id="主要坑点"><a href="#主要坑点" class="headerlink" title="主要坑点"></a>主要坑点</h3><ul>
<li>两个gemm的融合的layout问题: gemm-I, gemm-II<ul>
<li>输入输出的布局比较讲究: gemm-I的输出C layout要和gemm-II的输入A layout一致</li>
</ul>
</li>
</ul>

  
  
    
    <div class='footer'>
      
      
      
        <div class='copyright'>
          <blockquote>
            
              
                <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

              
            
              
                <p>本文永久链接是：<a href=http://github.com/66ring/2024/05/08/universe/ml/cutlass_flash_attention_top_down/>http://github.com/66ring/2024/05/08/universe/ml/cutlass_flash_attention_top_down/</a></p>
              
            
          </blockquote>
        </div>
      
      
    </div>
  
  
    


  <div class='article-meta' id="bottom">
    <div class='new-meta-box'>
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/cuda/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>cuda</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/machine-learning-system/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>machine learning system</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/cutlass/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>cutlass</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/mlsys/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>mlsys</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
    
      
    
  </div>
</div>



        
      
    </div>
  </div>


  
  

  
    <div class="prev-next">
      
        <a class='prev' href='/2024/05/10/universe/ml/mixtral_moe_impl/'>
          <p class='title'><i class="fas fa-chevron-left" aria-hidden="true"></i>Mixtral MoE源码笔记</p>
          <p class='content'>Mixtral MoE源码笔记
transformers/src/transformers/models/mixtral/modeling_mixtral.py
注意是mixtral不是mist...</p>
        </a>
      
      
        <a class='next' href='/2024/05/08/universe/ml/deepseek-v2-cheasheet/'>
          <p class='title'>DeepSeek-V2架构<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
          <p class='content'>DeepSeek-V2架构
简单的说MLA + MoE

参数嵌入更快: 利用类似lora的技术1234567891011self.q_a_proj = nn.Linear(    self.h...</p>
        </a>
      
    </div>
  
</article>


  

  <article class="post white-box reveal shadow" id="comments">
    <p ct><i class='fas fa-comments'></i> 评论</p>
    
    <div id="valine_container" class="valine_thread">
  <i class="fas fa-cog fa-spin fa-fw fa-2x"></i>
</div>

  </article>





  <script>
  // https://github.com/theme-next/hexo-theme-next/blob/master/layout/_third-party/math/mathjax.swig
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.0/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    // 文章章节标题不能为 “MathJax” ，否则会报错。
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



</div>
<aside class='l_side'>
  
  
    
    



  <section class="widget toc-wrapper shadow desktop mobile" id="toc-div" >
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#flash-attention速通"><span class="toc-text">flash attention速通</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自顶向下cute-flash-attention"><span class="toc-text">自顶向下cute flash attention</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Terms-名词解释"><span class="toc-text">Terms 名词解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基础设施"><span class="toc-text">基础设施</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#attention计算的线程模型"><span class="toc-text">attention计算的线程模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二维block-tiling"><span class="toc-text">二维block tiling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二维thread-tiling"><span class="toc-text">二维thread tiling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#传算交叠流水线"><span class="toc-text">传算交叠流水线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其他细节"><span class="toc-text">其他细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其他优化"><span class="toc-text">其他优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#稍微一点自底向上"><span class="toc-text">稍微一点自底向上</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#主要坑点"><span class="toc-text">主要坑点</span></a></li></ol></li></ol>
    </div>
  </section>


  


</aside>



		  
		  <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="cutlass cute实现flash attention";
  pdata.commentPath="";
  pdata.commentPlaceholder="";

  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
</script>

        </div>
        
  
  <footer class="footer clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
          
            
          
            
          
        </div>
      
    
      
        <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
      
    
      
        
          <div><p><span id="lc-sv">本站总访问量为 <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span> 次</span> <span id="lc-uv">访客数为 <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span> 人</span></p>
</div>
        
      
    
      
        Use
        <a href="https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.0" target="_blank" class="codename">Volantis</a>
        as theme
      
    
      
        <div class='copyright'>
        <p><a href="/">Copyright © 2017-2020 XXX</a></p>

        </div>
      
    
  </footer>


        <a id="s-top" class="fas fa-arrow-up fa-fw" href="javascript:void(0)"></a>
      </div>
    </div>
    <div>
      <script>
/************这个文件存放不需要重载的全局变量和全局函数*********/
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/******************** Pjax ********************************/
function VPjax(){
	this.list=[] // 存放回调函数
	this.start=()=>{
	  for(var i=0;i<this.list.length;i++){
		this.list[i].run();
	  }
	}
	this.push=(fn,name)=>{
		var f=new PjaxItem(fn,name);
		this.list.push(f);
	}
	// 构造一个可以run的对象
	function PjaxItem(fn,name){
		// 函数名称
		this.name = name || fn.name
		// run方法
		this.run=()=>{
			fn()
		}
	}
}
volantis.pjax={}
volantis.pjax.method={
	complete: new VPjax(),
	error: new VPjax(),
	send: new VPjax()
}
volantis.pjax={
	...volantis.pjax,
	push: volantis.pjax.method.complete.push,
	error: volantis.pjax.method.error.push,
	send: volantis.pjax.method.send.push
}
/********************脚本懒加载函数********************************/
// 已经加入了setTimeout
function loadScript(src, cb) {
	setTimeout(function() {
		var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
		var script = document.createElement('script');
		script.setAttribute('type','text/javascript');
		if (cb) script.onload = cb;
		script.setAttribute('src', src);
		HEAD.appendChild(script);
	});
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script>
<script>
  
  loadCSS("https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14/css/all.min.css", window.volantis.loadcss);
  
  
  
  
</script>
<!-- required -->

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js"></script>

<script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
  };
  $(function () {
    SCload_fancybox();
  });
  function Pjax_SCload_fancybox(){
	if (typeof $.fancybox == "undefined") {
	 SCload_fancybox();
    } else {
	 pjax_fancybox();
    }
  }
  volantis.pjax.push(Pjax_SCload_fancybox)
  volantis.pjax.send(()=>{
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
  },'fancybox')
</script>


<!-- internal -->




<script>
  function loadIssuesJS() {
    if ($(".md").find(".issues-api").length == 0) return;
	
	  loadScript('/js/issues.js');
	
  };
  $(function () {
    loadIssuesJS();
  });
  volantis.pjax.push(()=>{
	if (typeof IssuesAPI == "undefined") {
	  loadIssuesJS();
	}
  },"IssuesJS")
</script>



  <script defer src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  

<script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: [],
	maxRPS: 5,
	hoverDelay: 25
  };
</script>
<script defer src="https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"></script>











  
  
<script src="/js/valine.js"></script>


<script>
  function emoji(path, idx, ext) {
    return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  function pjax_valine() {
    if(!document.querySelectorAll("#valine_container")[0])return;
    let pagePlaceholder = pdata.commentPlaceholder || "快来评论吧~";
    let path = pdata.commentPath;
    if (path.length == 0) {
      let defaultPath = '';
      path = defaultPath || decodeURI(window.location.pathname);
    }
    var valine = new Valine();
    valine.init(Object.assign({"path":null,"placeholder":"快来评论吧~","appId":"EKmusUsvxKTWym4LJnmkk1eU-gzGzoHsz","appKey":"sdWXsEnYQvIqRVoEPSMsLCr6","meta":["nick","mail","link"],"requiredFields":["nick","mail"],"enableQQ":true,"recordIP":false,"avatar":"robohash","pageSize":10,"lang":"zh-cn","highlight":true,"mathJax":false}, {
      el: '#valine_container',
      path: path,
      placeholder: pagePlaceholder,
      emojiCDN: 'https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/',
      emojiMaps: emojiMaps,
    }))
  }
  $(function () {
    pjax_valine();
  });
  volantis.pjax.push(pjax_valine);
</script>






  
<script src="/js/app.js"></script>



<!-- optional -->

  <script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
}
</script>











  <script defer>

  const LCCounter = {
    app_id: 'u9j57bwJod4EDmXWdxrwuqQT-MdYXbMMI',
    app_key: 'jfHtEKVE24j0IVCGHbvuFClp',
    custom_api_server: '',

    // 查询存储的记录
    getRecord(Counter, url, title) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({url})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {url, title: title, times: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    },

    // 发起自增请求
    increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    },

    // 构建自增请求体
    buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "times": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    },

    // 校验是否为有效的 UV
    validUV() {
      var key = 'LeanCloudUVTimestamp';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    },

    addCount(Counter) {
      var enableIncr = '' === 'true' && window.location.hostname !== 'localhost';
      enableIncr = true;
      var getterArr = [];
      var incrArr = [];
      // 请求 PV 并自增
      var pvCtn = document.querySelector('#lc-sv');
      if (pvCtn || enableIncr) {
        var pvGetter = this.getRecord(Counter, 'http://github.com/66ring' + '/#lc-sv', 'Visits').then((record) => {
          incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-sv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + 1;
              if (pvCtn) {
                pvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#lc-uv');
      if (uvCtn || enableIncr) {
        var uvGetter = this.getRecord(Counter, 'http://github.com/66ring' + '/#lc-uv', 'Visitors').then((record) => {
          var vuv = this.validUV();
          vuv && incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-uv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + (vuv ? 1 : 0);
              if (uvCtn) {
                uvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(uvGetter);
      }

      // 请求文章的浏览数，如果是当前页面就自增
      var allPV = document.querySelectorAll('#lc-pv');
      if (allPV.length > 0 || enableIncr) {
        for (i = 0; i < allPV.length; i++) {
          let pv = allPV[i];
          let title = pv.getAttribute('data-title');
          var url = 'http://github.com/66ring' + pv.getAttribute('data-path');
          if (url) {
            var viewGetter = this.getRecord(Counter, url, title).then((record) => {
              // 是当前页面就自增
              let curPath = window.location.pathname;
              if (curPath.includes('index.html')) {
                curPath = curPath.substring(0, curPath.lastIndexOf('index.html'));
              }
              if (pv.getAttribute('data-path') == curPath) {
                incrArr.push(this.buildIncrement(record.objectId));
              }
              if (pv) {
                var ele = pv.querySelector('#lc-pv #number');
                if (ele) {
                  if (pv.getAttribute('data-path') == curPath) {
                    ele.innerText = (record.times || 0) + 1;
                  } else {
                    ele.innerText = record.times || 0;
                  }
                  pv.style.display = 'inline';
                }
              }
            });
            getterArr.push(viewGetter);
          }
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && this.increment(Counter, incrArr);
        })
      }

    },


    fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': this.app_id,
            'X-LC-Key': this.app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      this.addCount(Counter);
    },

    refreshCounter() {
      var api_server = this.app_id.slice(-9) !== '-MdYXbMMI' ? this.custom_api_server : `https://${ this.app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;
      if (api_server) {
        this.fetchData(api_server);
      } else {
        fetch('https://app-router.leancloud.cn/2/route?appId=' + this.app_id)
          .then(resp => resp.json())
          .then(({api_server}) => {
            this.fetchData('https://' + api_server);
          });
      }
    }

  };

  LCCounter.refreshCounter();

  document.addEventListener('pjax:complete', function () {
    LCCounter.refreshCounter();
  });
</script>




  <script>
const rootElement = document.documentElement;
const darkModeStorageKey = "user-color-scheme";
const rootElementDarkModeAttributeName = "data-user-color-scheme";

const setLS = (k, v) => {
    localStorage.setItem(k, v);
};

const removeLS = (k) => {
    localStorage.removeItem(k);
};

const getLS = (k) => {
    return localStorage.getItem(k);
};

const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};

const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};

const validColorModeKeys = {
  dark: true,
  light: true,
};

const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);

  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};

const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};

/**
 * get target mode
 */
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);

  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};

/**
 * bind click event for toggle button
 */
function bindToggleButton() {
	var btn=$("#wrapper .toggle-mode-btn");
    btn.on('click',(e) => {
      const mode = toggleCustomDarkMode();
      applyCustomDarkModeSettings(mode);
    });
}

applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", bindToggleButton);
volantis.pjax.push(bindToggleButton);
volantis.pjax.send(()=>{
	$("#wrapper .toggle-mode-btn").unbind('click');
},'toggle-mode-btn-unbind');
</script>








<script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script>

<!-- more -->

 
	   
	    


<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          "#l_cover",
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）

      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
		// 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
		volantis.pjax.method.complete.start();
      } catch (e) {
        console.log(e);
      }
    });

    document.addEventListener('pjax:error', function (e) {
	  // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.error.start();
      window.location.href = e.triggerElement.href;
    });
</script>
 
	  
    </div>
  </body>
</html>
